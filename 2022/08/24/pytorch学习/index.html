<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black"><link rel="icon" href="/images/icons/favicon-16x16.png?v=2.6.2" type="image/png" sizes="16x16"><link rel="icon" href="/images/icons/favicon-32x32.png?v=2.6.2" type="image/png" sizes="32x32"><meta name="description" content="1. Tensorboard        TensorBoard是TensorFlow自带的一个强大的可视化工具，也是一个Web应用程序套件。  可视化的主要功能  Scalars:展示训练过程中的准确率、损失值、权重&#x2F;偏置的变化情况。   1234567891011121314from torch.utils.tensorboard import Sum">
<meta property="og:type" content="article">
<meta property="og:title" content="pytorch学习">
<meta property="og:url" content="http://yoursite.com/2022/08/24/pytorch%E5%AD%A6%E4%B9%A0/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="1. Tensorboard        TensorBoard是TensorFlow自带的一个强大的可视化工具，也是一个Web应用程序套件。  可视化的主要功能  Scalars:展示训练过程中的准确率、损失值、权重&#x2F;偏置的变化情况。   1234567891011121314from torch.utils.tensorboard import Sum">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://yoursite.com/2022/08/24/pytorch%E5%AD%A6%E4%B9%A0/%E9%87%8D%E5%8F%A0.png">
<meta property="og:image" content="http://yoursite.com/2022/08/24/pytorch%E5%AD%A6%E4%B9%A0/%E9%87%8D%E5%8F%A0.png">
<meta property="og:image" content="http://yoursite.com/2022/08/24/pytorch%E5%AD%A6%E4%B9%A0/%E9%87%8D%E5%8F%A0.png">
<meta property="og:image" content="http://yoursite.com/2022/08/24/pytorch%E5%AD%A6%E4%B9%A0/transforms%E4%BD%BF%E7%94%A8.png">
<meta property="og:image" content="http://yoursite.com/2022/08/24/pytorch%E5%AD%A6%E4%B9%A0/normalize_tensor_output.png">
<meta property="og:image" content="http://yoursite.com/2022/08/24/pytorch%E5%AD%A6%E4%B9%A0/normalize_output.png">
<meta property="og:image" content="http://yoursite.com/2022/08/24/pytorch%E5%AD%A6%E4%B9%A0/cifar10_img_target.png">
<meta property="og:image" content="http://yoursite.com/2022/08/24/pytorch%E5%AD%A6%E4%B9%A0/nn_forward.png">
<meta property="og:image" content="http://yoursite.com/2022/08/24/pytorch%E5%AD%A6%E4%B9%A0/nn_forward%E6%B5%81%E7%A8%8B.png">
<meta property="og:image" content="http://yoursite.com/2022/08/24/pytorch%E5%AD%A6%E4%B9%A0/%E5%8D%B7%E7%A7%AF.png">
<meta property="og:image" content="http://yoursite.com/2022/08/24/pytorch%E5%AD%A6%E4%B9%A0/%E5%8D%B7%E7%A7%AF_padding%3D1.png">
<meta property="og:image" content="http://yoursite.com/2022/08/24/pytorch%E5%AD%A6%E4%B9%A0/%E5%8D%B7%E7%A7%AF_out_channel%3D2.png">
<meta property="og:image" content="http://yoursite.com/2022/08/24/pytorch%E5%AD%A6%E4%B9%A0/max_pooling.png">
<meta property="og:image" content="http://yoursite.com/2022/08/24/pytorch%E5%AD%A6%E4%B9%A0/relu.png">
<meta property="og:image" content="http://yoursite.com/2022/08/24/pytorch%E5%AD%A6%E4%B9%A0/relu_inplace.png">
<meta property="og:image" content="http://yoursite.com/2022/08/24/pytorch%E5%AD%A6%E4%B9%A0/cifar10_model_structure.png">
<meta property="og:image" content="http://yoursite.com/2022/08/24/pytorch%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E5%9B%BE.png">
<meta property="og:image" content="http://yoursite.com/2022/08/24/pytorch%E5%AD%A6%E4%B9%A0/vgg16_pretrained%3Dtrue.png">
<meta property="og:image" content="http://yoursite.com/2022/08/24/pytorch%E5%AD%A6%E4%B9%A0/vgg16_add_module.png">
<meta property="article:published_time" content="2022-08-24T08:29:01.659Z">
<meta property="article:modified_time" content="2022-08-31T07:02:19.243Z">
<meta property="article:author" content="Millionchan">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://yoursite.com/2022/08/24/pytorch%E5%AD%A6%E4%B9%A0/%E9%87%8D%E5%8F%A0.png"><title>pytorch学习 | Hexo</title><link ref="canonical" href="http://yoursite.com/2022/08/24/pytorch%E5%AD%A6%E4%B9%A0/"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.12.1/css/all.min.css" type="text/css"><link rel="stylesheet" href="/css/index.css?v=2.6.2"><script>var Stun = window.Stun || {};
var CONFIG = {
  root: '/',
  algolia: undefined,
  assistSearch: undefined,
  fontIcon: {"prompt":{"success":"fas fa-check-circle","info":"fas fa-arrow-circle-right","warning":"fas fa-exclamation-circle","error":"fas fa-times-circle"},"copyBtn":"fas fa-copy"},
  sidebar: {"offsetTop":"20px","tocMaxDepth":6},
  header: {"enable":true,"showOnPost":true,"scrollDownIcon":false},
  postWidget: {"endText":true},
  nightMode: {"enable":true},
  back2top: {"enable":true},
  codeblock: {"style":"default","highlight":"light","wordWrap":false},
  reward: false,
  fancybox: false,
  zoomImage: {"gapAside":"20px"},
  galleryWaterfall: undefined,
  lazyload: false,
  pjax: undefined,
  externalLink: {"icon":{"enable":true,"name":"fas fa-external-link-alt"}},
  shortcuts: undefined,
  prompt: {"copyButton":"Copy","copySuccess":"Copy Success","copyError":"Copy Error"},
  sourcePath: {"js":"js","css":"css","images":"images"},
};

window.CONFIG = CONFIG;</script><meta name="generator" content="Hexo 4.2.1"></head><body><div class="container" id="container"><header class="header" id="header"><div class="header-inner"><nav class="header-nav header-nav--fixed"><div class="header-nav-inner"><div class="header-nav-menubtn"><i class="fas fa-bars"></i></div><div class="header-nav-menu"><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/"><span class="header-nav-menu-item__icon"><i class="fas fa-home"></i></span><span class="header-nav-menu-item__text">Home</span></a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/archives/"><span class="header-nav-menu-item__icon"><i class="fas fa-folder-open"></i></span><span class="header-nav-menu-item__text">Archives</span></a></div></div><div class="header-nav-mode"><div class="mode"><div class="mode-track"><span class="mode-track-moon"></span><span class="mode-track-sun"></span></div><div class="mode-thumb"></div></div></div></div></nav><div class="header-banner"><div class="header-banner-info"><div class="header-banner-info__title">Hexo</div><div class="header-banner-info__subtitle"></div></div></div></div></header><main class="main" id="main"><div class="main-inner"><div class="content-wrap" id="content-wrap"><div class="content" id="content"><!-- Just used to judge whether it is an article page--><div id="is-post"></div><div class="post"><header class="post-header"><h1 class="post-title">pytorch学习</h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">Created</span><span class="post-meta-item__value">2022-08-24</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">Updated</span><span class="post-meta-item__value">2022-08-31</span></span></div></header><div class="post-body">
        <h3 id="1-Tensorboard">
          <a href="#1-Tensorboard" class="heading-link"><i class="fas fa-link"></i></a><a href="#1-Tensorboard" class="headerlink" title="1. Tensorboard"></a>1. Tensorboard</h3>
      <ul>
<li><p>TensorBoard是TensorFlow自带的一个强大的可视化工具，也是一个Web应用程序套件。</p>
</li>
<li><p>可视化的主要功能</p>
<ul>
<li><p>Scalars:展示训练过程中的准确率、损失值、权重/偏置的变化情况。</p>
  <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"></span><br><span class="line">writer=SummaryWriter(<span class="string">'logs'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#y=x</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">100</span>):</span><br><span class="line">    writer.add_scalar(<span class="string">'y=x'</span>,i,i)</span><br><span class="line"></span><br><span class="line">writer.close()</span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">运行后会生成logs文件夹</span></span><br><span class="line"><span class="string">terminal中输入tensorboard --logdir=logs可通过http://localhost:6006/ 打开查看，其中logdir=事件文件所在文件夹名</span></span><br><span class="line"><span class="string">为防止与其他端口冲突，可自行指定端口tensorboard --logdir=logs --port=6007</span></span><br><span class="line"><span class="string">'''</span></span><br></pre></td></tr></table></div></figure>
<p>  若出现重叠的情况，可将logs文件夹下的文件删除，重新运行；或每次都创建新的子文件夹SuummaryWriter(“新文件夹”)<br>  <img src="/2022/08/24/pytorch%E5%AD%A6%E4%B9%A0/%E9%87%8D%E5%8F%A0.png" alt><br>  <img src="/2022/08/24/pytorch%E5%AD%A6%E4%B9%A0/%E9%87%8D%E5%8F%A0.png" alt><br>  <img src="/2022/08/24/pytorch%E5%AD%A6%E4%B9%A0/%E9%87%8D%E5%8F%A0.png" alt></p>
</li>
<li><p>利用numpy.array()，对PIL图片进行转换</p>
  <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">image_path=<span class="string">'data/train/ants_image/0013035.jpg'</span></span><br><span class="line">img_PIL=Image.open(image_path)</span><br><span class="line">img_array=np.array(img_PIL)</span><br><span class="line"><span class="comment">#从PIL到numpy，需要在add_image()中指定shape中每一个数字/维表示的含义</span></span><br><span class="line">writer.add_image(<span class="string">'test'</span>,img_array,<span class="number">1</span>,dataformats=<span class="string">'HWC'</span>)</span><br></pre></td></tr></table></div></figure></li>
<li><p>add_image<br>add_image(tag, img_tensor, global_step=None, walltime=None, dataformats=’CHW’)</p>
<ul>
<li>tag (string): 数据名称</li>
<li>img_tensor (类型 torch.Tensor 或 numpy.array): 图像数据</li>
<li>global_step (int, optional): 记录这是第几个子图 后面解释这个参数</li>
<li>walltime (float, optional): 记录发生的时间，默认为 time.time()</li>
<li>dataformats (string, optional): 图像数据的格式，默认为 ‘CHW’，即 Channel x Height x Width，还可以是 ‘CHW’、‘HWC’ 或 ‘HW’ 等<br></li>
</ul>
</li>
</ul>
</li>
</ul>

        <h3 id="2-Transforms">
          <a href="#2-Transforms" class="heading-link"><i class="fas fa-link"></i></a><a href="#2-Transforms" class="headerlink" title="2. Transforms"></a>2. Transforms</h3>
      <ul>
<li>python的用法-&gt;tensor数据类型<ul>
<li>通过transforms.ToTensor去看两个问题<ul>
<li>transforms该如何使用<br><img src="/2022/08/24/pytorch%E5%AD%A6%E4%B9%A0/transforms%E4%BD%BF%E7%94%A8.png" alt><figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tensor_trans=transforms.ToTensor()</span><br><span class="line">tensor_img=tensor_trans(img)</span><br></pre></td></tr></table></div></figure></li>
<li>为什么需要Tensor数据类型</li>
</ul>
</li>
</ul>
</li>
<li>常见的Transforms<ul>
<li>call  <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Person</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__call__</span><span class="params">(self,name)</span>:</span></span><br><span class="line">        print(<span class="string">'__call__'</span>+<span class="string">"Hello"</span>+name)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">hello</span><span class="params">(self,name)</span>:</span></span><br><span class="line">        print(<span class="string">'hello'</span>+name)</span><br><span class="line"></span><br><span class="line">person=Person()</span><br><span class="line">person(<span class="string">'zhangsan'</span>)<span class="comment">#定义call可以直接用类+参数</span></span><br><span class="line">person.hello(<span class="string">'lisi'</span>)<span class="comment">#需要用点来调用方法</span></span><br></pre></td></tr></table></div></figure></li>
<li>ToTensor()  <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"></span><br><span class="line">writer=SummaryWriter(<span class="string">'logs'</span>)</span><br><span class="line">img=Image.open(<span class="string">'images/QQ图片201802031008421.jpg'</span>)</span><br><span class="line">print(img)</span><br><span class="line"></span><br><span class="line">trans_totensor=transforms.ToTensor()</span><br><span class="line">img_tensor=trans_totensor(img)</span><br><span class="line"></span><br><span class="line">writer.add_image(<span class="string">'ToTensor'</span>,img_tensor)</span><br><span class="line">writer.close()</span><br></pre></td></tr></table></div></figure></li>
<li>归一化函数Normalize()<ul>
<li>归一化要把需要处理的数据经过处理后（通过某种算法）限制在你需要的一定范围内，为了后面数据处理的方便，以及保证程序运行时收敛加快。</li>
<li>输入为tensor的数据类型  <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">output[channel] = (input[channel] - mean[channel]) / std[channel]</span><br></pre></td></tr></table></div></figure>
  <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">Normalize</span></span><br><span class="line"><span class="string">output[channel] = (input[channel] - mean[channel]) / std[channel]</span></span><br><span class="line"><span class="string">如下数据均值方差为[0.5,0.5,0.5],[0.5,0.5,0.5]，则output=(input-0.5)/0.5=2*input-1</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line">print(img_tensor[<span class="number">0</span>][<span class="number">0</span>][<span class="number">0</span>])<span class="comment">#第一层第一行第一列</span></span><br><span class="line">trans_norm=transforms.Normalize([<span class="number">1</span>,<span class="number">3</span>,<span class="number">5</span>],[<span class="number">3</span>,<span class="number">2</span>,<span class="number">1</span>])<span class="comment">#均值、方差</span></span><br><span class="line">img_norm=trans_norm(img_tensor)</span><br><span class="line">print(img_norm[<span class="number">0</span>][<span class="number">0</span>][<span class="number">0</span>])</span><br><span class="line">writer.add_image(<span class="string">'Normalize'</span>,img_norm,<span class="number">1</span>)</span><br><span class="line">writer.close()</span><br></pre></td></tr></table></div></figure>
  <img src="/2022/08/24/pytorch%E5%AD%A6%E4%B9%A0/normalize_tensor_output.png" alt><br>  <img src="/2022/08/24/pytorch%E5%AD%A6%E4%B9%A0/normalize_output.png" alt></li>
</ul>
</li>
<li>Resize()<ul>
<li>用于对PIL图像的预处理，可用resize函数进行缩放</li>
<li>open-cv的读取图像格式为numpy，而pytorch中的resize方法需要Image格式，因此需要转换</li>
<li>输入为PIL image  <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Resize</span></span><br><span class="line">print((img.size))</span><br><span class="line">trans_resize=transforms.Resize((<span class="number">512</span>,<span class="number">512</span>))</span><br><span class="line"><span class="comment">#img PIL -&gt;resize -&gt;img_resize PIL</span></span><br><span class="line">img_resize=trans_resize(img)</span><br><span class="line"><span class="comment">#img_resize PIL -&gt;totensor -&gt;img_resize tensor</span></span><br><span class="line">img_resize=trans_totensor(img_resize)</span><br><span class="line">writer.add_image(<span class="string">'Resize'</span>,img_resize,<span class="number">0</span>)</span><br><span class="line">print(img_resize)</span><br><span class="line">writer.close()</span><br></pre></td></tr></table></div></figure></li>
</ul>
</li>
<li>Compose()<ul>
<li>串联多个图片变换的操作</li>
<li>Compose()中的参数需要是一个列表，python中，列表的表示形式为[数据1，数据2，…]。在Compose中，数据需要是transforms类型，所以得到，Compose([transforms参数1,transforms参数2,…])  <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Compose - resize</span></span><br><span class="line">trans_resize_2=transforms.Resize(<span class="number">512</span>)</span><br><span class="line"><span class="comment">#PIL -&gt; PIL -&gt; tensor</span></span><br><span class="line"><span class="comment">#后面参数的输入应与前一参数的输出类型保持一致</span></span><br><span class="line">trans_compose=transforms.Compose([trans_resize_2,trans_totensor])</span><br><span class="line">img_resize_2=trans_compose(img)</span><br><span class="line">writer.add_image(<span class="string">'Resize'</span>,img_resize_2,<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">writer.close()</span><br></pre></td></tr></table></div></figure></li>
</ul>
</li>
<li>RandomCrop()随机裁剪  <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#RandomCrop</span></span><br><span class="line"><span class="comment">#用512截取图片的一部分</span></span><br><span class="line">trans_random=transforms.RandomCrop(<span class="number">512</span>)</span><br><span class="line"><span class="comment">#指定长和宽</span></span><br><span class="line"><span class="comment"># trans_random2=transforms.RandomCrop((512,1000))</span></span><br><span class="line">trans_compose_2=transforms.Compose([trans_random,trans_totensor])</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">    img_crop=trans_compose_2(img)</span><br><span class="line">    writer.add_image(<span class="string">'RandomCrop'</span>,img_crop,i)</span><br><span class="line"></span><br><span class="line">writer.close()</span><br></pre></td></tr></table></div></figure></li>
</ul>
</li>
<li>使用方法总结<ul>
<li>关注输入、输出类型</li>
<li>多看官方文档ctrl+鼠标左键</li>
<li>关注方法需要什么参数ctrl+p</li>
<li>不知道返回值的时候<ul>
<li>print</li>
<li>print(type())</li>
<li>debug</li>
<li>百度<br></li>
</ul>
</li>
</ul>
</li>
</ul>

        <h3 id="3-torchvision中的数据集使用">
          <a href="#3-torchvision中的数据集使用" class="heading-link"><i class="fas fa-link"></i></a><a href="#3-torchvision中的数据集使用" class="headerlink" title="3.torchvision中的数据集使用"></a>3.torchvision中的数据集使用</h3>
      <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"></span><br><span class="line">dataset_transform = torchvision.transforms.Compose([</span><br><span class="line">    torchvision.transforms.ToTensor()<span class="comment">#pytorch需要tensor类型的图片</span></span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># root:数据集村放在什么位置，./dataset会在程序所在文件夹创建dataset文件夹，并保存数据</span></span><br><span class="line"><span class="comment"># 训练集和测试集</span></span><br><span class="line">train_set = torchvision.datasets.CIFAR10(root=<span class="string">'./dataset'</span>, transform=dataset_transform, train=<span class="literal">True</span>, download=<span class="literal">True</span>)</span><br><span class="line">test_set = torchvision.datasets.CIFAR10(root=<span class="string">'./dataset'</span>, transform=dataset_transform, train=<span class="literal">False</span>, download=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">print(test_set[<span class="number">0</span>])</span><br><span class="line">print(test_set.classes)</span><br><span class="line">img, target = test_set[<span class="number">0</span>]</span><br><span class="line">print(img)</span><br><span class="line">print(target)</span><br><span class="line">print(test_set.classes[target])</span><br><span class="line"><span class="comment">#img.show()</span></span><br><span class="line"></span><br><span class="line">writer = SummaryWriter(<span class="string">'p10'</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">    img,target=test_set[i]</span><br><span class="line">    writer.add_image(<span class="string">'test_set'</span>,img,i)</span><br><span class="line">writer.close()</span><br><span class="line"></span><br><span class="line"><span class="comment">#terminal</span></span><br><span class="line"><span class="comment">#tensorboard --logdir=p10</span></span><br></pre></td></tr></table></div></figure>
<p><img src="/2022/08/24/pytorch%E5%AD%A6%E4%B9%A0/cifar10_img_target.png" alt><br>target=3对应为猫<br><br></p>

        <h3 id="4-DataLoader的使用">
          <a href="#4-DataLoader的使用" class="heading-link"><i class="fas fa-link"></i></a><a href="#4-DataLoader的使用" class="headerlink" title="4.DataLoader的使用"></a>4.DataLoader的使用</h3>
      <ul>
<li>常见参数<ul>
<li>很多参数有默认值，dataset没有</li>
<li>dataset:告诉程序数据集在什么地方</li>
<li>batch_size:每批要加载的样本数</li>
<li>shuffle:是否打乱，默认设为false，我们一般喜欢设置为true</li>
<li>num_workers:用于数据加载的子进程数。默认为0意味着数据将在主进程中加载</li>
<li>drop_last:设置为true如果数据集大小不能被批大小整除，则删除最后一个不完整的批，false则不删除</li>
</ul>
</li>
<li>代码  <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"></span><br><span class="line"><span class="comment">#准备的测试数据集</span></span><br><span class="line">test_data=torchvision.datasets.CIFAR10(root=<span class="string">'./dataset'</span>,train=<span class="literal">False</span>,transform=torchvision.transforms.ToTensor())</span><br><span class="line"></span><br><span class="line">test_loader=DataLoader(dataset=test_data,batch_size=<span class="number">4</span>,shuffle=<span class="literal">True</span>,num_workers=<span class="number">0</span>,drop_last=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#测试数据集中第一张图片及target</span></span><br><span class="line">img,target=test_data[<span class="number">0</span>]</span><br><span class="line"><span class="comment">#图片大小</span></span><br><span class="line">print(img.shape)</span><br><span class="line">print(target)</span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">output:</span></span><br><span class="line"><span class="string">torch.Size([3, 32, 32])#三通道（每个像素点都有3个值表示，RGB图片即为三通道图片），32*32的图片</span></span><br><span class="line"><span class="string">3</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line">writer=SummaryWriter(<span class="string">'dataloader'</span>)</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">2</span>):</span><br><span class="line">    step=<span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> test_loader:</span><br><span class="line">        imgs,targets=data</span><br><span class="line">        <span class="comment"># print(imgs.shape)</span></span><br><span class="line">        <span class="comment"># print(targets)</span></span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">        output</span></span><br><span class="line"><span class="string">        torch.Size([4, 3, 32, 32])#4表示4张图片，batch_size=4</span></span><br><span class="line"><span class="string">        tensor([2, 4, 9, 8])</span></span><br><span class="line"><span class="string">        torch.Size([4, 3, 32, 32])</span></span><br><span class="line"><span class="string">        tensor([4, 1, 2, 6])</span></span><br><span class="line"><span class="string">        ...</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        writer.add_images(<span class="string">'Epoch:&#123;&#125;'</span>.format(epoch),imgs,step)</span><br><span class="line">        step=step+<span class="number">1</span></span><br><span class="line">writer.close()</span><br></pre></td></tr></table></div></figure>
<br>

</li>
</ul>

        <h3 id="5-神经网络">
          <a href="#5-神经网络" class="heading-link"><i class="fas fa-link"></i></a><a href="#5-神经网络" class="headerlink" title="5.神经网络"></a>5.神经网络</h3>
      <ul>
<li>神经网络的基本骨架-nn.Module的使用  <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Tudui</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(Tudui, self).__init__()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self,input)</span>:</span></span><br><span class="line">        output=input+<span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line">tudui=Tudui()</span><br><span class="line">x=torch.tensor(<span class="number">1.0</span>)</span><br><span class="line">output=tudui(x)</span><br><span class="line">print(output)<span class="comment">#2.</span></span><br></pre></td></tr></table></div></figure>
<img src="/2022/08/24/pytorch%E5%AD%A6%E4%B9%A0/nn_forward.png" alt><br><img src="/2022/08/24/pytorch%E5%AD%A6%E4%B9%A0/nn_forward%E6%B5%81%E7%A8%8B.png" alt><br></li>
<li>卷积操作<br><img src="/2022/08/24/pytorch%E5%AD%A6%E4%B9%A0/%E5%8D%B7%E7%A7%AF.png" alt><br>padding填充默认填充0<br><img src="/2022/08/24/pytorch%E5%AD%A6%E4%B9%A0/%E5%8D%B7%E7%A7%AF_padding%3D1.png" alt>  <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="comment">#输入图像（5*5）</span></span><br><span class="line">input=torch.tensor([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">0</span>,<span class="number">3</span>,<span class="number">1</span>],</span><br><span class="line">                    [<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>],</span><br><span class="line">                    [<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>],</span><br><span class="line">                    [<span class="number">5</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">1</span>],</span><br><span class="line">                    [<span class="number">2</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>]])</span><br><span class="line"><span class="comment">#卷积核（3*3）</span></span><br><span class="line">kernel=torch.tensor([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>],</span><br><span class="line">                    [<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>],</span><br><span class="line">                    [<span class="number">2</span>,<span class="number">1</span>,<span class="number">0</span>]])</span><br><span class="line"></span><br><span class="line">input=torch.reshape(input,(<span class="number">1</span>,<span class="number">1</span>,<span class="number">5</span>,<span class="number">5</span>))<span class="comment">#1batch_size,1通道(平面）,5*5</span></span><br><span class="line">kernel=torch.reshape(kernel,(<span class="number">1</span>,<span class="number">1</span>,<span class="number">3</span>,<span class="number">3</span>))<span class="comment">#四维的，所以输出也是四维的</span></span><br><span class="line"></span><br><span class="line">print(input.shape)</span><br><span class="line">print(kernel.shape)</span><br><span class="line"></span><br><span class="line">output=F.conv2d(input,kernel,stride=<span class="number">1</span>)<span class="comment">#二维卷积</span></span><br><span class="line">print(output)</span><br><span class="line"></span><br><span class="line">output2=F.conv2d(input,kernel,stride=<span class="number">2</span>)</span><br><span class="line">print(output2)</span><br><span class="line"></span><br><span class="line">output3=F.conv2d(input,kernel,stride=<span class="number">1</span>,padding=<span class="number">1</span>)<span class="comment">#padding=1填充</span></span><br><span class="line">print(output3)</span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">output</span></span><br><span class="line"><span class="string">torch.Size([1, 1, 5, 5])</span></span><br><span class="line"><span class="string">torch.Size([1, 1, 3, 3])</span></span><br><span class="line"><span class="string">tensor([[[[10, 12, 12],</span></span><br><span class="line"><span class="string">        [18, 16, 16],</span></span><br><span class="line"><span class="string">        [13,  9,  3]]]])</span></span><br><span class="line"><span class="string">tensor([[[[10, 12],</span></span><br><span class="line"><span class="string">        [13,  3]]]])</span></span><br><span class="line"><span class="string">tensor([[[[ 1,  3,  4, 10,  8],</span></span><br><span class="line"><span class="string">        [ 5, 10, 12, 12,  6],</span></span><br><span class="line"><span class="string">        [ 7, 18, 16, 16,  8],</span></span><br><span class="line"><span class="string">        [11, 13,  9,  3,  4],</span></span><br><span class="line"><span class="string">        [14, 13,  9,  7,  4]]]])</span></span><br><span class="line"><span class="string">'''</span></span><br></pre></td></tr></table></div></figure></li>
<li>神经网络-卷积层<br><img src="/2022/08/24/pytorch%E5%AD%A6%E4%B9%A0/%E5%8D%B7%E7%A7%AF_out_channel%3D2.png" alt><br>input_channel=1（只有一层）,output_channel=2（有两层输出）,所以有两个卷积核（不一定完全相同）  <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> Conv2d</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"></span><br><span class="line">dataset=torchvision.datasets.CIFAR10(<span class="string">"../dataset"</span>,train=<span class="literal">False</span>,transform=torchvision.transforms.ToTensor(),</span><br><span class="line">                                    download=<span class="literal">True</span>)</span><br><span class="line">dataloader=DataLoader(dataset,batch_size=<span class="number">64</span>)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Tudui</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(Tudui, self).__init__()</span><br><span class="line">        <span class="comment"># input_channel=3(彩色图片channel为3,output_channel=6,kernel_size=3）</span></span><br><span class="line">        self.conv1=Conv2d(in_channels=<span class="number">3</span>,out_channels=<span class="number">6</span>,kernel_size=<span class="number">3</span>,stride=<span class="number">1</span>,padding=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self,x)</span>:</span><span class="comment">#x为输出</span></span><br><span class="line">        x=self.conv1(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="comment">#初始化网络</span></span><br><span class="line">tudui=Tudui()</span><br><span class="line">print(tudui)</span><br><span class="line"></span><br><span class="line">writer=SummaryWriter(<span class="string">'../logs'</span>)</span><br><span class="line"></span><br><span class="line">step=<span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> dataloader:</span><br><span class="line">    imgs,targets=data</span><br><span class="line">    output=tudui(imgs)</span><br><span class="line">    print(imgs.shape)</span><br><span class="line">    print(output.shape)</span><br><span class="line">    <span class="comment">#torch.Size([16, 3, 32, 32])</span></span><br><span class="line">    writer.add_images(<span class="string">'input'</span>,imgs,step)</span><br><span class="line">    <span class="comment">#torch.Size([16, 6, 30, 30]) -&gt; [xxx,3,30,30]</span></span><br><span class="line">    output=torch.reshape(output,(<span class="number">-1</span>,<span class="number">3</span>,<span class="number">30</span>,<span class="number">30</span>))<span class="comment">#不知道多少写-1，系统会自己计算</span></span><br><span class="line">    writer.add_images(<span class="string">'output'</span>,output,step)</span><br><span class="line">    step+=<span class="number">1</span></span><br></pre></td></tr></table></div></figure></li>
<li>神经网络-最大池化的使用<br>ceil_model=true则保留，false不保留（不满足3*3的不保留），一般设置为false<br><img src="/2022/08/24/pytorch%E5%AD%A6%E4%B9%A0/max_pooling.png" alt>  <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#降维，训练的更快</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> MaxPool2d</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"></span><br><span class="line">dataset=torchvision.datasets.CIFAR10(<span class="string">'../dataset'</span>,train=<span class="literal">False</span>,download=<span class="literal">True</span>,</span><br><span class="line">                                    transform=torchvision.transforms.ToTensor())</span><br><span class="line">dataloader=DataLoader(dataset,batch_size=<span class="number">64</span>)</span><br><span class="line"><span class="comment"># input=torch.tensor([[1,2,0,3,1],</span></span><br><span class="line"><span class="comment">#                     [0,1,2,3,1],</span></span><br><span class="line"><span class="comment">#                     [1,2,1,0,0],</span></span><br><span class="line"><span class="comment">#                     [5,2,3,1,1],</span></span><br><span class="line"><span class="comment">#                     [2,1,0,1,1]],dtype=torch.float32)#变为浮点型</span></span><br><span class="line"><span class="comment"># input=torch.reshape(input,(-1,1,5,5))</span></span><br><span class="line"><span class="comment"># print(input.shape)</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Tudui</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(Tudui, self).__init__()</span><br><span class="line">        self.maxpool1=MaxPool2d(kernel_size=<span class="number">3</span>,ceil_mode=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self,input)</span>:</span></span><br><span class="line">        output=self.maxpool1(input)</span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line">tudui=Tudui()</span><br><span class="line"><span class="comment"># output=tudui(input)</span></span><br><span class="line"><span class="comment"># print(output)</span></span><br><span class="line"></span><br><span class="line">writer=SummaryWriter(<span class="string">'../logs_maxpool'</span>)</span><br><span class="line">step=<span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> dataloader:</span><br><span class="line">    imgs,targets=data</span><br><span class="line">    writer.add_images(<span class="string">'input'</span>,imgs,step)</span><br><span class="line">    output=tudui(imgs)</span><br><span class="line">    writer.add_images(<span class="string">'output'</span>,output,step)</span><br><span class="line">    step+=<span class="number">1</span></span><br><span class="line"></span><br><span class="line">writer.close()</span><br></pre></td></tr></table></div></figure></li>
<li>神经网络-非线性激活<br>增加非线性的激活函数实际上是给模型增加非线性的表达能力或者因素，有了非线性函数，模型的表达能力就会更强，整个模型就像活了一样，而不是像机器只会做单一的线性操作。没有激活函数的神经网络实际上是线性可加的，那么多线性层其实可以归为一层，只具有线性的神经网络表达能力极其有限。<br><img src="/2022/08/24/pytorch%E5%AD%A6%E4%B9%A0/relu.png" alt><br>inplace=true则替换，false则不替换。<br>一般建议inplace取false，（默认为false）保留原始数据，防止数据丢失。<br><img src="/2022/08/24/pytorch%E5%AD%A6%E4%B9%A0/relu_inplace.png" alt>  <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> ReLU, Sigmoid</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"></span><br><span class="line">input=torch.tensor([[<span class="number">1</span>,<span class="number">-0.5</span>],</span><br><span class="line">                    [<span class="number">-1</span>,<span class="number">3</span>]])</span><br><span class="line"></span><br><span class="line">input=torch.reshape(input,(<span class="number">-1</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>))</span><br><span class="line">print(input.shape)</span><br><span class="line"></span><br><span class="line">dataset=torchvision.datasets.CIFAR10(<span class="string">'../dataset'</span>,train=<span class="literal">False</span>,download=<span class="literal">True</span>,</span><br><span class="line">                                    transform=torchvision.transforms.ToTensor())</span><br><span class="line">dataloader=DataLoader(dataset,batch_size=<span class="number">64</span>)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Tudui</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(Tudui, self).__init__()</span><br><span class="line">        self.relu=ReLU()</span><br><span class="line">        self.sigmoid=Sigmoid()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self,input)</span>:</span></span><br><span class="line">        <span class="comment">#output=self.relu(input)</span></span><br><span class="line">        output=self.sigmoid(input)</span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line">tudui=Tudui()</span><br><span class="line"><span class="comment"># output=tudui(input)</span></span><br><span class="line"><span class="comment"># print(output)</span></span><br><span class="line"></span><br><span class="line">writer=SummaryWriter(<span class="string">'../logs_relu'</span>)</span><br><span class="line">step=<span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> dataloader:</span><br><span class="line">    imgs,targets=data</span><br><span class="line">    output=tudui(imgs)</span><br><span class="line">    writer.add_images(<span class="string">'input'</span>,imgs,global_step=step)</span><br><span class="line">    writer.add_images(<span class="string">'output'</span>,output,step)</span><br><span class="line">    step+=<span class="number">1</span></span><br><span class="line"></span><br><span class="line">writer.close()</span><br></pre></td></tr></table></div></figure></li>
<li>神经网络-线性层及其他层介绍  <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> Linear</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"></span><br><span class="line">dataset=torchvision.datasets.CIFAR10(<span class="string">'../dataset'</span>,train=<span class="literal">False</span>,download=<span class="literal">True</span>,transform=torchvision.transforms.ToTensor())</span><br><span class="line">dataloader=DataLoader(dataset,batch_size=<span class="number">64</span>,drop_last=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Tudui</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(Tudui, self).__init__()</span><br><span class="line">        self.linear1=Linear(<span class="number">196608</span>,<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self,input)</span>:</span></span><br><span class="line">        output=self.linear1(input)</span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line">tudui=Tudui()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> dataloader:</span><br><span class="line">    imgs,targets=data</span><br><span class="line">    print(imgs.shape)</span><br><span class="line">    <span class="comment"># output:torch.Size([64, 3, 32, 32])</span></span><br><span class="line">    <span class="comment">#output=torch.reshape(imgs,(1,1,1,-1))#四个维度等于input元素数即可，其中一项写-1会自动给你补齐</span></span><br><span class="line">    output=torch.flatten(imgs)<span class="comment">#摊平，展成一行</span></span><br><span class="line">    <span class="comment">#output:torch.Size([196608])</span></span><br><span class="line">    print(output.shape)</span><br><span class="line">    <span class="comment"># output:torch.Size([1, 1, 1, 196608])</span></span><br><span class="line">    output=tudui(output)</span><br><span class="line">    print(output.shape)</span><br></pre></td></tr></table></div></figure></li>
<li>神经网络-搭建小实战和Sequential的使用<br>cifar10 model structure<br><img src="/2022/08/24/pytorch%E5%AD%A6%E4%B9%A0/cifar10_model_structure.png" alt>  <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#cifar10模型</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> Conv2d, MaxPool2d, Flatten, Linear, Sequential</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Tudui</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(Tudui, self).__init__()<span class="comment">#父类初始化</span></span><br><span class="line">        <span class="comment">#与下述代码功能等同</span></span><br><span class="line">        <span class="comment"># self.conv1=Conv2d(3,32,5,padding=2)#如图所示input3，output32，kernel5，padding分析得出</span></span><br><span class="line">        <span class="comment"># self.maxpool1=MaxPool2d(2)#如图maxpooling2*2kernel</span></span><br><span class="line">        <span class="comment"># self.conv2=Conv2d(32,32,5,padding=2)</span></span><br><span class="line">        <span class="comment"># self.maxpool2=MaxPool2d(2)</span></span><br><span class="line">        <span class="comment"># self.conv3=Conv2d(32,64,5,padding=2)</span></span><br><span class="line">        <span class="comment"># self.maxpool3=MaxPool2d(2)</span></span><br><span class="line">        <span class="comment"># self.flatten=Flatten()</span></span><br><span class="line">        <span class="comment"># self.linear1=Linear(1024,64)#如图</span></span><br><span class="line">        <span class="comment"># self.linear2=Linear(64,10)</span></span><br><span class="line"></span><br><span class="line">        self.model1=Sequential(</span><br><span class="line">            Conv2d(<span class="number">3</span>,<span class="number">32</span>,<span class="number">5</span>,padding=<span class="number">2</span>),</span><br><span class="line">            MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            Conv2d(<span class="number">32</span>, <span class="number">32</span>, <span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            Conv2d(<span class="number">32</span>, <span class="number">64</span>, <span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            Flatten(),</span><br><span class="line">            Linear(<span class="number">1024</span>, <span class="number">64</span>),</span><br><span class="line">            Linear(<span class="number">64</span>, <span class="number">10</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self,x)</span>:</span></span><br><span class="line">        <span class="comment"># x=self.conv1(x)</span></span><br><span class="line">        <span class="comment"># x=self.maxpool1(x)</span></span><br><span class="line">        <span class="comment"># x=self.conv2(x)</span></span><br><span class="line">        <span class="comment"># x=self.maxpool2(x)</span></span><br><span class="line">        <span class="comment"># x=self.conv3(x)</span></span><br><span class="line">        <span class="comment"># x=self.maxpool3(x)</span></span><br><span class="line">        <span class="comment"># x=self.flatten(x)</span></span><br><span class="line">        <span class="comment"># x=self.linear1(x)</span></span><br><span class="line">        <span class="comment"># x=self.linear2(x)</span></span><br><span class="line">        x=self.model1(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">tudui=Tudui()<span class="comment">#实例化网络</span></span><br><span class="line">print(tudui)</span><br><span class="line">input=torch.ones(<span class="number">64</span>,<span class="number">3</span>,<span class="number">32</span>,<span class="number">32</span>)</span><br><span class="line">output=tudui(input)</span><br><span class="line">print(output.shape)</span><br><span class="line"></span><br><span class="line">writer=SummaryWriter(<span class="string">'../logs_seq'</span>)</span><br><span class="line">writer.add_graph(tudui,input)<span class="comment">#计算图</span></span><br><span class="line">writer.close()</span><br></pre></td></tr></table></div></figure>
<img src="/2022/08/24/pytorch%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E5%9B%BE.png" alt></li>
<li>损失函数与反向传播<ul>
<li>计算实际输出和目标之间的差距</li>
<li>为我们更新输出提供一定的依据（反向传播）<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> L1Loss</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line">inputs=torch.tensor([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],dtype=torch.float32)</span><br><span class="line">targets=torch.tensor([<span class="number">1</span>,<span class="number">2</span>,<span class="number">5</span>],dtype=torch.float32)</span><br><span class="line"></span><br><span class="line">inputs=torch.reshape(inputs,(<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">3</span>))</span><br><span class="line">targets=torch.reshape(targets,(<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">loss=L1Loss()</span><br><span class="line">result=loss(inputs,targets)</span><br><span class="line"></span><br><span class="line">loss_mse=nn.MSELoss()</span><br><span class="line">result_mse=loss_mse(inputs,targets)</span><br><span class="line"></span><br><span class="line">print(result)</span><br><span class="line">print(result_mse)</span><br><span class="line"></span><br><span class="line">x=torch.tensor([<span class="number">0.1</span>,<span class="number">0.2</span>,<span class="number">0.3</span>])</span><br><span class="line">y=torch.tensor([<span class="number">1</span>])</span><br><span class="line">x=torch.reshape(x,(<span class="number">1</span>,<span class="number">3</span>))</span><br><span class="line">loss_cross=nn.CrossEntropyLoss()</span><br><span class="line">result_cross=loss_cross(x,y)</span><br><span class="line">print(result_cross)</span><br></pre></td></tr></table></div></figure>
<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> Sequential, Conv2d, MaxPool2d, Flatten, Linear</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"></span><br><span class="line">dataset=torchvision.datasets.CIFAR10(<span class="string">'../dataset'</span>,train=<span class="literal">False</span>,download=<span class="literal">True</span>,</span><br><span class="line">                                    transform=torchvision.transforms.ToTensor())</span><br><span class="line">dataloader=DataLoader(dataset,batch_size=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Tudui</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(Tudui, self).__init__()</span><br><span class="line">        self.model1=Sequential(</span><br><span class="line">            Conv2d(<span class="number">3</span>, <span class="number">32</span>, <span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            Conv2d(<span class="number">32</span>, <span class="number">32</span>, <span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            Conv2d(<span class="number">32</span>, <span class="number">64</span>, <span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            Flatten(),</span><br><span class="line">            Linear(<span class="number">1024</span>, <span class="number">64</span>),</span><br><span class="line">            Linear(<span class="number">64</span>, <span class="number">10</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self,x)</span>:</span></span><br><span class="line">        x=self.model1(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">loss=nn.CrossEntropyLoss()</span><br><span class="line">tudui=Tudui()</span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> dataloader:</span><br><span class="line">    imgs,targets=data</span><br><span class="line">    output=tudui(imgs)</span><br><span class="line">    <span class="comment"># print(output)</span></span><br><span class="line">    <span class="comment"># print(targets)</span></span><br><span class="line">    result_loss=loss(output,targets)</span><br><span class="line">    print(result_loss)<span class="comment">#得到神经网络的输出和真实值的误差</span></span><br><span class="line">    result_loss.backward()</span><br><span class="line">    print(<span class="string">'ok'</span>)</span><br></pre></td></tr></table></div></figure></li>
</ul>
</li>
<li>优化器  <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> Sequential, Conv2d, MaxPool2d, Flatten, Linear</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"></span><br><span class="line">dataset=torchvision.datasets.CIFAR10(<span class="string">'../dataset'</span>,train=<span class="literal">False</span>,download=<span class="literal">True</span>,</span><br><span class="line">                                    transform=torchvision.transforms.ToTensor())</span><br><span class="line">dataloader=DataLoader(dataset,batch_size=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Tudui</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(Tudui, self).__init__()</span><br><span class="line">        self.model1=Sequential(</span><br><span class="line">            Conv2d(<span class="number">3</span>, <span class="number">32</span>, <span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            Conv2d(<span class="number">32</span>, <span class="number">32</span>, <span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            Conv2d(<span class="number">32</span>, <span class="number">64</span>, <span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            Flatten(),</span><br><span class="line">            Linear(<span class="number">1024</span>, <span class="number">64</span>),</span><br><span class="line">            Linear(<span class="number">64</span>, <span class="number">10</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self,x)</span>:</span></span><br><span class="line">        x=self.model1(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">loss=nn.CrossEntropyLoss()</span><br><span class="line">tudui=Tudui()</span><br><span class="line"><span class="comment">#学习速率太小训练的慢，太大模型不稳定，一开始用比较大的，后来用比较小的</span></span><br><span class="line">optim=torch.optim.SGD(tudui.parameters(),lr=<span class="number">0.01</span>)</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">20</span>):<span class="comment">#epoch一轮一轮的意思</span></span><br><span class="line">    running_loss=<span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> dataloader:</span><br><span class="line">        imgs,targets=data</span><br><span class="line">        output=tudui(imgs)</span><br><span class="line">        <span class="comment"># print(output)</span></span><br><span class="line">        <span class="comment"># print(targets)</span></span><br><span class="line">        result_loss=loss(output,targets)</span><br><span class="line">        optim.zero_grad()<span class="comment">#每个参数梯度清零</span></span><br><span class="line">        result_loss.backward()</span><br><span class="line">        optim.step()<span class="comment">#对每个参数调优，会跳到34行</span></span><br><span class="line">        running_loss=result_loss+result_loss<span class="comment">#所有数据整体的loss</span></span><br><span class="line">    print(running_loss)</span><br></pre></td></tr></table></div></figure></li>
<li>现有网络模型的使用及修改<br><img src="/2022/08/24/pytorch%E5%AD%A6%E4%B9%A0/vgg16_pretrained%3Dtrue.png" alt>  <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#dataset:ImageNet</span></span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line"><span class="comment"># train_data=torchvision.datasets.ImageNet('../data_image_net',split='train',download=True,</span></span><br><span class="line"><span class="comment">#                                         transform=torchvision.transforms.ToTensor())</span></span><br><span class="line"></span><br><span class="line">vgg16_false=torchvision.models.vgg16(pretrainde=<span class="literal">False</span>)</span><br><span class="line">vgg16_true=torchvision.models.vgg16(pretrainde=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># print('ok')</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># vgg16_true.add_module('add_linear',nn.Linear(1000,10))</span></span><br><span class="line">vgg16_true.classifier.add_module(<span class="string">'add_linear'</span>,nn.Linear(<span class="number">1000</span>,<span class="number">10</span>))</span><br><span class="line">print(vgg16_true)</span><br><span class="line"></span><br><span class="line">print(vgg16_false)</span><br><span class="line">vgg16_false.classifier[<span class="number">6</span>]=nn.Linear(<span class="number">4096</span>,<span class="number">10</span>)<span class="comment">#修改</span></span><br><span class="line">print(vgg16_false)</span><br></pre></td></tr></table></div></figure>
vgg16_add_module<br><img src="/2022/08/24/pytorch%E5%AD%A6%E4%B9%A0/vgg16_add_module.png" alt></li>
<li>网络模型的保存与读取<ul>
<li>模型的保存  <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line">vgg16=torchvision.models.vgg16(pretrained=<span class="literal">False</span>)</span><br><span class="line"><span class="comment">#保存方式1模型结构+模型参数</span></span><br><span class="line">torch.save(vgg16,<span class="string">'vgg16_method1.pth'</span>)<span class="comment">#.pth常用的后缀模式</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#保存方式2模型参数（官方推荐的保存方式）</span></span><br><span class="line">torch.save(vgg16.state_dict(),<span class="string">'vgg16_method2.pth'</span>)<span class="comment">#vgg16状态保存成字典格式</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#陷阱</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Tudui</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(Tudui, self).__init__()</span><br><span class="line">        self.conv1=nn.Conv2d(<span class="number">3</span>,<span class="number">64</span>,kernel_size=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self,x)</span>:</span></span><br><span class="line">        x=self.conv1(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">tudui=Tudui()</span><br><span class="line">torch.save(tudui,<span class="string">'tudui_method1.pth'</span>)</span><br></pre></td></tr></table></div></figure></li>
<li>模型的加载  <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line"><span class="comment">#方式1 -&gt;保存方式1，加载模型</span></span><br><span class="line"><span class="comment"># model=torch.load('vgg16_method1.pth')</span></span><br><span class="line"><span class="comment"># print(model)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#方式2加载模型</span></span><br><span class="line">vgg16=torchvision.models.vgg16(pretrained=<span class="literal">False</span>)<span class="comment">#预训练设置为false</span></span><br><span class="line">vgg16.load_state_dict(torch.load(<span class="string">'vgg16_method2.pth'</span>))</span><br><span class="line"><span class="comment">#model=torch.load('vgg16_method2.pth')</span></span><br><span class="line">print(vgg16)</span><br><span class="line"></span><br><span class="line"><span class="comment">#陷阱1</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Tudui</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(Tudui, self).__init__()</span><br><span class="line">        self.conv1=nn.Conv2d(<span class="number">3</span>,<span class="number">64</span>,kernel_size=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self,x)</span>:</span></span><br><span class="line">        x=self.conv1(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">model=torch.load(<span class="string">'tudui_method1.pth'</span>)</span><br><span class="line">print(model)</span><br></pre></td></tr></table></div></figure>
  <br>

</li>
</ul>
</li>
</ul>

        <h3 id="6-完整的模型训练套路">
          <a href="#6-完整的模型训练套路" class="heading-link"><i class="fas fa-link"></i></a><a href="#6-完整的模型训练套路" class="headerlink" title="6.完整的模型训练套路"></a>6.完整的模型训练套路</h3>
      <ul>
<li>准备数据集dataset</li>
<li>加载数据集dataloader</li>
<li>创建网络模型、损失函数、优化器</li>
<li>设置训练中的参数</li>
<li>设置训练轮数epoch</li>
<li>开始训练tudui.train()(此行代码意义不大)</li>
<li>优化器优化</li>
<li>开始测试tudui.eval() with torch.no_grad()</li>
<li>保存模型<br>以cifar10数据集为例  <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"><span class="comment">#准备数据集</span></span><br><span class="line">train_data=torchvision.datasets.CIFAR10(root=<span class="string">'../dataset'</span>,train=<span class="literal">True</span>,transform=torchvision.transforms.ToTensor(),</span><br><span class="line">                                        download=<span class="literal">True</span>)</span><br><span class="line">test_data=torchvision.datasets.CIFAR10(root=<span class="string">'../dataset'</span>,train=<span class="literal">False</span>,transform=torchvision.transforms.ToTensor(),</span><br><span class="line">                                    download=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#length长度</span></span><br><span class="line">train_data_size=len(train_data)</span><br><span class="line">test_data_size=len(test_data)</span><br><span class="line"><span class="comment">#如果train_data_size=10，训练数据集的长度为：10</span></span><br><span class="line"><span class="comment">#ctrl+d可以复制当前行</span></span><br><span class="line">print(<span class="string">'训练数据集长度为：&#123;&#125;'</span>.format(train_data_size))</span><br><span class="line">print(<span class="string">'测试数据集长度为：&#123;&#125;'</span>.format(test_data_size))</span><br><span class="line"></span><br><span class="line"><span class="comment">#利用dataloader来加载数据集</span></span><br><span class="line">train_dataloader=DataLoader(dataset=train_data,batch_size=<span class="number">64</span>)</span><br><span class="line">test_dataloader=DataLoader(dataset=test_data,batch_size=<span class="number">64</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># #搭建神经网络，见model.py</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#创建网络模型</span></span><br><span class="line">tudui=Tudui()</span><br><span class="line"></span><br><span class="line"><span class="comment">#损失函数</span></span><br><span class="line">loss_fn=nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line"><span class="comment">#优化器</span></span><br><span class="line"><span class="comment">#learning_rate=0.01</span></span><br><span class="line"><span class="comment">#1e-2=1*10^(-2)=1/100=0.01</span></span><br><span class="line">learning_rate=<span class="number">1e-2</span></span><br><span class="line">optimizer=torch.optim.SGD(tudui.parameters(),lr=learning_rate)</span><br><span class="line"></span><br><span class="line"><span class="comment">#设置训练网络的一些参数</span></span><br><span class="line">total_train_step=<span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#记录测试的次数</span></span><br><span class="line">total_test_step=<span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#训练次数</span></span><br><span class="line">epoch=<span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#添加tensorboard</span></span><br><span class="line">writer=SummaryWriter(<span class="string">'../logs_train'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(epoch):</span><br><span class="line">    print(<span class="string">'------第&#123;&#125;轮训练开始------'</span>.format(i+<span class="number">1</span>))</span><br><span class="line">    <span class="comment">#训练开始</span></span><br><span class="line">    tudui.train()</span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> train_dataloader:</span><br><span class="line">        imgs,targets=data</span><br><span class="line">        outputs=tudui(imgs)</span><br><span class="line">        loss=loss_fn(outputs,targets)</span><br><span class="line">        <span class="comment">#优化器优化模型</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        total_train_step+=<span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> total_train_step%<span class="number">100</span>==<span class="number">0</span>:</span><br><span class="line">            print(<span class="string">'训练次数：&#123;&#125;,Loss:&#123;&#125;'</span>.format(total_train_step,loss.item()))</span><br><span class="line">            writer.add_scalar(<span class="string">'train_loss'</span>,loss.item(),total_train_step)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#判断模型是否训练好：每次训练完之后在测试数据集上跑一遍，以测试数据集的损失或正确率来评估模型是否训练好</span></span><br><span class="line">    <span class="comment">#测试步骤开始</span></span><br><span class="line">    tudui.eval()</span><br><span class="line">    total_test_loss=<span class="number">0</span></span><br><span class="line">    total_accuracy=<span class="number">0</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():<span class="comment">#没有梯度调优，便于测试</span></span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> test_dataloader:</span><br><span class="line">            imgs,targets=data</span><br><span class="line">            outputs=tudui(imgs)</span><br><span class="line">            loss=loss_fn(outputs,targets)</span><br><span class="line">            total_test_loss+=loss.item()</span><br><span class="line">            accuracy=(outputs.argmax(<span class="number">1</span>)==targets).sum()</span><br><span class="line">            total_accuracy+=accuracy</span><br><span class="line">    print(<span class="string">'整体测试集上的Loss:&#123;&#125;'</span>.format(total_test_loss))</span><br><span class="line">    print(<span class="string">'整体测试集上的正确率：&#123;&#125;'</span>.format(total_accuracy/test_data_size))</span><br><span class="line">    writer.add_scalar(<span class="string">'test_loss'</span>,total_test_loss,total_test_step)</span><br><span class="line">    writer.add_scalar(<span class="string">'test_accuracy'</span>,total_accuracy/test_data_size,total_test_step)</span><br><span class="line">    total_test_step+=<span class="number">1</span></span><br><span class="line"></span><br><span class="line">    torch.save(tudui,<span class="string">'tudui_&#123;&#125;.pth'</span>.format(i))</span><br><span class="line">    <span class="comment">#torch.save(tudui,'tudui_&#123;&#125;.pth'.format(i))#方式二</span></span><br><span class="line">    print(<span class="string">'模型已保存'</span>)</span><br><span class="line">writer.close()</span><br></pre></td></tr></table></div></figure>
  <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#test</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">a=torch.tensor(<span class="number">5</span>)</span><br><span class="line">print(a)</span><br><span class="line"><span class="comment">#item()会把tensor数据类型转换成真实的数字</span></span><br><span class="line">print(a.item())</span><br></pre></td></tr></table></div></figure>
  <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#test2</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">outputs=torch.tensor([[<span class="number">0.1</span>,<span class="number">0.2</span>],</span><br><span class="line">                    [<span class="number">0.05</span>,<span class="number">0.4</span>]])</span><br><span class="line">print(outputs.argmax(<span class="number">1</span>))<span class="comment">#为1的时候横向看 0.2和0.4最大，所以结果为1，1</span></span><br><span class="line">print(outputs.argmax(<span class="number">0</span>))<span class="comment">#为0的时候纵向看 0.1和0.4最大，所以结果为0，1</span></span><br><span class="line">preds=outputs.argmax(<span class="number">1</span>)</span><br><span class="line">targets=torch.tensor([<span class="number">0</span>,<span class="number">1</span>])</span><br><span class="line">print((preds==targets).sum())<span class="comment">#相等返回true，不相等返回false</span></span><br></pre></td></tr></table></div></figure>
  <br>

</li>
</ul>

        <h3 id="7-利用GPU训练">
          <a href="#7-利用GPU训练" class="heading-link"><i class="fas fa-link"></i></a><a href="#7-利用GPU训练" class="headerlink" title="7.利用GPU训练"></a>7.利用GPU训练</h3>
      <p>若没有GPU，可访问Google colab<br>方式一</p>
<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"></span><br><span class="line"><span class="comment">#准备数据集</span></span><br><span class="line">train_data=torchvision.datasets.CIFAR10(root=<span class="string">'../dataset'</span>,train=<span class="literal">True</span>,transform=torchvision.transforms.ToTensor(),</span><br><span class="line">                                        download=<span class="literal">True</span>)</span><br><span class="line">test_data=torchvision.datasets.CIFAR10(root=<span class="string">'../dataset'</span>,train=<span class="literal">False</span>,transform=torchvision.transforms.ToTensor(),</span><br><span class="line">                                       download=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#length长度</span></span><br><span class="line">train_data_size=len(train_data)</span><br><span class="line">test_data_size=len(test_data)</span><br><span class="line"><span class="comment">#如果train_data_size=10，训练数据集的长度为：10</span></span><br><span class="line"><span class="comment">#ctrl+d可以复制当前行</span></span><br><span class="line">print(<span class="string">'训练数据集长度为：&#123;&#125;'</span>.format(train_data_size))</span><br><span class="line">print(<span class="string">'测试数据集长度为：&#123;&#125;'</span>.format(test_data_size))</span><br><span class="line"></span><br><span class="line"><span class="comment">#利用dataloader来加载数据集</span></span><br><span class="line">train_dataloader=DataLoader(dataset=train_data,batch_size=<span class="number">64</span>)</span><br><span class="line">test_dataloader=DataLoader(dataset=test_data,batch_size=<span class="number">64</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#搭建神经网络</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Tudui</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(Tudui, self).__init__()</span><br><span class="line">        self.model=nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">3</span>,<span class="number">32</span>,<span class="number">5</span>,<span class="number">1</span>,<span class="number">2</span>),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">32</span>,<span class="number">32</span>,<span class="number">5</span>,<span class="number">1</span>,<span class="number">2</span>),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">32</span>,<span class="number">64</span>,<span class="number">5</span>,<span class="number">1</span>,<span class="number">2</span>),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            nn.Flatten(),</span><br><span class="line">            nn.Linear(<span class="number">64</span>*<span class="number">4</span>*<span class="number">4</span>,<span class="number">64</span>),</span><br><span class="line">            nn.Linear(<span class="number">64</span>,<span class="number">10</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self,x)</span>:</span></span><br><span class="line">        x=self.model(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"><span class="comment">#创建网络模型</span></span><br><span class="line">tudui=Tudui()</span><br><span class="line"><span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">    tudui=tudui.cuda()</span><br><span class="line"></span><br><span class="line"><span class="comment">#损失函数</span></span><br><span class="line">loss_fn=nn.CrossEntropyLoss()</span><br><span class="line"><span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">    loss_fn=loss_fn.cuda()</span><br><span class="line"></span><br><span class="line"><span class="comment">#优化器</span></span><br><span class="line"><span class="comment">#learning_rate=0.01</span></span><br><span class="line"><span class="comment">#1e-2=1*10^(-2)=1/100=0.01</span></span><br><span class="line">learning_rate=<span class="number">1e-2</span></span><br><span class="line">optimizer=torch.optim.SGD(tudui.parameters(),lr=learning_rate)</span><br><span class="line"></span><br><span class="line"><span class="comment">#设置训练网络的一些参数</span></span><br><span class="line">total_train_step=<span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#记录测试的次数</span></span><br><span class="line">total_test_step=<span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#训练次数</span></span><br><span class="line">epoch=<span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#添加tensorboard</span></span><br><span class="line">writer=SummaryWriter(<span class="string">'../logs_train'</span>)</span><br><span class="line">strat_time=time.time()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(epoch):</span><br><span class="line">    print(<span class="string">'------第&#123;&#125;轮训练开始------'</span>.format(i+<span class="number">1</span>))</span><br><span class="line">    <span class="comment">#训练步骤开始</span></span><br><span class="line">    tudui.train()</span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> train_dataloader:</span><br><span class="line">        imgs,targets=data</span><br><span class="line">        <span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">            imgs=imgs.cuda()</span><br><span class="line">            targets=targets.cuda()</span><br><span class="line">        outputs=tudui(imgs)</span><br><span class="line">        loss=loss_fn(outputs,targets)</span><br><span class="line">        <span class="comment">#优化器优化模型</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        total_train_step+=<span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> total_train_step%<span class="number">100</span>==<span class="number">0</span>:</span><br><span class="line">            end_time = time.time()</span><br><span class="line">            print(end_time-strat_time)</span><br><span class="line">            print(<span class="string">'训练次数：&#123;&#125;,Loss:&#123;&#125;'</span>.format(total_train_step,loss.item()))</span><br><span class="line">            writer.add_scalar(<span class="string">'train_loss'</span>,loss.item(),total_train_step)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#判断模型是否训练好：每次训练完之后在测试数据集上跑一遍，以测试数据集的损失或正确率来评估模型是否训练好</span></span><br><span class="line">    <span class="comment">#测试步骤开始</span></span><br><span class="line">    tudui.eval()</span><br><span class="line">    total_test_loss=<span class="number">0</span></span><br><span class="line">    total_accuracy=<span class="number">0</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():<span class="comment">#没有梯度调优，便于测试</span></span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> test_dataloader:</span><br><span class="line">            imgs,targets=data</span><br><span class="line">            <span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">                imgs = imgs.cuda()</span><br><span class="line">                targets = targets.cuda()</span><br><span class="line">            outputs=tudui(imgs)</span><br><span class="line">            loss=loss_fn(outputs,targets)</span><br><span class="line">            total_test_loss+=loss.item()</span><br><span class="line">            accuracy=(outputs.argmax(<span class="number">1</span>)==targets).sum()</span><br><span class="line">            total_accuracy+=accuracy</span><br><span class="line">    print(<span class="string">'整体测试集上的Loss:&#123;&#125;'</span>.format(total_test_loss))</span><br><span class="line">    print(<span class="string">'整体测试集上的正确率：&#123;&#125;'</span>.format(total_accuracy/test_data_size))</span><br><span class="line">    writer.add_scalar(<span class="string">'test_loss'</span>,total_test_loss,total_test_step)</span><br><span class="line">    writer.add_scalar(<span class="string">'test_accuracy'</span>,total_accuracy/test_data_size,total_test_step)</span><br><span class="line">    total_test_step+=<span class="number">1</span></span><br><span class="line"></span><br><span class="line">    torch.save(tudui,<span class="string">'tudui_&#123;&#125;.pth'</span>.format(i))</span><br><span class="line">    <span class="comment">#torch.save(tudui,'tudui_&#123;&#125;.pth'.format(i))#方式二</span></span><br><span class="line">    print(<span class="string">'模型已保存'</span>)</span><br><span class="line">writer.close()</span><br></pre></td></tr></table></div></figure>
<p>方式二</p>
<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#定义了训练的设备</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"></span><br><span class="line"><span class="comment">#定义训练的设备</span></span><br><span class="line">device=torch.device(<span class="string">'cuda'</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">'cpu'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#准备数据集</span></span><br><span class="line">train_data=torchvision.datasets.CIFAR10(root=<span class="string">'../dataset'</span>,train=<span class="literal">True</span>,transform=torchvision.transforms.ToTensor(),</span><br><span class="line">                                        download=<span class="literal">True</span>)</span><br><span class="line">test_data=torchvision.datasets.CIFAR10(root=<span class="string">'../dataset'</span>,train=<span class="literal">False</span>,transform=torchvision.transforms.ToTensor(),</span><br><span class="line">                                       download=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#length长度</span></span><br><span class="line">train_data_size=len(train_data)</span><br><span class="line">test_data_size=len(test_data)</span><br><span class="line"><span class="comment">#如果train_data_size=10，训练数据集的长度为：10</span></span><br><span class="line"><span class="comment">#ctrl+d可以复制当前行</span></span><br><span class="line">print(<span class="string">'训练数据集长度为：&#123;&#125;'</span>.format(train_data_size))</span><br><span class="line">print(<span class="string">'测试数据集长度为：&#123;&#125;'</span>.format(test_data_size))</span><br><span class="line"></span><br><span class="line"><span class="comment">#利用dataloader来加载数据集</span></span><br><span class="line">train_dataloader=DataLoader(dataset=train_data,batch_size=<span class="number">64</span>)</span><br><span class="line">test_dataloader=DataLoader(dataset=test_data,batch_size=<span class="number">64</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#搭建神经网络</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Tudui</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(Tudui, self).__init__()</span><br><span class="line">        self.model=nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">3</span>,<span class="number">32</span>,<span class="number">5</span>,<span class="number">1</span>,<span class="number">2</span>),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">32</span>,<span class="number">32</span>,<span class="number">5</span>,<span class="number">1</span>,<span class="number">2</span>),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">32</span>,<span class="number">64</span>,<span class="number">5</span>,<span class="number">1</span>,<span class="number">2</span>),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            nn.Flatten(),</span><br><span class="line">            nn.Linear(<span class="number">64</span>*<span class="number">4</span>*<span class="number">4</span>,<span class="number">64</span>),</span><br><span class="line">            nn.Linear(<span class="number">64</span>,<span class="number">10</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self,x)</span>:</span></span><br><span class="line">        x=self.model(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"><span class="comment">#创建网络模型</span></span><br><span class="line">tudui=Tudui()</span><br><span class="line">tudui=tudui.to(device)</span><br><span class="line"></span><br><span class="line"><span class="comment">#损失函数</span></span><br><span class="line">loss_fn=nn.CrossEntropyLoss()</span><br><span class="line">loss_fn=loss_fn.to(device)</span><br><span class="line"></span><br><span class="line"><span class="comment">#优化器</span></span><br><span class="line"><span class="comment">#learning_rate=0.01</span></span><br><span class="line"><span class="comment">#1e-2=1*10^(-2)=1/100=0.01</span></span><br><span class="line">learning_rate=<span class="number">1e-2</span></span><br><span class="line">optimizer=torch.optim.SGD(tudui.parameters(),lr=learning_rate)</span><br><span class="line"></span><br><span class="line"><span class="comment">#设置训练网络的一些参数</span></span><br><span class="line">total_train_step=<span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#记录测试的次数</span></span><br><span class="line">total_test_step=<span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#训练次数</span></span><br><span class="line">epoch=<span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#添加tensorboard</span></span><br><span class="line">writer=SummaryWriter(<span class="string">'../logs_train'</span>)</span><br><span class="line">strat_time=time.time()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(epoch):</span><br><span class="line">    print(<span class="string">'------第&#123;&#125;轮训练开始------'</span>.format(i+<span class="number">1</span>))</span><br><span class="line">    <span class="comment">#训练步骤开始</span></span><br><span class="line">    tudui.train()</span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> train_dataloader:</span><br><span class="line">        imgs,targets=data</span><br><span class="line">        imgs=imgs.to(device)</span><br><span class="line">        targets=targets.to(device)</span><br><span class="line">        outputs=tudui(imgs)</span><br><span class="line">        loss=loss_fn(outputs,targets)</span><br><span class="line">        <span class="comment">#优化器优化模型</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        total_train_step+=<span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> total_train_step%<span class="number">100</span>==<span class="number">0</span>:</span><br><span class="line">            end_time = time.time()</span><br><span class="line">            print(end_time-strat_time)</span><br><span class="line">            print(<span class="string">'训练次数：&#123;&#125;,Loss:&#123;&#125;'</span>.format(total_train_step,loss.item()))</span><br><span class="line">            writer.add_scalar(<span class="string">'train_loss'</span>,loss.item(),total_train_step)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#判断模型是否训练好：每次训练完之后在测试数据集上跑一遍，以测试数据集的损失或正确率来评估模型是否训练好</span></span><br><span class="line">    <span class="comment">#测试步骤开始</span></span><br><span class="line">    tudui.eval()</span><br><span class="line">    total_test_loss=<span class="number">0</span></span><br><span class="line">    total_accuracy=<span class="number">0</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():<span class="comment">#没有梯度调优，便于测试</span></span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> test_dataloader:</span><br><span class="line">            imgs,targets=data</span><br><span class="line">            imgs = imgs.to(device)</span><br><span class="line">            targets = targets.to(device)</span><br><span class="line">            outputs=tudui(imgs)</span><br><span class="line">            loss=loss_fn(outputs,targets)</span><br><span class="line">            total_test_loss+=loss.item()</span><br><span class="line">            accuracy=(outputs.argmax(<span class="number">1</span>)==targets).sum()</span><br><span class="line">            total_accuracy+=accuracy</span><br><span class="line">    print(<span class="string">'整体测试集上的Loss:&#123;&#125;'</span>.format(total_test_loss))</span><br><span class="line">    print(<span class="string">'整体测试集上的正确率：&#123;&#125;'</span>.format(total_accuracy/test_data_size))</span><br><span class="line">    writer.add_scalar(<span class="string">'test_loss'</span>,total_test_loss,total_test_step)</span><br><span class="line">    writer.add_scalar(<span class="string">'test_accuracy'</span>,total_accuracy/test_data_size,total_test_step)</span><br><span class="line">    total_test_step+=<span class="number">1</span></span><br><span class="line"></span><br><span class="line">    torch.save(tudui,<span class="string">'tudui_&#123;&#125;.pth'</span>.format(i))</span><br><span class="line">    <span class="comment">#torch.save(tudui,'tudui_&#123;&#125;.pth'.format(i))#方式二</span></span><br><span class="line">    print(<span class="string">'模型已保存'</span>)</span><br><span class="line">writer.close()</span><br></pre></td></tr></table></div></figure>

        <h3 id="8-完整的模型验证（测试，demo）套路">
          <a href="#8-完整的模型验证（测试，demo）套路" class="heading-link"><i class="fas fa-link"></i></a><a href="#8-完整的模型验证（测试，demo）套路" class="headerlink" title="8.完整的模型验证（测试，demo）套路"></a>8.完整的模型验证（测试，demo）套路</h3>
      <p>利用已经训练好的模型，然后给它提供输入</p>
<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line">image_path=<span class="string">'../images/QQ图片201802031008421.jpg'</span></span><br><span class="line">image=Image.open(image_path)<span class="comment">#PIL类型</span></span><br><span class="line">print(image)</span><br><span class="line"><span class="comment">#因为png格式是四个通道，除了RGB三通道外，还有一个透明度通道。所以，外面调用下述代码，保留其颜色通道</span></span><br><span class="line"><span class="comment">#当然，如果图片本来就是三个颜色通道，经过此操作，不变。加上这一步后，可以适应png jpg各种格式的图片</span></span><br><span class="line">image=image.convert(<span class="string">'RGB'</span>)</span><br><span class="line">transform=torchvision.transforms.Compose([torchvision.transforms.Resize((<span class="number">32</span>,<span class="number">32</span>)),</span><br><span class="line">                                          torchvision.transforms.ToTensor()])</span><br><span class="line">image=transform(image)</span><br><span class="line">print(image.shape)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Tudui</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(Tudui, self).__init__()</span><br><span class="line">        self.model=nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">3</span>,<span class="number">32</span>,<span class="number">5</span>,<span class="number">1</span>,<span class="number">2</span>),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">32</span>,<span class="number">32</span>,<span class="number">5</span>,<span class="number">1</span>,<span class="number">2</span>),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">32</span>,<span class="number">64</span>,<span class="number">5</span>,<span class="number">1</span>,<span class="number">2</span>),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            nn.Flatten(),</span><br><span class="line">            nn.Linear(<span class="number">64</span>*<span class="number">4</span>*<span class="number">4</span>,<span class="number">64</span>),</span><br><span class="line">            nn.Linear(<span class="number">64</span>,<span class="number">10</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self,x)</span>:</span></span><br><span class="line">        x=self.model(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">model=torch.load(<span class="string">'tudui_0.pth'</span>,map_location=torch.device(<span class="string">'cpu'</span>))</span><br><span class="line">print(model)</span><br><span class="line">image=torch.reshape(image,(<span class="number">1</span>,<span class="number">3</span>,<span class="number">32</span>,<span class="number">32</span>))</span><br><span class="line">model.eval()</span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    output=model(image)</span><br><span class="line">print(output)</span><br><span class="line"></span><br><span class="line">print(output.argmax(<span class="number">1</span>))</span><br></pre></td></tr></table></div></figure></div><footer class="post-footer"><div class="post-ending ending"><div class="ending__text">------ END ------</div></div><div class="post-copyright copyright"><div class="copyright-author"><span class="copyright-author__name">Author: </span><span class="copyright-author__value"><a href="http://yoursite.com">Millionchan</a></span></div><div class="copyright-link"><span class="copyright-link__name">Link: </span><span class="copyright-link__value"><a href="http://yoursite.com/2022/08/24/pytorch%E5%AD%A6%E4%B9%A0/">http://yoursite.com/2022/08/24/pytorch%E5%AD%A6%E4%B9%A0/</a></span></div><div class="copyright-notice"><span class="copyright-notice__name">Copyright: </span><span class="copyright-notice__value">All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en" rel="external nofollow" target="_blank">BY-NC-SA</a> unless stating additionally</span></div></div><nav class="post-paginator paginator"><div class="paginator-prev"><a class="paginator-prev__link" href="/2022/09/05/Machine%20Learning%20for%20Semiconductors/"><span class="paginator-prev__icon"><i class="fas fa-angle-left"></i></span><span class="paginator-prev__text">Machine Learning for Semiconductors</span></a></div><div class="paginator-next"><a class="paginator-next__link" href="/2022/07/07/pytorch%E7%8E%AF%E5%A2%83%E7%9A%84%E9%85%8D%E7%BD%AE%E4%B8%8E%E5%AE%89%E8%A3%85/"><span class="paginator-prev__text">pytorch环境的配置与安装</span><span class="paginator-next__icon"><i class="fas fa-angle-right"></i></span></a></div></nav></footer></div></div></div><div class="sidebar-wrap" id="sidebar-wrap"><aside class="sidebar" id="sidebar"><div class="sidebar-nav"><span class="sidebar-nav-toc current">Catalog</span><span class="sidebar-nav-ov">Overview</span></div><section class="sidebar-toc"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-Tensorboard"><span class="toc-number">1.</span> <span class="toc-text">
          1. Tensorboard</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-Transforms"><span class="toc-number">2.</span> <span class="toc-text">
          2. Transforms</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-torchvision中的数据集使用"><span class="toc-number">3.</span> <span class="toc-text">
          3.torchvision中的数据集使用</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-DataLoader的使用"><span class="toc-number">4.</span> <span class="toc-text">
          4.DataLoader的使用</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-神经网络"><span class="toc-number">5.</span> <span class="toc-text">
          5.神经网络</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-完整的模型训练套路"><span class="toc-number">6.</span> <span class="toc-text">
          6.完整的模型训练套路</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-利用GPU训练"><span class="toc-number">7.</span> <span class="toc-text">
          7.利用GPU训练</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-完整的模型验证（测试，demo）套路"><span class="toc-number">8.</span> <span class="toc-text">
          8.完整的模型验证（测试，demo）套路</span></a></li></ol></section><!-- ov = overview--><section class="sidebar-ov hide"><div class="sidebar-ov-author"><div class="sidebar-ov-author__avatar"><img class="sidebar-ov-author__avatar_img" src="/images/icons/stun-logo.svg" alt="avatar"></div><p class="sidebar-ov-author__text">hello world</p></div><div class="sidebar-ov-state"><a class="sidebar-ov-state-item sidebar-ov-state-item--posts" href="/archives/"><div class="sidebar-ov-state-item__count">20</div><div class="sidebar-ov-state-item__name">Archives</div></a></div><div class="sidebar-ov-cc"><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en" target="_blank" rel="noopener" data-popover="Creative Commons" data-popover-pos="up"><img src="/images/cc-by-nc-sa.svg"></a></div></section><div class="sidebar-reading"><div class="sidebar-reading-info"><span class="sidebar-reading-info__text">You have read </span><span class="sidebar-reading-info__num">0</span><span class="sidebar-reading-info__perc">%</span></div><div class="sidebar-reading-line"></div></div></aside></div><div class="clearfix"></div></div></main><footer class="footer" id="footer"><div class="footer-inner"><div><span>Copyright © 2023</span><span class="footer__icon"><i class="fas fa-heart"></i></span><span>Millionchan</span></div><div><span>Powered by <a href="http://hexo.io/" title="Hexo" target="_blank" rel="noopener">Hexo</a></span><span> v4.2.1</span><span class="footer__devider">|</span><span>Theme - <a href="https://github.com/liuyib/hexo-theme-stun/" title="Stun" target="_blank" rel="noopener">Stun</a></span><span> v2.6.2</span></div></div></footer><div class="loading-bar" id="loading-bar"><div class="loading-bar__progress"></div></div><div class="back2top" id="back2top"><span class="back2top__icon"><i class="fas fa-rocket"></i></span></div></div><script src="https://cdn.jsdelivr.net/npm/jquery@v3.4.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.2/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.2/velocity.ui.min.js"></script><script src="/js/utils.js?v=2.6.2"></script><script src="/js/stun-boot.js?v=2.6.2"></script><script src="/js/scroll.js?v=2.6.2"></script><script src="/js/header.js?v=2.6.2"></script><script src="/js/sidebar.js?v=2.6.2"></script></body></html>