<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black"><link rel="icon" href="/images/icons/favicon-16x16.png?v=2.6.2" type="image/png" sizes="16x16"><link rel="icon" href="/images/icons/favicon-32x32.png?v=2.6.2" type="image/png" sizes="32x32"><meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Millionchan">
<meta name="twitter:card" content="summary"><title>Hexo</title><link ref="canonical" href="http://yoursite.com/index.html"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.12.1/css/all.min.css" type="text/css"><link rel="stylesheet" href="/css/index.css?v=2.6.2"><script>var Stun = window.Stun || {};
var CONFIG = {
  root: '/',
  algolia: undefined,
  assistSearch: undefined,
  fontIcon: {"prompt":{"success":"fas fa-check-circle","info":"fas fa-arrow-circle-right","warning":"fas fa-exclamation-circle","error":"fas fa-times-circle"},"copyBtn":"fas fa-copy"},
  sidebar: {"offsetTop":"20px","tocMaxDepth":6},
  header: {"enable":true,"showOnPost":true,"scrollDownIcon":false},
  postWidget: {"endText":true},
  nightMode: {"enable":true},
  back2top: {"enable":true},
  codeblock: {"style":"default","highlight":"light","wordWrap":false},
  reward: false,
  fancybox: false,
  zoomImage: {"gapAside":"20px"},
  galleryWaterfall: undefined,
  lazyload: false,
  pjax: undefined,
  externalLink: {"icon":{"enable":true,"name":"fas fa-external-link-alt"}},
  shortcuts: undefined,
  prompt: {"copyButton":"Copy","copySuccess":"Copy Success","copyError":"Copy Error"},
  sourcePath: {"js":"js","css":"css","images":"images"},
};

window.CONFIG = CONFIG;</script><meta name="generator" content="Hexo 4.2.1"></head><body><div class="container" id="container"><header class="header" id="header"><div class="header-inner"><nav class="header-nav header-nav--fixed"><div class="header-nav-inner"><div class="header-nav-menubtn"><i class="fas fa-bars"></i></div><div class="header-nav-menu"><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/"><span class="header-nav-menu-item__icon"><i class="fas fa-home"></i></span><span class="header-nav-menu-item__text">Home</span></a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/archives/"><span class="header-nav-menu-item__icon"><i class="fas fa-folder-open"></i></span><span class="header-nav-menu-item__text">Archives</span></a></div></div><div class="header-nav-mode"><div class="mode"><div class="mode-track"><span class="mode-track-moon"></span><span class="mode-track-sun"></span></div><div class="mode-thumb"></div></div></div></div></nav><div class="header-banner"><div class="header-banner-info"><div class="header-banner-info__title">Hexo</div><div class="header-banner-info__subtitle"></div></div></div></div></header><main class="main" id="main"><div class="main-inner"><div class="content-wrap" id="content-wrap"><div class="content content-home" id="content"><section class="postlist"><article class="postlist-item post"><header class="post-header"><h1 class="post-title"><a class="post-title__link" href="/2023/05/11/Linux%E5%91%BD%E4%BB%A4%E4%B9%8B%E8%BF%90%E8%A1%8C.sh%E6%96%87%E4%BB%B6/">Linux命令之运行.sh文件</a></h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">Created</span><span class="post-meta-item__value">2023-05-11</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">Updated</span><span class="post-meta-item__value">2023-05-11</span></span></div></header><div class="post-body"><div class="post-excerpt"><ol>
<li>运行.sh文件<ul>
<li>使用sh test.sh执行<ul>
<li>使用 sh test.sh 来执行script文件，该方法标明使用 sh 这种shell来执行test.sh文件，sh已经是一种被bash替代的shell.</li>
</ul>
</li>
<li>使用bash test.sh 执行<ul>
<li>该方法其实与 sh test.sh 的原理一样，只是使用了 /bin/bash 该种shell来执行我们的脚本文件。所以，其实使用 dash test.sh’ 也是可以的，只是取决于自己想使用那种shell来执行脚本，但sh、bash、dash三者有些许差别，对于部分关键字如 let，bash支持，而sh和dash并不支持，对于部分关键字则选择使用bash。</li>
</ul>
</li>
<li>使用点.执行<ul>
<li>该种方式使用之前必须为文件添加执行的权限：chmod +x test.sh</li>
<li>.和source是同一个命令，可以理解为source的缩写，简称点命令。</li>
<li>添加完执行权限之后，便可以使用 ./test.sh 来执行脚本，该方式与 bash test.sh 是一样的 ，默认使用 bin/bash 来执行我们的脚本。只有该种执行方式需要对文件添加执行权限，其他方式并不需要。</li>
</ul>
</li>
<li>使用source执行<ul>
<li>使用source则也能够直接执行我们的脚本：source test.sh</li>
</ul>
</li>
<li>区别<ul>
<li>当我们使用 sh test.sh 、bash test.sh 、 ./test.sh 执行脚本的时候，该test.sh运行脚本都会使用一个新的shell环境来执行脚本内的命令，也就是说，使用这3种方式时，其实script是在子进程的shell内执行，当子进程完成后，子进程内的各项变量和操作将会结束而不会传回到父进程中。</li>
<li>source方法执行脚本是在父进程中执行的，test.sh的各项操作都会在原本的shell内生效</li>
</ul>
</li>
<li>./sh 文件开头***的含义：<ul>
<li>#!/bin/sh　　　　         以下的代码由/bin/sh 来解释</li>
<li>#!/bin/bash　　　　       以bash shell来解释</li>
<li>#!/bin/csh　　　　        以csh shell来解释</li>
<li>#!/usr/bin/env python　　以下代码由python来解释 </li>
<li>#! 是一个约定的标记，它告诉系统这个脚本需要什么解释器来执行，即使用哪<br>一种 Shell</li>
</ul>
</li>
</ul>
</li>
<li>编写.sh文件<ul>
<li>定义变量：变量名不加美元符号(注意：变量名和等号之间不能有空格)，不需要对变量进行声明</li>
<li>使用变量：使用一个定义过的变量，只要在变量名前面加美元符号即可   <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Num=<span class="number">1</span></span><br><span class="line">Var2=<span class="string">"hello world!"</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#!/bin/sh</span></span><br><span class="line">a=<span class="string">"hello world!"</span></span><br><span class="line">num=<span class="number">2</span></span><br><span class="line">echo <span class="string">"a is : $a num is : $&#123;num&#125;nd"</span></span><br><span class="line"><span class="comment">#说明：变量名外面的花括号是可选的，加不加都行，加花括号是为了帮助解释器识别变量的边界，我们通常加花括号。</span></span><br><span class="line"><span class="comment">#运行结果a is : hello world! num is : 2nd</span></span><br></pre></td></tr></table></div></figure>
<ul>
<li>传递参数<ul>
<li>我们可以在执行 Shell 脚本时，向脚本传递参数，脚本内获取参数的格式为：n。n代表一个数字，1为执行脚本的第一个参数，2为执行脚本的第二个参数，以此类推……</li>
<li>值得注意的是，0 获取到的是脚本路径以及脚本名，后面按顺序获取参数，当参数超过10个时(包括10 个)，需要使用10,{11}….才能获取到参数，但是一般很少会超过10 个参数的情况。<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">    <span class="comment">#建立脚本文件test.sh</span></span><br><span class="line">    <span class="comment">#!/bin/bash</span></span><br><span class="line">    echo <span class="string">"脚本$0"</span></span><br><span class="line">    echo <span class="string">"第一个参数$1"</span></span><br><span class="line">    echo <span class="string">"第二个参数$2"</span></span><br><span class="line">    <span class="comment">#调用的时候就可以：sh test.sh 2 3</span></span><br><span class="line">    <span class="string">'''输出：脚本 test.sh</span></span><br><span class="line"><span class="string">    第一个参数2</span></span><br><span class="line"><span class="string">    第二个参数3'''</span></span><br><span class="line">    ``` </span><br><span class="line">- echo命令：echo 用于字符串的输出，常用于观察系统变量的路径。</span><br><span class="line">  - 显示普通字符串：echo <span class="string">"learn linux"</span></span><br><span class="line">  - 显示系统库路径：echo $PATH PATH 就是一个系统变量，与windonws 下的环境变量相同，存储默认库的搜索路径</span><br><span class="line">- shell脚本文件遍历目录</span><br><span class="line">    ```python</span><br><span class="line">    <span class="comment">#问题：文件夹 /tmp 遍历</span></span><br><span class="line">    <span class="comment">#!/bin/bash</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> /tmp/*</span><br><span class="line">    do</span><br><span class="line">    　　echo <span class="string">"Hello, $i"</span></span><br><span class="line">    done</span><br></pre></td></tr></table></div></figure></li>
</ul>
</li>
<li>环境变量：由export关键字处理过的变量叫做环境变量。我们不对环境变量进行讨论，因为通常情况下仅仅在登录脚本中使用环境变量。<ul>
<li>如果你要在某个环境变量（比如PATH）中加入一些新的路径（如/bin/bash），可以使用如下命令格式<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export PATH=/bin/bash:$PATH</span><br></pre></td></tr></table></div></figure>
<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#列出所有的shell赋予程序的环境变量</span></span><br><span class="line">export -p</span><br></pre></td></tr></table></div></figure></li>
<li>一般在执行脚本程序前，都要先设置一下自己要用到的环境变量，再跑自己的程序脚本</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>module常见命令 <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">module help       <span class="comment"># 显示帮助信息</span></span><br><span class="line">module avail      <span class="comment"># 显示已经安装的软件环境</span></span><br><span class="line">module avail matlab<span class="comment">#module avail matlab</span></span><br><span class="line">module load       <span class="comment"># 导入相应的软件环境</span></span><br><span class="line">module unload     <span class="comment"># 删除相应的软件环境</span></span><br><span class="line">module list       <span class="comment"># 列出已经导入的软件环境</span></span><br><span class="line">module purge      <span class="comment"># 清除所有已经导入的软件环境</span></span><br><span class="line">module switch [mod1] mod2 <span class="comment"># 删除mod1并导入mod2</span></span><br></pre></td></tr></table></div></figure></li>
<li>conda常见命令 <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">conda info -e     <span class="comment"># 查看已有的conda环境；</span></span><br><span class="line">source activate env_name        <span class="comment"># 进入指定的conda环境；</span></span><br><span class="line">conda deactivate  <span class="comment"># 退出当前的conda环境；</span></span><br><span class="line">conda create -n env_name [python=&lt;version&gt;] <span class="comment"># 创建环境，并指定python版本，或者安装包等；</span></span><br><span class="line">conda remove -n env_name --all  <span class="comment"># 删除指定环境；</span></span><br><span class="line">conda list [-n env_name] <span class="comment"># 查看当前环境(指定环境)下安装的包；</span></span><br><span class="line">conda search pkg_name    <span class="comment"># 查看安装包；</span></span><br><span class="line">conda update pkg_name    <span class="comment"># 更新指定的安装包；</span></span><br><span class="line">conda remove pkg_name    <span class="comment"># 卸载指定的安装包</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#用conda创建一个python环境</span></span><br><span class="line"><span class="comment"># 创建时可以指定Python版本，不指定的话会使用默认的版本(miniconda自带的Python版本)；</span></span><br><span class="line">conda create -n TensorFlow<span class="number">-1.14</span><span class="number">.0</span> -y</span><br><span class="line"></span><br><span class="line"><span class="comment"># 进入上一步创建好的环境;</span></span><br><span class="line">source activate TensorFlow<span class="number">-1.14</span><span class="number">.0</span> </span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装相应的库；</span></span><br><span class="line">conda install tensorflow-gpu=<span class="number">1.14</span><span class="number">.0</span> <span class="comment"># 根据自己的需要安装相应的库；</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装pip并使用pip安装 python 库；</span></span><br><span class="line">conda install pip     <span class="comment"># 环境中需要先安装pip</span></span><br><span class="line">pip install numpy     <span class="comment"># 根据自己的需要安装相应的库</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 退出当前的虚拟环境；</span></span><br><span class="line">conda deactivate</span><br></pre></td></tr></table></div></figure></li>
<li>pytorch<ul>
<li>PyTorch是一个开源的Python机器学习库，基于Torch，用于自然语言处理等应用程序。</li>
<li>安装<ul>
<li>导入conda环境<ul>
<li>在自己的HOME目录安装conda或者通过module导入conda环境</li>
</ul>
</li>
<li>创建虚拟环境并安装pytorch，这里安装1.6.0版本 <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda create -n pytorch<span class="number">-1.6</span><span class="number">.0</span> pytorch=<span class="number">1.6</span><span class="number">.0</span> torchvision cudatoolkit=<span class="number">10.1</span> -c pytorch</span><br></pre></td></tr></table></div></figure></li>
<li>进入和退出创建好的虚拟环境 <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">source activate pytorch<span class="number">-1.6</span><span class="number">.0</span></span><br><span class="line">conda deactivate</span><br></pre></td></tr></table></div></figure></li>
</ul>
</li>
<li>提交作业<ul>
<li>创建工作目录并进入 <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkdir pytorchJob1</span><br><span class="line">cd pytorchJob1</span><br></pre></td></tr></table></div></figure>
<ul>
<li>将运行pytorch需要的相关文件上传到该文件夹下，这里创建一个简单的test.py程序，用于检测GPU是否可用<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">print(torch.cuda.is_available())</span><br><span class="line">torch.zeros(<span class="number">1</span>).cuda()</span><br></pre></td></tr></table></div></figure></li>
<li>在该文件夹下编写作业脚本，命名为pytorchJob1.sh，脚本内容如下<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/bin/bash</span></span><br><span class="line"><span class="comment">#SBATCH -o job.%j.out</span></span><br><span class="line"><span class="comment">#SBATCH --partition=GPU</span></span><br><span class="line"><span class="comment">#SBATCH -J pytorch_job_1</span></span><br><span class="line"><span class="comment">#SBATCH -N 1</span></span><br><span class="line"><span class="comment">#SBATCH --ntasks-per-node=2</span></span><br><span class="line"><span class="comment">#SBATCH --gres=gpu:1</span></span><br><span class="line"><span class="comment">#SBATCH --qos=low</span></span><br><span class="line"></span><br><span class="line">source activate pytorch<span class="number">-1.6</span><span class="number">.0</span></span><br><span class="line">python test.py</span><br></pre></td></tr></table></div></figure></li>
<li>提交作业<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbatch pytorchJob1.sh</span><br></pre></td></tr></table></div></figure></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>编写示例<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/bin/bash</span></span><br><span class="line"><span class="comment"># 导入MPI运行环境</span></span><br><span class="line">module load intel/<span class="number">2017.1</span></span><br><span class="line"><span class="comment"># 导入MPI应用程序</span></span><br><span class="line">module load vasp/<span class="number">5.4</span><span class="number">.4</span>-intel<span class="number">-2017.1</span></span><br><span class="line">source /public/software/profile.d/compiler_intel-compiler<span class="number">-2017.5</span><span class="number">.239</span>.sh //加载intel编译器</span><br><span class="line">source /public/software/profile.d/mpi_intelmpi<span class="number">-2017.4</span><span class="number">.239</span>.sh //加载mpi</span><br><span class="line"><span class="comment">#export PATH=/public/software/apps/lammps/intelmpi/14May16/lmp_intelmpi:$&#123;PATH&#125; //加载并行LAMMPS可执行程序的地址</span></span><br><span class="line">mpirun -np <span class="number">90</span> /data/home/***/lammps<span class="number">-29</span>Oct20/build/lmp_mpi &lt; <span class="keyword">in</span>.*** //运行自己的<span class="keyword">in</span>文件</span><br></pre></td></tr></table></div></figure></li>
<li>提交作业<figure class="highlight plain"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sbatch --gpus&#x3D;n xxx.sh</span><br><span class="line">n为要使用的gpu数量，xxx.sh</span><br><span class="line">为要执行的script</span><br></pre></td></tr></table></div></figure></li>
<li>查看作业队列<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#显示队列中所有的作业</span></span><br><span class="line">sequeue</span><br><span class="line"><span class="comment">#在队列中显示自己的作业</span></span><br><span class="line"><span class="comment"># 注意whoami前后不是单引号</span></span><br><span class="line">squeue -u `whoami`</span><br></pre></td></tr></table></div></figure></li>
<li>查看作业信息<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#查看作业7454119的详细信息</span></span><br><span class="line">scontrol show job <span class="number">7454119</span> <span class="comment">#只能显示正在运行或者刚结束没多久的作业信息</span></span><br><span class="line"><span class="comment">#通过sacct查询已经结束作业的相关信息</span></span><br><span class="line">sacct -j <span class="number">7454119</span></span><br><span class="line"><span class="comment">#通过sacct按照指定格式输出作业信息。指定输出内容为：作业号，作业名，分区，运行节点，申请核数，状态，作业结束时间</span></span><br><span class="line">format=jobid,jobname,partition,nodelist,alloccpus,state,end </span><br><span class="line">sacct --format=$format -j <span class="number">7454119</span></span><br></pre></td></tr></table></div></figure></li>
<li>取消队列中已提交的作业<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 取消作业ID为123的作业</span></span><br><span class="line">scancel <span class="number">123</span></span><br><span class="line"><span class="comment">#取消自己上机上号上所有作业</span></span><br><span class="line"><span class="comment"># 注意whoami前后不是单引号</span></span><br><span class="line">scancel -u `whoami`</span><br><span class="line"><span class="comment">#取消自己上机账号上所有状态为PENDING的作业</span></span><br><span class="line">scancel -t PENDING -u `whoami`</span><br></pre></td></tr></table></div></figure>
参考：<br><span class="exturl"><a class="exturl__link" href="https://www.cnblogs.com/carle-09/p/12582209.html" target="_blank" rel="noopener">https://www.cnblogs.com/carle-09/p/12582209.html</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span><br><span class="exturl"><a class="exturl__link" href="https://hpc.pku.edu.cn/_book/guide/faq.html" target="_blank" rel="noopener">https://hpc.pku.edu.cn/_book/guide/faq.html</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></li>
</ol>
</div></div></article><article class="postlist-item post"><header class="post-header"><h1 class="post-title"><a class="post-title__link" href="/2022/10/18/sgdml%E6%A8%A1%E5%9E%8B/">sgdml模型</a></h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">Created</span><span class="post-meta-item__value">2022-10-18</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">Updated</span><span class="post-meta-item__value">2022-10-18</span></span></div></header><div class="post-body"><div class="post-excerpt">
        <h2 id="1-运行步骤">
          <a href="#1-运行步骤" class="heading-link"><i class="fas fa-link"></i></a><a href="#1-运行步骤" class="headerlink" title="1.运行步骤"></a>1.运行步骤</h2>
      <ul>
<li><span class="exturl"><a class="exturl__link" href="https://github.com/stefanch/sGDML" target="_blank" rel="noopener">参考</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span><figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''terminal'''</span></span><br><span class="line"><span class="comment">#安装</span></span><br><span class="line">pip install sgdml</span><br><span class="line"><span class="comment">#下载其中一个示例数据集</span></span><br><span class="line">sgdml-get dataset ethanol_dft</span><br><span class="line"><span class="comment">#训练力场模型</span></span><br><span class="line">sgdml all ethanol_dft.npz <span class="number">200</span> <span class="number">1000</span> <span class="number">5000</span></span><br><span class="line"><span class="string">'''代码'''</span></span><br><span class="line"><span class="comment">#查询力场</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sgdml.predict <span class="keyword">import</span> GDMLPredict</span><br><span class="line"><span class="keyword">from</span> sgdml.utils <span class="keyword">import</span> io</span><br><span class="line"></span><br><span class="line">r,_ = io.read_xyz(<span class="string">'geometries/ethanol.xyz'</span>) <span class="comment"># 9 atoms</span></span><br><span class="line">print(r.shape) <span class="comment"># (1,27)</span></span><br><span class="line"></span><br><span class="line">model = np.load(<span class="string">'models/ethanol.npz'</span>)</span><br><span class="line">gdml = GDMLPredict(model)</span><br><span class="line">e,f = gdml.predict(r)</span><br><span class="line">print(e.shape) <span class="comment"># (1,)</span></span><br><span class="line">print(f.shape) <span class="comment"># (1,27)</span></span><br></pre></td></tr></table></div></figure>

        <h2 id="2-遇到的问题">
          <a href="#2-遇到的问题" class="heading-link"><i class="fas fa-link"></i></a><a href="#2-遇到的问题" class="headerlink" title="2. 遇到的问题"></a>2. 遇到的问题</h2>
      </li>
<li>ValueError: cannot find context for ‘fork’<ul>
<li>sgdml包路径(C:\Users\dell\PycharmProjects\untitled\venv\Lib\site-packages\sgdml)下的predict.py、desc.py、train.py、perm.py四个文件中<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Pool = mp.get_context(<span class="string">'fork'</span>).Pool</span><br><span class="line"><span class="comment">#改为</span></span><br><span class="line">Pool = mp.get_context(<span class="string">'spawn'</span>).Pool</span><br></pre></td></tr></table></div></figure></li>
<li>pytorch中sgdml包路径为C:\Users\dell\Anaconda3\envs\pytorch\Lib\site-packages\sgdml</li>
</ul>
</li>
<li>Exception: You can not create multiple instances of this class. Please reuse…<ul>
<li>sgdml包目录下train.py（342行）、predict.py（312行）<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#windows不支持多进程并行，将进程数改为一个</span></span><br><span class="line">self._max_processes = (</span><br><span class="line">        min(max_processes, total_cpus) <span class="keyword">if</span> max_processes <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">else</span> total_cpus</span><br><span class="line">        <span class="comment">#改为</span></span><br><span class="line">        min(max_processes, total_cpus, <span class="number">1</span>) <span class="keyword">if</span> max_processes <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">else</span> <span class="number">1</span></span><br><span class="line">    )</span><br></pre></td></tr></table></div></figure></li>
</ul>
</li>
</ul>
</div></div></article><article class="postlist-item post"><header class="post-header"><h1 class="post-title"><a class="post-title__link" href="/2022/10/10/GDML%20and%20sGDML/">GDML and sGDML</a></h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">Created</span><span class="post-meta-item__value">2022-10-10</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">Updated</span><span class="post-meta-item__value">2022-10-11</span></span></div></header><div class="post-body"><div class="post-excerpt">
        <h2 id="梯度域机器学习GDML">
          <a href="#梯度域机器学习GDML" class="heading-link"><i class="fas fa-link"></i></a><a href="#梯度域机器学习GDML" class="headerlink" title="梯度域机器学习GDML"></a>梯度域机器学习GDML</h2>
      <ol>
<li>准确的能量保持型分子力场的机器学习Machine learning of accurate energy-conserving molecular force fields</li>
</ol>
<ul>
<li>使用有限数量的样本从从头算分子动力学（AIMD）轨迹中构建精确的分子力场</li>
<li>GDML的实现能够重现中等大小分子的全局势能面</li>
<li>GDML方法能够以明确的AIMD计算的一小部分成本对分子进行定量的分子动力学模拟，从而允许构建高效的力场，并具有高水平的非初始方法的准确性和可转移性。
        <h2 id="对称梯度域机器学习sGDML">
          <a href="#对称梯度域机器学习sGDML" class="heading-link"><i class="fas fa-link"></i></a><a href="#对称梯度域机器学习sGDML" class="headerlink" title="对称梯度域机器学习sGDML"></a>对称梯度域机器学习sGDML</h2>
      </li>
</ul>
<ol>
<li>构建具有量子化学精确性的机器学习力场:应用和化学洞察力Construction of Machine Learned Force Fields with Quantum Chemical Accuracy: Applications and Chemical Insights</li>
</ol>
<ul>
<li><p>即使只使用几百个分子构象进行训练，也能够以高精度重建复杂的高维势能面（PES）</p>
</li>
<li><p>sGDML框架的灵活性质可以捕捉到局部和非局部的电子相互作用（如H键、孤对、立体排斥、杂化状态的变化，而不会对原子间势的性质施加任何限制。</p>
</li>
<li><p>这个模型的主要特点是，它在数学上被设想为一个可分析的无曲线框架并应用了能量守恒定律。一旦sGDML被训练出来，势能函数也就可用了。该模型的第二个基本属性是，通过明确纳入分子对称性（即刚性和流动性），降低了重建过程的复杂性。对称性是通过一个多部分程序从参考数据集中自动提取的。</p>
</li>
<li><p>在这个框架中，所有的原子相互作用都是全局建模的，这意味着学习问题的解决不需要任何固有的非唯一的原子间的、成对的或任何其他的多体划分。因此，该方法保留了量子问题的多体性质。这些核心属性有助于提高sGDML模型从有限的参考计算中学习到中等大小分子的复杂PES的能力，这是其他ML方法学所不能完成的任务。</p>
</li>
<li><p>关键思想是使用高斯过程（GP）将力场建模为未知势能面</p>
</li>
<li><p>该模型的完全对称化需要对其输入的所有可能的排列组合进行求和。为了避免与大型对称组求和相关的组合挑战，我们将自己限制在物理上合理的刚性空间组和通量对称的更小的子集上，{Pq}S q=1。提取这些对称性通常需要关于所研究系统的化学和物理直觉，例如旋转障碍，这在ML环境中是不切实际的。为了使这一步骤自动化，我们采用了一个多部件匹配方案，以识别和恢复系统在训练数据集中所经历的包络转换。这是通过寻找使成本函数最小化的互换操作τ来实现的。</p>
</li>
<li><p>sGDML框架具有很高的数据效率，即使在只有几百个参考数据点的情况下，也能实现最先进的预测。</p>
</li>
<li><p>机器学习力场（ML-FFs）利用从AIMD轨迹（或任何其他采样方法）产生的分子数据集中编码的相关性来重建基本的PES，而不对原子间相互作用施加任何特定的明确分析形式。此外，机器学习是基于严格的统计学习理论[18, 19]，为FF学习提供了一个强大而通用的框架。鉴于有足够数量的数据样本（如分子能量和原子力）进行训练，ML方法可以以任意的精度重建复杂的高维对象。</p>
</li>
</ul>
<ol start="3">
<li>梯度域机器学习（GDML）的分子力场。与经典力场的比较和协同作用Molecular force fields with gradient-domain machine learning (GDML): Comparison and synergies with classical force fields</li>
<li>sGDML：利用机器学习构建准确和数据高效的分子力场sGDML: Constructing accurate and data efficient molecular force fields using machine learning</li>
</ol>
</div></div></article><article class="postlist-item post"><header class="post-header"><h1 class="post-title"><a class="post-title__link" href="/2022/10/10/Towards%20Exact%20Molecular%20Dynamics%20Simulations%20with%20Machine-Learned%20Force%20Fields/">Towards Exact Molecular Dynamics Simulations with Machine-Learned Force Fields</a></h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">Created</span><span class="post-meta-item__value">2022-10-10</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">Updated</span><span class="post-meta-item__value">2022-11-08</span></span></div></header><div class="post-body"><div class="post-excerpt"><ol>
<li>摘要</li>
</ol>
<ul>
<li>经典势是基于原子间相互作用的力学模型，无法很好地捕捉分子和材料中的关键量子效应。</li>
<li>因此通过以自动数据驱动的方式将空间和时间物理对称性结合到梯度域机器（sGDML）模型中<ul>
<li>很好的再现了量子化学CCSD（T）精度水平下的全局力场</li>
<li>降低了力场学习问题的内在复杂性，</li>
<li>首次允许使用完全量子化的电子和原子核对具有多达几十个原子的柔性分子进行聚合分子动力学模拟。</li>
</ul>
</li>
</ul>
<ol start="2">
<li>introduction</li>
</ol>
<ul>
<li>原子论建模的基石：Born-Oppenheimer（BO）近似下的分子动力学（MD）模拟</li>
<li>然而，在MD模拟中，一个十分紧迫的问题是潜在的经典原子间势的准确性不足，阻碍了分子动力学的预测建模。</li>
<li>从头算分子动力学（AIMD）模拟在每个时间步长对原子构型的量子力学力进行实时计算，可以解决准确性不足的问题。</li>
<li>但大多数AIMD模拟采用密度泛函近似（DFA）来精确求解核和电子系统的薛定谔方程。不同的DFA对分子系统的结构、动力学和性质产生不同的结果。且DFA计算无法系统地改进。</li>
<li>如用除了DFA之外相关方法则会导致所需计算资源的急剧增加，仅在相当小且刚性的分子中实际可行。</li>
<li>为了解决这一问题，并更接近真实的AIMD模拟，提出了一种使用对称梯度域机器学习（sGDML）构建力场的方法。<ul>
<li>通过数据驱动的相关空间和时间物理对称性的发现来降低问题的复杂性，</li>
<li>通过使用这些确定的对称性来增强数据样本的信息含量，</li>
<li>从而隐式地增加训练数据的量</li>
</ul>
</li>
</ul>
<ol start="3">
<li>sgdml</li>
</ol>
<ul>
<li>sGDML在GDML的基础上结合了所有相关的物理对称性（空间和时间的对称性以及给定分子的特定静态和动态对称性），从而实现了高水平的从头算力场精度的MD模拟。</li>
<li>全局空间对称性包括能量的旋转和平移不变性，而时间的均匀性意味着能量守恒。</li>
<li>提出了一种物理驱动的算法，用于从MD轨迹中发现相关的分子对称性。</li>
<li>分子动力学轨迹由几乎同构的分子图中的连续变化组成。</li>
<li>对这些轨迹采样时，难点是正确识别样本中的相同原子，</li>
<li>邻接矩阵表示分子图</li>
</ul>
</div></div></article><article class="postlist-item post"><header class="post-header"><h1 class="post-title"><a class="post-title__link" href="/2022/09/21/SQL%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B/">SQL基础教程</a></h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">Created</span><span class="post-meta-item__value">2022-09-21</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">Updated</span><span class="post-meta-item__value">2022-09-22</span></span></div></header><div class="post-body"><div class="post-excerpt"><ol>
<li><p>User表<br>user_id user_name user_age<br>1       mary      10<br>3       mary      12<br>4       alice     14<br>5       lunna     13</p>
</li>
<li><p>Select</p>
 <figure class="highlight sql"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*sql对大小写不敏感*/</span></span><br><span class="line"><span class="comment">--查询user表里面的user_name字段和user_age字段的所有数据</span></span><br><span class="line"><span class="keyword">select</span> user_name,user_age <span class="keyword">from</span> <span class="keyword">user</span></span><br><span class="line"><span class="comment">/*用*表示列的名称*/</span></span><br><span class="line"><span class="comment">--查询user表中所有的字段数据</span></span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> <span class="keyword">user</span></span><br></pre></td></tr></table></div></figure></li>
<li><p>Distinct<br>Distinct选取所有的值的时候不会出现重复的数据</p>
 <figure class="highlight sql"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">--相同的数据只会出现一次</span></span><br><span class="line"><span class="keyword">select</span> <span class="keyword">distinct</span> user_name,user_age <span class="keyword">from</span> <span class="keyword">user</span></span><br></pre></td></tr></table></div></figure></li>
<li><p>Where</p>
 <figure class="highlight sql"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">--查询user_id等于1的数据</span></span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> <span class="keyword">user</span> <span class="keyword">where</span> user_id=<span class="number">1</span></span><br><span class="line"><span class="comment">--查询user_age大于等于12的数据</span></span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> <span class="keyword">user</span> <span class="keyword">where</span> user_age&gt;=<span class="number">12</span></span><br><span class="line"><span class="comment">--查询user_age不等于12的数据</span></span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> <span class="keyword">user</span> <span class="keyword">where</span> user_age&lt;&gt;<span class="number">12</span></span><br></pre></td></tr></table></div></figure></li>
<li><p>AND和OR<br>and和or在where子语句中把两个或多个条件结合起来。如果需要两个条件都成立用and，如果只需要其中一个条件成立就用or</p>
 <figure class="highlight sql"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">--SQL使用单引号来环绕文本值，如果是数值则不需要引号</span></span><br><span class="line"><span class="comment">--查询名字为mary且12岁的数据</span></span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> <span class="keyword">user</span> <span class="keyword">where</span> user_name=<span class="string">'mary'</span> <span class="keyword">and</span> user_age=<span class="number">12</span></span><br><span class="line"><span class="comment">--查询名字为mary或年龄为13岁的数据</span></span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> <span class="keyword">user</span> <span class="keyword">where</span> user_name=<span class="string">'mary'</span> <span class="keyword">or</span> user_age=<span class="number">13</span></span><br><span class="line"><span class="comment">/*结合and和or使用圆括号来组成复杂的表达式*/</span></span><br><span class="line"><span class="comment">--查询名字为mary且12岁或年龄为13岁的数据</span></span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> <span class="keyword">user</span> <span class="keyword">where</span> (user_name=<span class="string">'mary'</span> <span class="keyword">and</span> user_age=<span class="number">12</span>) <span class="keyword">or</span> (user_age=<span class="number">13</span>)</span><br></pre></td></tr></table></div></figure></li>
<li><p>Order by</p>
 <figure class="highlight sql"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">--对指定列进行升序排列</span></span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> <span class="keyword">user</span> <span class="keyword">order</span> <span class="keyword">by</span> user_name</span><br><span class="line"><span class="comment">--按照user_id逆序排列</span></span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> <span class="keyword">user</span> <span class="keyword">order</span> <span class="keyword">by</span> user_id <span class="keyword">desc</span></span><br><span class="line"><span class="comment">--按照升序排列user_id，逆序排列user_age</span></span><br><span class="line"><span class="comment">/*先对结果按照user_id升序排列，对id相同的结果再进行user_age的降序排列，前面的条件优先级更高*/</span></span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> <span class="keyword">user</span> <span class="keyword">order</span> <span class="keyword">by</span> <span class="keyword">user</span> user_id <span class="keyword">asc</span>,user_age <span class="keyword">desc</span></span><br></pre></td></tr></table></div></figure></li>
<li><p>Insert</p>
 <figure class="highlight sql"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*如果每一项都有插入的话就不需要在前面列出列名*/</span></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> <span class="keyword">user</span> <span class="keyword">values</span>(<span class="number">2</span>,<span class="string">'tom'</span>,<span class="number">12</span>)</span><br><span class="line"><span class="comment">--新插入一行数据，只要求user_name为eva</span></span><br><span class="line"><span class="comment">/*因为id设置为自增，所以user_id不为null*/</span></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> <span class="keyword">user</span>(user_name) <span class="keyword">values</span>(<span class="string">'eva'</span>)</span><br></pre></td></tr></table></div></figure></li>
<li><p>Update</p>
 <figure class="highlight sql"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">--修改user_id为1的数据user_name为ann，user_age为11</span></span><br><span class="line"><span class="keyword">update</span> <span class="keyword">user</span> <span class="keyword">set</span> user_name=<span class="string">'ann'</span>,user_age=<span class="number">11</span> <span class="keyword">where</span> user_id=<span class="number">1</span></span><br></pre></td></tr></table></div></figure></li>
<li><p>Delete</p>
 <figure class="highlight sql"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">--删除user_age为12的数据</span></span><br><span class="line"><span class="keyword">delete</span> <span class="keyword">from</span> <span class="keyword">user</span> <span class="keyword">where</span> user_age=<span class="number">12</span></span><br><span class="line"><span class="comment">--删除表中的所有数据</span></span><br><span class="line"><span class="keyword">delete</span> <span class="keyword">from</span> <span class="keyword">user</span></span><br></pre></td></tr></table></div></figure></li>
<li><p>Top<br>top子句用于返回要返回的记录的数目，但并不是所有的数据库都支持top子句</p>
<figure class="highlight sql"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">--查询前五名用户的信息</span></span><br><span class="line"><span class="keyword">select</span> top5* <span class="keyword">from</span> <span class="keyword">user</span></span><br></pre></td></tr></table></div></figure></li>
<li><p>Like</p>
<figure class="highlight sql"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">--找出以li开头的数据</span></span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> <span class="keyword">user</span> <span class="keyword">where</span> user_name <span class="keyword">like</span> <span class="string">'li%'</span></span><br><span class="line"><span class="comment">--找出以ry结尾的数据</span></span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> <span class="keyword">user</span> <span class="keyword">where</span> user_name <span class="keyword">like</span> <span class="string">'%ry'</span></span><br><span class="line"><span class="comment">--找出含a的数据</span></span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> <span class="keyword">user</span> <span class="keyword">where</span> user_name <span class="keyword">like</span> <span class="string">'%a%'</span></span><br><span class="line"><span class="comment">--找出第二个字母是a，第四个字母是y的数据</span></span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> <span class="keyword">user</span> <span class="keyword">where</span> user_name <span class="keyword">like</span> <span class="string">'_a_y'</span></span><br></pre></td></tr></table></div></figure></li>
<li><p>通配符<br>在搜索数据库中的数据的时候SQL通配符可以替代一个或多个字符。SQL通配符必须与like运算符一起使用</p>
<ul>
<li>_替代一个字符</li>
<li>%替代一个或多个字符</li>
<li>[]字符列中的任意一个单字符  <figure class="highlight sql"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">--找出以a或者l开头的数据</span></span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> <span class="keyword">user</span> <span class="keyword">where</span> user_name <span class="keyword">like</span> <span class="string">'[al]%'</span></span><br><span class="line"><span class="comment">--找出不是a或者l开头的数据</span></span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> <span class="keyword">user</span> <span class="keyword">where</span> user_name <span class="keyword">like</span> <span class="string">'[!al]%'</span></span><br></pre></td></tr></table></div></figure></li>
</ul>
</li>
<li><p>In<br>只要数据满足in里面的一个条件就可以了</p>
<figure class="highlight sql"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">--找到user_age是12或者13的数据</span></span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> <span class="keyword">user</span> <span class="keyword">where</span> user_age <span class="keyword">in</span>(<span class="number">12</span>,<span class="number">13</span>)</span><br></pre></td></tr></table></div></figure></li>
<li><p>between<br>选取两个值之间的数据</p>
<figure class="highlight sql"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">--查询年龄在12和14之间的数据</span></span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> <span class="keyword">user</span> <span class="keyword">where</span> user_age <span class="keyword">between</span> <span class="number">12</span> <span class="keyword">and</span> <span class="number">14</span></span><br></pre></td></tr></table></div></figure></li>
<li><p>Aliases<br>指定别名</p>
<figure class="highlight sql"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">--不使用别名</span></span><br><span class="line"><span class="keyword">Select</span> room.room_name,user.user_name,user.user_age <span class="keyword">from</span> <span class="keyword">user</span> ,room <span class="keyword">Where</span> user.user_age=<span class="number">12</span> <span class="keyword">and</span> room.room_id = <span class="number">1</span></span><br><span class="line"><span class="comment">--使用别名</span></span><br><span class="line">使用别名的时候直接将别名跟在后面，不使用<span class="keyword">as</span>也可以</span><br><span class="line"><span class="keyword">Select</span> r.room_name,u.user_name,u.user_age <span class="keyword">from</span> <span class="keyword">user</span> <span class="keyword">as</span> u,room <span class="keyword">as</span> r <span class="keyword">Where</span> u.user_age=<span class="number">12</span> <span class="keyword">and</span> r.room_id = <span class="number">1</span></span><br></pre></td></tr></table></div></figure></li>
<li><p>Join</p>
<ul>
<li>引用两个表  <figure class="highlight sql"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> u.user_name,u.user_age,r.room_name <span class="keyword">from</span> <span class="keyword">user</span> <span class="keyword">as</span> u,room <span class="keyword">as</span> r <span class="keyword">where</span> u.room_id=r.room_id <span class="keyword">and</span> r.room_name=<span class="string">'room of boy'</span></span><br></pre></td></tr></table></div></figure></li>
<li>使用关键字join来连接两张表  <figure class="highlight sql"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> u.user_name,u.user_age,r.room_name <span class="keyword">from</span> <span class="keyword">user</span> <span class="keyword">as</span> u <span class="keyword">join</span> room <span class="keyword">as</span> r <span class="keyword">on</span> u.room_id=r.room_id <span class="keyword">and</span> r.room_name=<span class="string">'room of boy'</span></span><br></pre></td></tr></table></div></figure></li>
<li>Inner join用法与join一致</li>
<li>Left join<ul>
<li>左连接把左边的全部查出来，右边有的则匹配，没有则为null</li>
</ul>
</li>
<li>Right join右连接同上</li>
<li>Full join连接表将包含的所有记录来自两个表，并使用NULL值作为两侧缺失匹配结果</li>
</ul>
</li>
<li><p>Union</p>
<ul>
<li>用于合并两个或者多个SELECT语句的结果集</li>
<li>UNION内部的select语句必须拥有相同数量的列。列也必须拥有相同的数据类型。同时，每条select语句中的列的顺序必须相同。</li>
<li>默认的union选取不同的值，不重复出现相同的值，如果想要有相同的值出现就使用union all<figure class="highlight sql"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">    <span class="keyword">select</span> room_name <span class="keyword">from</span> room <span class="keyword">union</span> <span class="keyword">select</span> color_name <span class="keyword">from</span> color</span><br><span class="line"><span class="number">18.</span> <span class="keyword">Create</span></span><br><span class="line">    - <span class="keyword">Create</span> DB</span><br><span class="line">        <span class="string">``</span><span class="string">`sql</span></span><br><span class="line"><span class="string">        --创建数据库mysqltest</span></span><br><span class="line"><span class="string">        create database mysqltest</span></span><br></pre></td></tr></table></div></figure></li>
<li>Create table<figure class="highlight sql"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> sqltest(</span><br><span class="line">    <span class="keyword">id</span> <span class="built_in">int</span>,</span><br><span class="line">    <span class="keyword">name</span> <span class="built_in">varchar</span>(<span class="number">45</span>),</span><br><span class="line">    age <span class="built_in">int</span>,</span><br><span class="line">    salary <span class="built_in">float</span>,</span><br><span class="line">    <span class="built_in">time</span> <span class="built_in">date</span>,</span><br><span class="line">)</span><br></pre></td></tr></table></div></figure></li>
</ul>
</li>
<li><p>Constraints<br>SQL约束，用于限制加入表的数据的类型。<br>常见约束：not noll、unique、primary key、foreign key、check、default</p>
<ul>
<li>Not null<ul>
<li>Not null 约束强制列不接受NULL值。Not null 约束强制字段始终包含值，这意味着，如果不向字段添加值，就无法插入新的字段或者更新记录</li>
<li>用法：在字段后面加上not null<figure class="highlight sql"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> sqltest(</span><br><span class="line"><span class="keyword">id</span> <span class="built_in">int</span>,</span><br><span class="line"><span class="keyword">name</span> <span class="built_in">varchar</span>(<span class="number">45</span>) <span class="keyword">not</span> <span class="literal">null</span>,</span><br><span class="line">age <span class="built_in">int</span>,</span><br><span class="line">salary <span class="built_in">float</span>,</span><br><span class="line"><span class="built_in">time</span> <span class="built_in">date</span>,</span><br><span class="line">)</span><br></pre></td></tr></table></div></figure></li>
</ul>
</li>
<li>Unique<ul>
<li>Unique约束唯一标识数据库中的每一条记录。Primary key约束拥有自动的unique约束。需要注意的是，每个表里面可以拥有多个unique约束，但只能有一个primary key约束</li>
<li>MySQL用法，unique(字段名)</li>
<li>SQL Server 、 Oracle 、 MS Access在字段后面加Unique</li>
<li>命名约束使用constraint<figure class="highlight sql"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> persons(</span><br><span class="line">    id_p <span class="built_in">int</span> <span class="keyword">not</span> <span class="literal">null</span>,</span><br><span class="line">    lastname <span class="built_in">varchar</span>(<span class="number">255</span>) <span class="keyword">not</span> <span class="literal">null</span>,</span><br><span class="line">    firstname <span class="built_in">varchar</span>(<span class="number">255</span>),</span><br><span class="line">    address <span class="built_in">varchar</span>(<span class="number">255</span>),</span><br><span class="line">    city <span class="built_in">varchar</span>(<span class="number">255</span>),</span><br><span class="line">    <span class="keyword">constraint</span> uc_personid <span class="keyword">unique</span> (id_p,lastname)</span><br><span class="line">)</span><br></pre></td></tr></table></div></figure></li>
<li>已经创建了表后需要添加约束<figure class="highlight sql"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> sqltest <span class="keyword">add</span> <span class="keyword">unique</span>(age)</span><br></pre></td></tr></table></div></figure></li>
<li>给已经创建了的表添加约束并命名<figure class="highlight sql"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> sqltest <span class="keyword">add</span> <span class="keyword">constraint</span> unique_name <span class="keyword">unique</span>(age,salary)</span><br></pre></td></tr></table></div></figure></li>
<li>撤销约束<br>alter table 表名 drop constraint 约束名    <ul>
<li>在没有给约束命名的情况下（上面的age约束）直接使用字段名就可以<figure class="highlight sql"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> sqltest <span class="keyword">drop</span> <span class="keyword">index</span> age</span><br></pre></td></tr></table></div></figure></li>
<li>约束有名字的情况下，直接使用名字就可以<figure class="highlight sql"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> sqltest <span class="keyword">drop</span> <span class="keyword">index</span> unique_name</span><br></pre></td></tr></table></div></figure></li>
</ul>
</li>
</ul>
</li>
<li>Primary Key<br>Primary key约束唯一标识数据库表中的每一条记录，组件必须包含唯一的值。组件列不能包含NULL值。每个表都应该有一个主键，并且每一个表都只能有一个主键<ul>
<li>mysql:primary key(id_p)</li>
<li>SQL Server、Oracle和MS Access:字段名后加primary key</li>
<li>为已经创建成功的表创建primary key约束<figure class="highlight sql"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> sqltest <span class="keyword">add</span> primary <span class="keyword">key</span>(<span class="keyword">id</span>)</span><br></pre></td></tr></table></div></figure></li>
<li>为已经创建成功的表添加主键约束，以及为多个列定义主键约束<figure class="highlight sql"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> sqltest <span class="keyword">add</span> <span class="keyword">constraint</span> pk_name primary <span class="keyword">key</span>(<span class="keyword">id</span>,<span class="keyword">name</span>)</span><br></pre></td></tr></table></div></figure></li>
<li>在MySQL中撤销主键<figure class="highlight sql"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> sqltest <span class="keyword">drop</span> primary <span class="keyword">key</span></span><br></pre></td></tr></table></div></figure></li>
<li>在SQL Server、Oracle、MS Access中撤销主键<figure class="highlight sql"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> 表名 <span class="keyword">drop</span> <span class="keyword">constraint</span> 主键名</span><br></pre></td></tr></table></div></figure></li>
</ul>
</li>
<li>Foreign key<ul>
<li>外键，即一个表的外键指向另一个表的主键</li>
<li>外键约束用于预防破坏表之间的连接动作，外键约束也能防止非法数据插入外键列，因为他必须是他指向的那个表的值之一。</li>
</ul>
</li>
<li>Check<ul>
<li>Check约束用于限制列中的值的范围。如果对单一的列定义check约束，那么改了只允许特定的值。如果对一个表定义check约束，那么此约束会在特定的列中对值进行限制。<figure class="highlight sql"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">--对表定义check约束</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> persons(</span><br><span class="line">    id_p <span class="built_in">int</span> <span class="keyword">not</span> <span class="literal">null</span>,</span><br><span class="line">    lastname <span class="built_in">varchar</span>(<span class="number">255</span>) <span class="keyword">not</span> <span class="literal">null</span>,</span><br><span class="line">    <span class="keyword">check</span>(id_p&gt;<span class="number">0</span>)</span><br><span class="line">)</span><br><span class="line"><span class="comment">--对单一的列定义check约束</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> persons(</span><br><span class="line">    id_p <span class="built_in">int</span> <span class="keyword">not</span> <span class="literal">null</span> <span class="keyword">check</span> (id_p&gt;<span class="number">0</span>),</span><br><span class="line">    lastname <span class="built_in">varchar</span>(<span class="number">255</span>) <span class="keyword">not</span> <span class="literal">null</span></span><br><span class="line">)</span><br><span class="line">- 为已经创建成功的表添加<span class="keyword">check</span>约束</span><br><span class="line"><span class="string">``</span><span class="string">`sql</span></span><br><span class="line"><span class="string">alter table user add check (age&gt;10)</span></span><br></pre></td></tr></table></div></figure></li>
</ul>
</li>
<li>Default<ul>
<li>Default约束用于向列宗插入默认值。如果没有规定其他值，那么就会将默认值添加到所有的新纪录。</li>
<li>当表已经存在的时候，添加默认值<figure class="highlight sql"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> sqltest <span class="keyword">alter</span> <span class="keyword">name</span> <span class="keyword">set</span> <span class="keyword">default</span> <span class="string">'tom'</span></span><br></pre></td></tr></table></div></figure></li>
<li>撤销默认值<figure class="highlight sql"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> persons </span><br><span class="line"><span class="keyword">alter</span> city <span class="keyword">drop</span> <span class="keyword">default</span></span><br></pre></td></tr></table></div></figure></li>
</ul>
</li>
</ul>
</li>
<li><p>create index<br>在表里面创建索引，一边更加快速高效地查询数据。用户无法看见索引，他们只能被用来加速搜索、查询。<br>注意：更新一个包含索引的表需要比更新一个没有索引的表更多的时间，这是索引本身也需要更新，因此，理想的做法是仅仅在常常被搜索的列上面创建索引。</p>
<ul>
<li>创建一个索引<figure class="highlight sql"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">index</span> index_name <span class="keyword">on</span> color(color_id)</span><br></pre></td></tr></table></div></figure></li>
<li>创建一个独一无二的索引，即两行不能拥有相同的索引值。<figure class="highlight sql"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">unique</span> <span class="keyword">index</span> book_index <span class="keyword">on</span> book(book_id)</span><br></pre></td></tr></table></div></figure></li>
<li>如果索引不止一个列，你可以在括号中列出这些列的名称，用逗号隔开<figure class="highlight sql"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">    <span class="keyword">create</span> <span class="keyword">index</span> index_bank <span class="keyword">on</span> bank(bank_id,bank_name)</span><br><span class="line"><span class="number">21.</span> <span class="keyword">Drop</span></span><br><span class="line">通过使用<span class="keyword">DROP</span>语句，可以删掉索引、表和数据库</span><br><span class="line">    - 删除索引</span><br><span class="line">    <span class="string">``</span><span class="string">`sql</span></span><br><span class="line"><span class="string">    drop index index_name on color</span></span><br></pre></td></tr></table></div></figure></li>
<li>删除表<figure class="highlight sql"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> colorcopy</span><br></pre></td></tr></table></div></figure></li>
<li>清空表<figure class="highlight sql"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">truncate</span> <span class="keyword">table</span> color</span><br></pre></td></tr></table></div></figure></li>
<li>删除数据库<figure class="highlight sql"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">drop</span> <span class="keyword">database</span> mysqltest</span><br></pre></td></tr></table></div></figure></li>
</ul>
</li>
<li><p>Alter</p>
<ul>
<li>添加列<figure class="highlight sql"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> <span class="keyword">user</span> <span class="keyword">add</span> salary <span class="built_in">float</span></span><br></pre></td></tr></table></div></figure></li>
<li>删除列<br>alter table user drop column room_id</li>
</ul>
</li>
<li><p>increment</p>
<figure class="highlight sql"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">--定义主键自增</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> persons(</span><br><span class="line">    <span class="comment">/*sql server的语法*/</span></span><br><span class="line">    p_id <span class="built_in">int</span> primary <span class="keyword">key</span> <span class="keyword">identity</span>,</span><br><span class="line">    <span class="comment">/*mysql的语法</span></span><br><span class="line"><span class="comment">    MS SQL 使用 IDENTITY 关键字来执行 auto-increment 任务。*/</span></span><br><span class="line">    p_id <span class="built_in">int</span> <span class="keyword">not</span> <span class="literal">null</span> auto_increment,</span><br><span class="line">    lastname <span class="built_in">varchar</span>(<span class="number">255</span>) <span class="keyword">not</span> <span class="literal">null</span></span><br><span class="line">)</span><br></pre></td></tr></table></div></figure></li>
<li><p>View</p>
<ul>
<li>视图，一种基于SQL语句的结果集可视化表。视图包含行和列，就像一个真实的表。视图中的字段来自一个或多个数据库中的真实的表中的字段，我们可以向视图添加SQL函数、where以及join语句，我们提交数据，然后这些来自某个单一的表。需要注意的是，数据库中的结构和设计不会受到视图的函数、where或join语句的影响</li>
<li>创建一个视图，字段来自user表和Room表<figure class="highlight sql"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">view</span> view_test <span class="keyword">as</span> <span class="keyword">select</span> user.user_name,user.user_age,room.room_name <span class="keyword">from</span> <span class="keyword">user</span>,room <span class="keyword">where</span> user.user_age&gt;<span class="number">10</span></span><br></pre></td></tr></table></div></figure></li>
<li>查询视图<figure class="highlight sql"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> view_test</span><br></pre></td></tr></table></div></figure></li>
<li>撤销视图<figure class="highlight sql"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">drop</span> <span class="keyword">view</span> view_test</span><br></pre></td></tr></table></div></figure></li>
</ul>
</li>
<li><p>date</p>
<ul>
<li><p>Mysql使用下列数据类型在数据库中存储日期或日期/时间值</p>
<ul>
<li>DATE:YYYY-MM-DD</li>
<li>DATETIME:YYYY-MM-DD HH:MM:SS</li>
<li>TIMESTAMP:YYYY-MM-DD HH:MM:SS</li>
<li>YEAR:YYYY或YY</li>
</ul>
</li>
<li><p>sql server使用下列数据类型在数据库中存储日期/时间值</p>
<ul>
<li>DATE:YYYY-MM-DD</li>
<li>DATETIME:YYYY-MM-DD HH:MM:SS</li>
<li>SMALLDATETIME:YYYY-MM-DD HH:MM:SS</li>
<li>TIMESTAMP:唯一的数字</li>
</ul>
</li>
</ul>
</li>
<li><p>Nulls</p>
<ul>
<li>默认的，表的列可以存放NULL值。如果表里面的某个列是可选的，那么我们可以在不想改列添加值的情况下插入记录或者更新记录，这意味着该字段以NULL值保存。注意，NULL和0是不等价的，不能进行比较。</li>
<li>查询NUll值<figure class="highlight sql"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> <span class="keyword">user</span> <span class="keyword">where</span> salary <span class="keyword">is</span> <span class="literal">null</span></span><br></pre></td></tr></table></div></figure></li>
<li>查询非NULL值<figure class="highlight sql"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> <span class="keyword">user</span> <span class="keyword">where</span> salary <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">null</span></span><br></pre></td></tr></table></div></figure></li>
</ul>
</li>
<li><p>数据类型</p>
<ul>
<li>MySQL主要有三种类型：文本、数字、日期</li>
</ul>
</li>
<li><p>SQL函数</p>
<ul>
<li>在SQL当中，基本的函数类型和种类有若干种，函数的基本类型是：合计函数（Aggregate function）和 Scalar函数</li>
<li>Aggregate 函数，函数操作面向一系列的值，并返回一个单一的值。</li>
<li>Scalar 函数，操作面向某个单一的值，并返回基于输入值的一个单一的值。</li>
<li>Avg()  <figure class="highlight sql"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">--求平均年龄</span></span><br><span class="line"><span class="keyword">select</span> <span class="keyword">avg</span>(user_age) <span class="keyword">from</span> <span class="keyword">user</span></span><br><span class="line"><span class="comment">--求大于平均年龄的用户</span></span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> <span class="keyword">user</span> <span class="keyword">where</span> user_age&gt;(<span class="keyword">select</span> <span class="keyword">avg</span>(user_age) <span class="keyword">from</span> <span class="keyword">user</span>)</span><br></pre></td></tr></table></div></figure></li>
<li>Count()<ul>
<li>可以使用as来给count()取一个别名<figure class="highlight sql"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">--返回列的值的数目（不包含NULL）</span></span><br><span class="line"><span class="keyword">select</span> <span class="keyword">count</span>(salary) <span class="keyword">from</span> <span class="keyword">user</span></span><br><span class="line"><span class="comment">--返回值不同的有多少</span></span><br><span class="line"><span class="keyword">select</span> <span class="keyword">count</span>(<span class="keyword">distinct</span> user_name) <span class="keyword">from</span> <span class="keyword">user</span></span><br><span class="line"><span class="comment">--查询所有列</span></span><br><span class="line"><span class="keyword">select</span> <span class="keyword">count</span>(*) <span class="keyword">from</span> <span class="keyword">user</span></span><br></pre></td></tr></table></div></figure></li>
</ul>
</li>
<li>Max()<ul>
<li>返回最大值，NULL不包括在计算中<figure class="highlight plain"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">    select max(price) as max_price from commodity</span><br><span class="line">- Min()用法同上</span><br><span class="line">- Sum()</span><br><span class="line">    - 返回该列值的总额</span><br><span class="line">    &#96;&#96;&#96;sql</span><br><span class="line">    select sum(salary) from user</span><br></pre></td></tr></table></div></figure></li>
</ul>
</li>
<li>Group By<ul>
<li>用于结合合计函数，根据一个或多个列对结果集进行分组<figure class="highlight sql"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> cname,<span class="keyword">sum</span>(price) <span class="keyword">from</span> commodity <span class="keyword">group</span> <span class="keyword">by</span> cname</span><br></pre></td></tr></table></div></figure></li>
</ul>
</li>
<li>Having<ul>
<li>在SQL中增加having子句的原因是where不能与合计函数一起使用。用法和where 一样<figure class="highlight sql"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> cname,<span class="keyword">sum</span>(price) <span class="keyword">from</span> commodity <span class="keyword">group</span> <span class="keyword">by</span> cname <span class="keyword">having</span> <span class="keyword">sum</span>(price)&gt;<span class="number">20</span></span><br></pre></td></tr></table></div></figure></li>
</ul>
</li>
<li>Ucase()<ul>
<li>把函数字段的值转化为大写<figure class="highlight sql"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="keyword">ucase</span>(user_name) <span class="keyword">from</span> <span class="keyword">user</span></span><br></pre></td></tr></table></div></figure></li>
</ul>
</li>
<li>Lcase()<ul>
<li>将函数字段转化为小写<figure class="highlight sql"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="keyword">lcase</span>(user_name) <span class="keyword">from</span> <span class="keyword">user</span></span><br></pre></td></tr></table></div></figure></li>
</ul>
</li>
<li>Mid()<ul>
<li>从文本字段中提取字符<figure class="highlight sql"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="keyword">mid</span>(user_name,<span class="number">2</span>,<span class="number">2</span>) <span class="keyword">from</span> <span class="keyword">user</span></span><br></pre></td></tr></table></div></figure></li>
</ul>
</li>
<li>Round()<ul>
<li>Round函数把数值字段舍入为指定的小数位数<figure class="highlight sql"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="keyword">round</span>(salary,<span class="number">2</span>) <span class="keyword">from</span> <span class="keyword">user</span></span><br></pre></td></tr></table></div></figure></li>
</ul>
</li>
<li>Now()<ul>
<li>返回当前时间<figure class="highlight sql"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="keyword">now</span>() <span class="keyword">from</span> <span class="keyword">user</span></span><br></pre></td></tr></table></div></figure></li>
</ul>
</li>
<li>If()<ul>
<li>根据条件返回不同值</li>
<li>基本语法：IF(条件表达式,值1,值2)</li>
<li>如果条件表达式为True，返回值1，为False,返回值2</li>
<li>返回值可以是任何值，比如：数值，文本，日期，空值，NULL，数学表达式，函数等。<figure class="highlight sql"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*if函数*/</span></span><br><span class="line"><span class="comment">--在学生表中，将1995年以后出生的学生划分为2班，将1995年(包括1995)之前的学生划分为1班，最后显示Sname,Sage,所在班级这三列。</span></span><br><span class="line"><span class="keyword">select</span> sname <span class="keyword">as</span> <span class="string">'学生姓名'</span>,sage <span class="keyword">as</span> <span class="string">'学生年龄'</span>, <span class="keyword">if</span>(<span class="keyword">year</span>(sage)&lt;=<span class="number">1995</span>,<span class="string">'1班'</span>,<span class="string">'2班'</span>) <span class="keyword">as</span> <span class="string">'所在班级'</span> <span class="keyword">from</span> students <span class="keyword">order</span> <span class="keyword">by</span> sage;</span><br><span class="line"><span class="comment">/*if函数嵌套*/</span></span><br><span class="line"><span class="comment">--在学生表中，将学生编号小于等于3的学生，分为1班，学生编号在4-6的学生，分为2班，学生编号大于等于7的学生，分为3班，最后显示Sid,Sname,所在班级这三列。</span></span><br><span class="line"><span class="keyword">select</span> <span class="keyword">sid</span>,sname <span class="keyword">if</span>(</span><br><span class="line">    <span class="keyword">sid</span>&lt;=<span class="number">3</span>,<span class="string">'class 1'</span></span><br><span class="line">    <span class="keyword">if</span>(<span class="keyword">sid</span>&gt;=<span class="number">7</span>,<span class="string">'class 3'</span>,<span class="string">'class 2'</span>)) <span class="keyword">as</span> <span class="string">'class'</span></span><br><span class="line"><span class="keyword">from</span> students <span class="keyword">order</span> <span class="keyword">by</span> <span class="keyword">sid</span></span><br><span class="line"><span class="comment">/*if+聚合函数*/</span></span><br><span class="line"><span class="comment">--将学生表和教师结合使用，计算班主任所带的学生数量，大于等于5人以上的显示：5人以上，人数小于5人的显示：5人以下。</span></span><br><span class="line"><span class="comment">--USING()函数的作用是简化等值连接语句</span></span><br><span class="line"><span class="keyword">select</span> t.name <span class="keyword">as</span> <span class="string">'teacher name'</span>,<span class="keyword">count</span>(*) <span class="keyword">as</span> <span class="string">'count'</span>,</span><br><span class="line"><span class="keyword">if</span>(</span><br><span class="line">    <span class="keyword">count</span>(*)&gt;=<span class="number">5</span>,<span class="string">'more than 5'</span>,<span class="string">'less than 5'</span></span><br><span class="line">) <span class="keyword">as</span> <span class="string">'classify'</span></span><br><span class="line"><span class="keyword">from</span> teachers <span class="keyword">as</span> t <span class="keyword">join</span> students <span class="keyword">as</span> s</span><br><span class="line"><span class="keyword">using</span>(tid) <span class="keyword">group</span> <span class="keyword">by</span> t.name</span><br><span class="line"><span class="comment">--与where s.tid=t.tid效果等同</span></span><br></pre></td></tr></table></div></figure>



</li>
</ul>
</li>
</ul>
</li>
</ol>
<p>参考<br><span class="exturl"><a class="exturl__link" href="https://blog.csdn.net/m0_68850571/article/details/123990306" target="_blank" rel="noopener">https://blog.csdn.net/m0_68850571/article/details/123990306</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></p>
</div></div></article><article class="postlist-item post"><header class="post-header"><h1 class="post-title"><a class="post-title__link" href="/2022/09/05/Machine%20Learning%20for%20Semiconductors/">Machine Learning for Semiconductors</a></h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">Created</span><span class="post-meta-item__value">2022-09-05</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">Updated</span><span class="post-meta-item__value">2022-10-10</span></span></div></header><div class="post-body"><div class="post-excerpt">
        <h3 id="1-问题提出">
          <a href="#1-问题提出" class="heading-link"><i class="fas fa-link"></i></a><a href="#1-问题提出" class="headerlink" title="1.问题提出"></a>1.问题提出</h3>
      <p>在半导体材料科学和半导体制造这两个领域，已经积累了大量的数据，需要解决无数的相关问题。如果这些数据能够得到有效分析，将极大地有助于发现新的半导体材料，加速半导体制造的发展。因此，我们需要更有效的方法来处理这些数据和问题，而不是传统的研究方法。</p>

        <h3 id="2-ML算法模式及选择">
          <a href="#2-ML算法模式及选择" class="heading-link"><i class="fas fa-link"></i></a><a href="#2-ML算法模式及选择" class="headerlink" title="2. ML算法模式及选择"></a>2. ML算法模式及选择</h3>
      <p>这些方法大致可以分为三种类型：监督学习、无监督学习、强化学习。</p>
<ul>
<li>监督学习<br>监督学习需要训练数据中的每一个样本都有明确的特征和标签，并且期望学习一个能够将标签和特征联系起来的模型，所以这个模型可以给其他合理的样本贴标签。</li>
<li>无监督学习<br>无监督学习的训练数据不需要标签，无监督学习的目的一般是对输入数据进行聚类或降维。</li>
<li>强化学习<br>强化学习可以从零开始获得模型，不需要数据。在学习的过程中，程序尝试访问结果，然后更新策略，尝试获得更好的结果，然后再次尝试，循环直到结果足够好。</li>
<li>模型选择<br>对于半导体的 ML 任务，大多数任务是分类、预测某些材料特性、预测器件或制造的性能等且材料科学和半导体制造领域有大量数据。因此，ML 在该领域的大多数应用都在监督学习的范围内。
        <h3 id="3-数据准备">
          <a href="#3-数据准备" class="heading-link"><i class="fas fa-link"></i></a><a href="#3-数据准备" class="headerlink" title="3.数据准备"></a>3.数据准备</h3>
      </li>
<li>数据要求<ul>
<li>适合训练目标模型，如果原始数据不适合，则需要进行一些转换</li>
<li>足以代表背后的规则和训练一个好的模型</li>
<li>尽可能准确地给出隐藏的统计分布</li>
</ul>
</li>
<li>根据 ML 中使用的特征，用于描述样本的特征可以分为三类<ul>
<li>原子构型-类型+位置</li>
<li>原子信息-原子序数、电负性…</li>
<li>材料特性-晶格常数、空间群、吸收光谱…
        <h3 id="4-ML模型">
          <a href="#4-ML模型" class="heading-link"><i class="fas fa-link"></i></a><a href="#4-ML模型" class="headerlink" title="4.ML模型"></a>4.ML模型</h3>
      </li>
</ul>
</li>
<li>支持向量机SVM<br>SVM已被用于预测一种材料是半导体还是金属，或者一种半导体的间隙是直接的还是间接的，或其他属性 </li>
<li>核岭回归KRR<br>它隐式地将初始特征转换为新的高维特征空间。这将带来两个好处：更强的表达能力，以及在原始特征空间中的非线性拟合效果只是在新特征空间中的线性拟合。<br>由于KRR方法需要一个N × N矩阵，其中 N 是样本点的数量，它更适用于小系统或小样本的问题，如有机材料。</li>
<li>决策树DT和随机森林RF<br>DT 和 RF 算法都广泛应用于半导体材料和制造的许多问题，例如预测间隙，其他材料属性、晶圆检测，技术优化，制造故障检测</li>
<li>深度神经网络DNN<br>DNN 可以自动提取样本或输入数据的隐藏、深层特征。<br>DNN 和 ANN 已被用于许多研究中。关于半导体，研究人员将它们应用于形成能预测、间隙、其他材料特性、材料加工优化、制造技术优化, 晶圆检测, 制造故障检测等</li>
<li>线性拟合法<br>线性拟合方法已被用于预测间隙、磁性能，以提高晶圆质量，提高制造良率等。</li>
<li>Boost算法<br>可以提高某种学习模型的训练效果</li>
<li>主动学习<br>允许在将学习模型应用于预测时对其进行改进。因此它已被应用于处理一些在训练前难以收集到足够合适数据的问题，如机器学习力场（MLFF）</li>
<li>其他算法<br>如遗传算法（GA），朴素贝耶斯（NB），迁移学习（TL）等
        <h3 id="5-半导体材料科学的学习过程">
          <a href="#5-半导体材料科学的学习过程" class="heading-link"><i class="fas fa-link"></i></a><a href="#5-半导体材料科学的学习过程" class="headerlink" title="5.半导体材料科学的学习过程"></a>5.半导体材料科学的学习过程</h3>
      </li>
<li>取样<br>没有免费的午餐定理表示：如果训练集与测试集无关，任何模型都不能比在测试集中随机猜测更好。</li>
<li>特征工程<br>描述符是否能够表达对研究目标很重要的特定特征是非常重要的。这是另一个决定机器学习结果好坏的核心因素。</li>
<li>训练和预测<br>平衡过拟合和欠拟合：扩大训练数据外，调整超参数
        <h3 id="6-半导体机器学习的现状">
          <a href="#6-半导体机器学习的现状" class="heading-link"><i class="fas fa-link"></i></a><a href="#6-半导体机器学习的现状" class="headerlink" title="6.半导体机器学习的现状"></a>6.半导体机器学习的现状</h3>
      </li>
<li>新材料发现</li>
<li>性能预测</li>
<li>半导体制造</li>
</ul>
</div></div></article><article class="postlist-item post"><header class="post-header"><h1 class="post-title"><a class="post-title__link" href="/2022/08/24/pytorch%E5%AD%A6%E4%B9%A0/">pytorch学习</a></h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">Created</span><span class="post-meta-item__value">2022-08-24</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">Updated</span><span class="post-meta-item__value">2022-08-31</span></span></div></header><div class="post-body"><div class="post-excerpt">
        <h3 id="1-Tensorboard">
          <a href="#1-Tensorboard" class="heading-link"><i class="fas fa-link"></i></a><a href="#1-Tensorboard" class="headerlink" title="1. Tensorboard"></a>1. Tensorboard</h3>
      <ul>
<li><p>TensorBoard是TensorFlow自带的一个强大的可视化工具，也是一个Web应用程序套件。</p>
</li>
<li><p>可视化的主要功能</p>
<ul>
<li><p>Scalars:展示训练过程中的准确率、损失值、权重/偏置的变化情况。</p>
  <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"></span><br><span class="line">writer=SummaryWriter(<span class="string">'logs'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#y=x</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">100</span>):</span><br><span class="line">    writer.add_scalar(<span class="string">'y=x'</span>,i,i)</span><br><span class="line"></span><br><span class="line">writer.close()</span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">运行后会生成logs文件夹</span></span><br><span class="line"><span class="string">terminal中输入tensorboard --logdir=logs可通过http://localhost:6006/ 打开查看，其中logdir=事件文件所在文件夹名</span></span><br><span class="line"><span class="string">为防止与其他端口冲突，可自行指定端口tensorboard --logdir=logs --port=6007</span></span><br><span class="line"><span class="string">'''</span></span><br></pre></td></tr></table></div></figure>
<p>  若出现重叠的情况，可将logs文件夹下的文件删除，重新运行；或每次都创建新的子文件夹SuummaryWriter(“新文件夹”)<br>  <img src="/2022/08/24/pytorch%E5%AD%A6%E4%B9%A0/%E9%87%8D%E5%8F%A0.png" alt><br>  <img src="/2022/08/24/pytorch%E5%AD%A6%E4%B9%A0/%E9%87%8D%E5%8F%A0.png" alt><br>  <img src="/2022/08/24/pytorch%E5%AD%A6%E4%B9%A0/%E9%87%8D%E5%8F%A0.png" alt></p>
</li>
<li><p>利用numpy.array()，对PIL图片进行转换</p>
  <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">image_path=<span class="string">'data/train/ants_image/0013035.jpg'</span></span><br><span class="line">img_PIL=Image.open(image_path)</span><br><span class="line">img_array=np.array(img_PIL)</span><br><span class="line"><span class="comment">#从PIL到numpy，需要在add_image()中指定shape中每一个数字/维表示的含义</span></span><br><span class="line">writer.add_image(<span class="string">'test'</span>,img_array,<span class="number">1</span>,dataformats=<span class="string">'HWC'</span>)</span><br></pre></td></tr></table></div></figure></li>
<li><p>add_image<br>add_image(tag, img_tensor, global_step=None, walltime=None, dataformats=’CHW’)</p>
<ul>
<li>tag (string): 数据名称</li>
<li>img_tensor (类型 torch.Tensor 或 numpy.array): 图像数据</li>
<li>global_step (int, optional): 记录这是第几个子图 后面解释这个参数</li>
<li>walltime (float, optional): 记录发生的时间，默认为 time.time()</li>
<li>dataformats (string, optional): 图像数据的格式，默认为 ‘CHW’，即 Channel x Height x Width，还可以是 ‘CHW’、‘HWC’ 或 ‘HW’ 等<br></li>
</ul>
</li>
</ul>
</li>
</ul>

        <h3 id="2-Transforms">
          <a href="#2-Transforms" class="heading-link"><i class="fas fa-link"></i></a><a href="#2-Transforms" class="headerlink" title="2. Transforms"></a>2. Transforms</h3>
      <ul>
<li>python的用法-&gt;tensor数据类型<ul>
<li>通过transforms.ToTensor去看两个问题<ul>
<li>transforms该如何使用<br><img src="/2022/08/24/pytorch%E5%AD%A6%E4%B9%A0/transforms%E4%BD%BF%E7%94%A8.png" alt><figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tensor_trans=transforms.ToTensor()</span><br><span class="line">tensor_img=tensor_trans(img)</span><br></pre></td></tr></table></div></figure></li>
<li>为什么需要Tensor数据类型</li>
</ul>
</li>
</ul>
</li>
<li>常见的Transforms<ul>
<li>call  <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Person</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__call__</span><span class="params">(self,name)</span>:</span></span><br><span class="line">        print(<span class="string">'__call__'</span>+<span class="string">"Hello"</span>+name)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">hello</span><span class="params">(self,name)</span>:</span></span><br><span class="line">        print(<span class="string">'hello'</span>+name)</span><br><span class="line"></span><br><span class="line">person=Person()</span><br><span class="line">person(<span class="string">'zhangsan'</span>)<span class="comment">#定义call可以直接用类+参数</span></span><br><span class="line">person.hello(<span class="string">'lisi'</span>)<span class="comment">#需要用点来调用方法</span></span><br></pre></td></tr></table></div></figure></li>
<li>ToTensor()  <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"></span><br><span class="line">writer=SummaryWriter(<span class="string">'logs'</span>)</span><br><span class="line">img=Image.open(<span class="string">'images/QQ图片201802031008421.jpg'</span>)</span><br><span class="line">print(img)</span><br><span class="line"></span><br><span class="line">trans_totensor=transforms.ToTensor()</span><br><span class="line">img_tensor=trans_totensor(img)</span><br><span class="line"></span><br><span class="line">writer.add_image(<span class="string">'ToTensor'</span>,img_tensor)</span><br><span class="line">writer.close()</span><br></pre></td></tr></table></div></figure></li>
<li>归一化函数Normalize()<ul>
<li>归一化要把需要处理的数据经过处理后（通过某种算法）限制在你需要的一定范围内，为了后面数据处理的方便，以及保证程序运行时收敛加快。</li>
<li>输入为tensor的数据类型  <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">output[channel] = (input[channel] - mean[channel]) / std[channel]</span><br></pre></td></tr></table></div></figure>
  <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">Normalize</span></span><br><span class="line"><span class="string">output[channel] = (input[channel] - mean[channel]) / std[channel]</span></span><br><span class="line"><span class="string">如下数据均值方差为[0.5,0.5,0.5],[0.5,0.5,0.5]，则output=(input-0.5)/0.5=2*input-1</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line">print(img_tensor[<span class="number">0</span>][<span class="number">0</span>][<span class="number">0</span>])<span class="comment">#第一层第一行第一列</span></span><br><span class="line">trans_norm=transforms.Normalize([<span class="number">1</span>,<span class="number">3</span>,<span class="number">5</span>],[<span class="number">3</span>,<span class="number">2</span>,<span class="number">1</span>])<span class="comment">#均值、方差</span></span><br><span class="line">img_norm=trans_norm(img_tensor)</span><br><span class="line">print(img_norm[<span class="number">0</span>][<span class="number">0</span>][<span class="number">0</span>])</span><br><span class="line">writer.add_image(<span class="string">'Normalize'</span>,img_norm,<span class="number">1</span>)</span><br><span class="line">writer.close()</span><br></pre></td></tr></table></div></figure>
  <img src="/2022/08/24/pytorch%E5%AD%A6%E4%B9%A0/normalize_tensor_output.png" alt><br>  <img src="/2022/08/24/pytorch%E5%AD%A6%E4%B9%A0/normalize_output.png" alt></li>
</ul>
</li>
<li>Resize()<ul>
<li>用于对PIL图像的预处理，可用resize函数进行缩放</li>
<li>open-cv的读取图像格式为numpy，而pytorch中的resize方法需要Image格式，因此需要转换</li>
<li>输入为PIL image  <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Resize</span></span><br><span class="line">print((img.size))</span><br><span class="line">trans_resize=transforms.Resize((<span class="number">512</span>,<span class="number">512</span>))</span><br><span class="line"><span class="comment">#img PIL -&gt;resize -&gt;img_resize PIL</span></span><br><span class="line">img_resize=trans_resize(img)</span><br><span class="line"><span class="comment">#img_resize PIL -&gt;totensor -&gt;img_resize tensor</span></span><br><span class="line">img_resize=trans_totensor(img_resize)</span><br><span class="line">writer.add_image(<span class="string">'Resize'</span>,img_resize,<span class="number">0</span>)</span><br><span class="line">print(img_resize)</span><br><span class="line">writer.close()</span><br></pre></td></tr></table></div></figure></li>
</ul>
</li>
<li>Compose()<ul>
<li>串联多个图片变换的操作</li>
<li>Compose()中的参数需要是一个列表，python中，列表的表示形式为[数据1，数据2，…]。在Compose中，数据需要是transforms类型，所以得到，Compose([transforms参数1,transforms参数2,…])  <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Compose - resize</span></span><br><span class="line">trans_resize_2=transforms.Resize(<span class="number">512</span>)</span><br><span class="line"><span class="comment">#PIL -&gt; PIL -&gt; tensor</span></span><br><span class="line"><span class="comment">#后面参数的输入应与前一参数的输出类型保持一致</span></span><br><span class="line">trans_compose=transforms.Compose([trans_resize_2,trans_totensor])</span><br><span class="line">img_resize_2=trans_compose(img)</span><br><span class="line">writer.add_image(<span class="string">'Resize'</span>,img_resize_2,<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">writer.close()</span><br></pre></td></tr></table></div></figure></li>
</ul>
</li>
<li>RandomCrop()随机裁剪  <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#RandomCrop</span></span><br><span class="line"><span class="comment">#用512截取图片的一部分</span></span><br><span class="line">trans_random=transforms.RandomCrop(<span class="number">512</span>)</span><br><span class="line"><span class="comment">#指定长和宽</span></span><br><span class="line"><span class="comment"># trans_random2=transforms.RandomCrop((512,1000))</span></span><br><span class="line">trans_compose_2=transforms.Compose([trans_random,trans_totensor])</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">    img_crop=trans_compose_2(img)</span><br><span class="line">    writer.add_image(<span class="string">'RandomCrop'</span>,img_crop,i)</span><br><span class="line"></span><br><span class="line">writer.close()</span><br></pre></td></tr></table></div></figure></li>
</ul>
</li>
<li>使用方法总结<ul>
<li>关注输入、输出类型</li>
<li>多看官方文档ctrl+鼠标左键</li>
<li>关注方法需要什么参数ctrl+p</li>
<li>不知道返回值的时候<ul>
<li>print</li>
<li>print(type())</li>
<li>debug</li>
<li>百度<br></li>
</ul>
</li>
</ul>
</li>
</ul>

        <h3 id="3-torchvision中的数据集使用">
          <a href="#3-torchvision中的数据集使用" class="heading-link"><i class="fas fa-link"></i></a><a href="#3-torchvision中的数据集使用" class="headerlink" title="3.torchvision中的数据集使用"></a>3.torchvision中的数据集使用</h3>
      <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"></span><br><span class="line">dataset_transform = torchvision.transforms.Compose([</span><br><span class="line">    torchvision.transforms.ToTensor()<span class="comment">#pytorch需要tensor类型的图片</span></span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># root:数据集村放在什么位置，./dataset会在程序所在文件夹创建dataset文件夹，并保存数据</span></span><br><span class="line"><span class="comment"># 训练集和测试集</span></span><br><span class="line">train_set = torchvision.datasets.CIFAR10(root=<span class="string">'./dataset'</span>, transform=dataset_transform, train=<span class="literal">True</span>, download=<span class="literal">True</span>)</span><br><span class="line">test_set = torchvision.datasets.CIFAR10(root=<span class="string">'./dataset'</span>, transform=dataset_transform, train=<span class="literal">False</span>, download=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">print(test_set[<span class="number">0</span>])</span><br><span class="line">print(test_set.classes)</span><br><span class="line">img, target = test_set[<span class="number">0</span>]</span><br><span class="line">print(img)</span><br><span class="line">print(target)</span><br><span class="line">print(test_set.classes[target])</span><br><span class="line"><span class="comment">#img.show()</span></span><br><span class="line"></span><br><span class="line">writer = SummaryWriter(<span class="string">'p10'</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">    img,target=test_set[i]</span><br><span class="line">    writer.add_image(<span class="string">'test_set'</span>,img,i)</span><br><span class="line">writer.close()</span><br><span class="line"></span><br><span class="line"><span class="comment">#terminal</span></span><br><span class="line"><span class="comment">#tensorboard --logdir=p10</span></span><br></pre></td></tr></table></div></figure>
<p><img src="/2022/08/24/pytorch%E5%AD%A6%E4%B9%A0/cifar10_img_target.png" alt><br>target=3对应为猫<br><br></p>

        <h3 id="4-DataLoader的使用">
          <a href="#4-DataLoader的使用" class="heading-link"><i class="fas fa-link"></i></a><a href="#4-DataLoader的使用" class="headerlink" title="4.DataLoader的使用"></a>4.DataLoader的使用</h3>
      <ul>
<li>常见参数<ul>
<li>很多参数有默认值，dataset没有</li>
<li>dataset:告诉程序数据集在什么地方</li>
<li>batch_size:每批要加载的样本数</li>
<li>shuffle:是否打乱，默认设为false，我们一般喜欢设置为true</li>
<li>num_workers:用于数据加载的子进程数。默认为0意味着数据将在主进程中加载</li>
<li>drop_last:设置为true如果数据集大小不能被批大小整除，则删除最后一个不完整的批，false则不删除</li>
</ul>
</li>
<li>代码  <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"></span><br><span class="line"><span class="comment">#准备的测试数据集</span></span><br><span class="line">test_data=torchvision.datasets.CIFAR10(root=<span class="string">'./dataset'</span>,train=<span class="literal">False</span>,transform=torchvision.transforms.ToTensor())</span><br><span class="line"></span><br><span class="line">test_loader=DataLoader(dataset=test_data,batch_size=<span class="number">4</span>,shuffle=<span class="literal">True</span>,num_workers=<span class="number">0</span>,drop_last=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#测试数据集中第一张图片及target</span></span><br><span class="line">img,target=test_data[<span class="number">0</span>]</span><br><span class="line"><span class="comment">#图片大小</span></span><br><span class="line">print(img.shape)</span><br><span class="line">print(target)</span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">output:</span></span><br><span class="line"><span class="string">torch.Size([3, 32, 32])#三通道（每个像素点都有3个值表示，RGB图片即为三通道图片），32*32的图片</span></span><br><span class="line"><span class="string">3</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line">writer=SummaryWriter(<span class="string">'dataloader'</span>)</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">2</span>):</span><br><span class="line">    step=<span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> test_loader:</span><br><span class="line">        imgs,targets=data</span><br><span class="line">        <span class="comment"># print(imgs.shape)</span></span><br><span class="line">        <span class="comment"># print(targets)</span></span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">        output</span></span><br><span class="line"><span class="string">        torch.Size([4, 3, 32, 32])#4表示4张图片，batch_size=4</span></span><br><span class="line"><span class="string">        tensor([2, 4, 9, 8])</span></span><br><span class="line"><span class="string">        torch.Size([4, 3, 32, 32])</span></span><br><span class="line"><span class="string">        tensor([4, 1, 2, 6])</span></span><br><span class="line"><span class="string">        ...</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        writer.add_images(<span class="string">'Epoch:&#123;&#125;'</span>.format(epoch),imgs,step)</span><br><span class="line">        step=step+<span class="number">1</span></span><br><span class="line">writer.close()</span><br></pre></td></tr></table></div></figure>
<br>

</li>
</ul>

        <h3 id="5-神经网络">
          <a href="#5-神经网络" class="heading-link"><i class="fas fa-link"></i></a><a href="#5-神经网络" class="headerlink" title="5.神经网络"></a>5.神经网络</h3>
      <ul>
<li>神经网络的基本骨架-nn.Module的使用  <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Tudui</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(Tudui, self).__init__()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self,input)</span>:</span></span><br><span class="line">        output=input+<span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line">tudui=Tudui()</span><br><span class="line">x=torch.tensor(<span class="number">1.0</span>)</span><br><span class="line">output=tudui(x)</span><br><span class="line">print(output)<span class="comment">#2.</span></span><br></pre></td></tr></table></div></figure>
<img src="/2022/08/24/pytorch%E5%AD%A6%E4%B9%A0/nn_forward.png" alt><br><img src="/2022/08/24/pytorch%E5%AD%A6%E4%B9%A0/nn_forward%E6%B5%81%E7%A8%8B.png" alt><br></li>
<li>卷积操作<br><img src="/2022/08/24/pytorch%E5%AD%A6%E4%B9%A0/%E5%8D%B7%E7%A7%AF.png" alt><br>padding填充默认填充0<br><img src="/2022/08/24/pytorch%E5%AD%A6%E4%B9%A0/%E5%8D%B7%E7%A7%AF_padding%3D1.png" alt>  <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="comment">#输入图像（5*5）</span></span><br><span class="line">input=torch.tensor([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">0</span>,<span class="number">3</span>,<span class="number">1</span>],</span><br><span class="line">                    [<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>],</span><br><span class="line">                    [<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>],</span><br><span class="line">                    [<span class="number">5</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">1</span>],</span><br><span class="line">                    [<span class="number">2</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>]])</span><br><span class="line"><span class="comment">#卷积核（3*3）</span></span><br><span class="line">kernel=torch.tensor([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>],</span><br><span class="line">                    [<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>],</span><br><span class="line">                    [<span class="number">2</span>,<span class="number">1</span>,<span class="number">0</span>]])</span><br><span class="line"></span><br><span class="line">input=torch.reshape(input,(<span class="number">1</span>,<span class="number">1</span>,<span class="number">5</span>,<span class="number">5</span>))<span class="comment">#1batch_size,1通道(平面）,5*5</span></span><br><span class="line">kernel=torch.reshape(kernel,(<span class="number">1</span>,<span class="number">1</span>,<span class="number">3</span>,<span class="number">3</span>))<span class="comment">#四维的，所以输出也是四维的</span></span><br><span class="line"></span><br><span class="line">print(input.shape)</span><br><span class="line">print(kernel.shape)</span><br><span class="line"></span><br><span class="line">output=F.conv2d(input,kernel,stride=<span class="number">1</span>)<span class="comment">#二维卷积</span></span><br><span class="line">print(output)</span><br><span class="line"></span><br><span class="line">output2=F.conv2d(input,kernel,stride=<span class="number">2</span>)</span><br><span class="line">print(output2)</span><br><span class="line"></span><br><span class="line">output3=F.conv2d(input,kernel,stride=<span class="number">1</span>,padding=<span class="number">1</span>)<span class="comment">#padding=1填充</span></span><br><span class="line">print(output3)</span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">output</span></span><br><span class="line"><span class="string">torch.Size([1, 1, 5, 5])</span></span><br><span class="line"><span class="string">torch.Size([1, 1, 3, 3])</span></span><br><span class="line"><span class="string">tensor([[[[10, 12, 12],</span></span><br><span class="line"><span class="string">        [18, 16, 16],</span></span><br><span class="line"><span class="string">        [13,  9,  3]]]])</span></span><br><span class="line"><span class="string">tensor([[[[10, 12],</span></span><br><span class="line"><span class="string">        [13,  3]]]])</span></span><br><span class="line"><span class="string">tensor([[[[ 1,  3,  4, 10,  8],</span></span><br><span class="line"><span class="string">        [ 5, 10, 12, 12,  6],</span></span><br><span class="line"><span class="string">        [ 7, 18, 16, 16,  8],</span></span><br><span class="line"><span class="string">        [11, 13,  9,  3,  4],</span></span><br><span class="line"><span class="string">        [14, 13,  9,  7,  4]]]])</span></span><br><span class="line"><span class="string">'''</span></span><br></pre></td></tr></table></div></figure></li>
<li>神经网络-卷积层<br><img src="/2022/08/24/pytorch%E5%AD%A6%E4%B9%A0/%E5%8D%B7%E7%A7%AF_out_channel%3D2.png" alt><br>input_channel=1（只有一层）,output_channel=2（有两层输出）,所以有两个卷积核（不一定完全相同）  <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> Conv2d</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"></span><br><span class="line">dataset=torchvision.datasets.CIFAR10(<span class="string">"../dataset"</span>,train=<span class="literal">False</span>,transform=torchvision.transforms.ToTensor(),</span><br><span class="line">                                    download=<span class="literal">True</span>)</span><br><span class="line">dataloader=DataLoader(dataset,batch_size=<span class="number">64</span>)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Tudui</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(Tudui, self).__init__()</span><br><span class="line">        <span class="comment"># input_channel=3(彩色图片channel为3,output_channel=6,kernel_size=3）</span></span><br><span class="line">        self.conv1=Conv2d(in_channels=<span class="number">3</span>,out_channels=<span class="number">6</span>,kernel_size=<span class="number">3</span>,stride=<span class="number">1</span>,padding=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self,x)</span>:</span><span class="comment">#x为输出</span></span><br><span class="line">        x=self.conv1(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="comment">#初始化网络</span></span><br><span class="line">tudui=Tudui()</span><br><span class="line">print(tudui)</span><br><span class="line"></span><br><span class="line">writer=SummaryWriter(<span class="string">'../logs'</span>)</span><br><span class="line"></span><br><span class="line">step=<span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> dataloader:</span><br><span class="line">    imgs,targets=data</span><br><span class="line">    output=tudui(imgs)</span><br><span class="line">    print(imgs.shape)</span><br><span class="line">    print(output.shape)</span><br><span class="line">    <span class="comment">#torch.Size([16, 3, 32, 32])</span></span><br><span class="line">    writer.add_images(<span class="string">'input'</span>,imgs,step)</span><br><span class="line">    <span class="comment">#torch.Size([16, 6, 30, 30]) -&gt; [xxx,3,30,30]</span></span><br><span class="line">    output=torch.reshape(output,(<span class="number">-1</span>,<span class="number">3</span>,<span class="number">30</span>,<span class="number">30</span>))<span class="comment">#不知道多少写-1，系统会自己计算</span></span><br><span class="line">    writer.add_images(<span class="string">'output'</span>,output,step)</span><br><span class="line">    step+=<span class="number">1</span></span><br></pre></td></tr></table></div></figure></li>
<li>神经网络-最大池化的使用<br>ceil_model=true则保留，false不保留（不满足3*3的不保留），一般设置为false<br><img src="/2022/08/24/pytorch%E5%AD%A6%E4%B9%A0/max_pooling.png" alt>  <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#降维，训练的更快</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> MaxPool2d</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"></span><br><span class="line">dataset=torchvision.datasets.CIFAR10(<span class="string">'../dataset'</span>,train=<span class="literal">False</span>,download=<span class="literal">True</span>,</span><br><span class="line">                                    transform=torchvision.transforms.ToTensor())</span><br><span class="line">dataloader=DataLoader(dataset,batch_size=<span class="number">64</span>)</span><br><span class="line"><span class="comment"># input=torch.tensor([[1,2,0,3,1],</span></span><br><span class="line"><span class="comment">#                     [0,1,2,3,1],</span></span><br><span class="line"><span class="comment">#                     [1,2,1,0,0],</span></span><br><span class="line"><span class="comment">#                     [5,2,3,1,1],</span></span><br><span class="line"><span class="comment">#                     [2,1,0,1,1]],dtype=torch.float32)#变为浮点型</span></span><br><span class="line"><span class="comment"># input=torch.reshape(input,(-1,1,5,5))</span></span><br><span class="line"><span class="comment"># print(input.shape)</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Tudui</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(Tudui, self).__init__()</span><br><span class="line">        self.maxpool1=MaxPool2d(kernel_size=<span class="number">3</span>,ceil_mode=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self,input)</span>:</span></span><br><span class="line">        output=self.maxpool1(input)</span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line">tudui=Tudui()</span><br><span class="line"><span class="comment"># output=tudui(input)</span></span><br><span class="line"><span class="comment"># print(output)</span></span><br><span class="line"></span><br><span class="line">writer=SummaryWriter(<span class="string">'../logs_maxpool'</span>)</span><br><span class="line">step=<span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> dataloader:</span><br><span class="line">    imgs,targets=data</span><br><span class="line">    writer.add_images(<span class="string">'input'</span>,imgs,step)</span><br><span class="line">    output=tudui(imgs)</span><br><span class="line">    writer.add_images(<span class="string">'output'</span>,output,step)</span><br><span class="line">    step+=<span class="number">1</span></span><br><span class="line"></span><br><span class="line">writer.close()</span><br></pre></td></tr></table></div></figure></li>
<li>神经网络-非线性激活<br>增加非线性的激活函数实际上是给模型增加非线性的表达能力或者因素，有了非线性函数，模型的表达能力就会更强，整个模型就像活了一样，而不是像机器只会做单一的线性操作。没有激活函数的神经网络实际上是线性可加的，那么多线性层其实可以归为一层，只具有线性的神经网络表达能力极其有限。<br><img src="/2022/08/24/pytorch%E5%AD%A6%E4%B9%A0/relu.png" alt><br>inplace=true则替换，false则不替换。<br>一般建议inplace取false，（默认为false）保留原始数据，防止数据丢失。<br><img src="/2022/08/24/pytorch%E5%AD%A6%E4%B9%A0/relu_inplace.png" alt>  <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> ReLU, Sigmoid</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"></span><br><span class="line">input=torch.tensor([[<span class="number">1</span>,<span class="number">-0.5</span>],</span><br><span class="line">                    [<span class="number">-1</span>,<span class="number">3</span>]])</span><br><span class="line"></span><br><span class="line">input=torch.reshape(input,(<span class="number">-1</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>))</span><br><span class="line">print(input.shape)</span><br><span class="line"></span><br><span class="line">dataset=torchvision.datasets.CIFAR10(<span class="string">'../dataset'</span>,train=<span class="literal">False</span>,download=<span class="literal">True</span>,</span><br><span class="line">                                    transform=torchvision.transforms.ToTensor())</span><br><span class="line">dataloader=DataLoader(dataset,batch_size=<span class="number">64</span>)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Tudui</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(Tudui, self).__init__()</span><br><span class="line">        self.relu=ReLU()</span><br><span class="line">        self.sigmoid=Sigmoid()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self,input)</span>:</span></span><br><span class="line">        <span class="comment">#output=self.relu(input)</span></span><br><span class="line">        output=self.sigmoid(input)</span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line">tudui=Tudui()</span><br><span class="line"><span class="comment"># output=tudui(input)</span></span><br><span class="line"><span class="comment"># print(output)</span></span><br><span class="line"></span><br><span class="line">writer=SummaryWriter(<span class="string">'../logs_relu'</span>)</span><br><span class="line">step=<span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> dataloader:</span><br><span class="line">    imgs,targets=data</span><br><span class="line">    output=tudui(imgs)</span><br><span class="line">    writer.add_images(<span class="string">'input'</span>,imgs,global_step=step)</span><br><span class="line">    writer.add_images(<span class="string">'output'</span>,output,step)</span><br><span class="line">    step+=<span class="number">1</span></span><br><span class="line"></span><br><span class="line">writer.close()</span><br></pre></td></tr></table></div></figure></li>
<li>神经网络-线性层及其他层介绍  <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> Linear</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"></span><br><span class="line">dataset=torchvision.datasets.CIFAR10(<span class="string">'../dataset'</span>,train=<span class="literal">False</span>,download=<span class="literal">True</span>,transform=torchvision.transforms.ToTensor())</span><br><span class="line">dataloader=DataLoader(dataset,batch_size=<span class="number">64</span>,drop_last=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Tudui</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(Tudui, self).__init__()</span><br><span class="line">        self.linear1=Linear(<span class="number">196608</span>,<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self,input)</span>:</span></span><br><span class="line">        output=self.linear1(input)</span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line">tudui=Tudui()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> dataloader:</span><br><span class="line">    imgs,targets=data</span><br><span class="line">    print(imgs.shape)</span><br><span class="line">    <span class="comment"># output:torch.Size([64, 3, 32, 32])</span></span><br><span class="line">    <span class="comment">#output=torch.reshape(imgs,(1,1,1,-1))#四个维度等于input元素数即可，其中一项写-1会自动给你补齐</span></span><br><span class="line">    output=torch.flatten(imgs)<span class="comment">#摊平，展成一行</span></span><br><span class="line">    <span class="comment">#output:torch.Size([196608])</span></span><br><span class="line">    print(output.shape)</span><br><span class="line">    <span class="comment"># output:torch.Size([1, 1, 1, 196608])</span></span><br><span class="line">    output=tudui(output)</span><br><span class="line">    print(output.shape)</span><br></pre></td></tr></table></div></figure></li>
<li>神经网络-搭建小实战和Sequential的使用<br>cifar10 model structure<br><img src="/2022/08/24/pytorch%E5%AD%A6%E4%B9%A0/cifar10_model_structure.png" alt>  <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#cifar10模型</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> Conv2d, MaxPool2d, Flatten, Linear, Sequential</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Tudui</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(Tudui, self).__init__()<span class="comment">#父类初始化</span></span><br><span class="line">        <span class="comment">#与下述代码功能等同</span></span><br><span class="line">        <span class="comment"># self.conv1=Conv2d(3,32,5,padding=2)#如图所示input3，output32，kernel5，padding分析得出</span></span><br><span class="line">        <span class="comment"># self.maxpool1=MaxPool2d(2)#如图maxpooling2*2kernel</span></span><br><span class="line">        <span class="comment"># self.conv2=Conv2d(32,32,5,padding=2)</span></span><br><span class="line">        <span class="comment"># self.maxpool2=MaxPool2d(2)</span></span><br><span class="line">        <span class="comment"># self.conv3=Conv2d(32,64,5,padding=2)</span></span><br><span class="line">        <span class="comment"># self.maxpool3=MaxPool2d(2)</span></span><br><span class="line">        <span class="comment"># self.flatten=Flatten()</span></span><br><span class="line">        <span class="comment"># self.linear1=Linear(1024,64)#如图</span></span><br><span class="line">        <span class="comment"># self.linear2=Linear(64,10)</span></span><br><span class="line"></span><br><span class="line">        self.model1=Sequential(</span><br><span class="line">            Conv2d(<span class="number">3</span>,<span class="number">32</span>,<span class="number">5</span>,padding=<span class="number">2</span>),</span><br><span class="line">            MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            Conv2d(<span class="number">32</span>, <span class="number">32</span>, <span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            Conv2d(<span class="number">32</span>, <span class="number">64</span>, <span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            Flatten(),</span><br><span class="line">            Linear(<span class="number">1024</span>, <span class="number">64</span>),</span><br><span class="line">            Linear(<span class="number">64</span>, <span class="number">10</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self,x)</span>:</span></span><br><span class="line">        <span class="comment"># x=self.conv1(x)</span></span><br><span class="line">        <span class="comment"># x=self.maxpool1(x)</span></span><br><span class="line">        <span class="comment"># x=self.conv2(x)</span></span><br><span class="line">        <span class="comment"># x=self.maxpool2(x)</span></span><br><span class="line">        <span class="comment"># x=self.conv3(x)</span></span><br><span class="line">        <span class="comment"># x=self.maxpool3(x)</span></span><br><span class="line">        <span class="comment"># x=self.flatten(x)</span></span><br><span class="line">        <span class="comment"># x=self.linear1(x)</span></span><br><span class="line">        <span class="comment"># x=self.linear2(x)</span></span><br><span class="line">        x=self.model1(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">tudui=Tudui()<span class="comment">#实例化网络</span></span><br><span class="line">print(tudui)</span><br><span class="line">input=torch.ones(<span class="number">64</span>,<span class="number">3</span>,<span class="number">32</span>,<span class="number">32</span>)</span><br><span class="line">output=tudui(input)</span><br><span class="line">print(output.shape)</span><br><span class="line"></span><br><span class="line">writer=SummaryWriter(<span class="string">'../logs_seq'</span>)</span><br><span class="line">writer.add_graph(tudui,input)<span class="comment">#计算图</span></span><br><span class="line">writer.close()</span><br></pre></td></tr></table></div></figure>
<img src="/2022/08/24/pytorch%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E5%9B%BE.png" alt></li>
<li>损失函数与反向传播<ul>
<li>计算实际输出和目标之间的差距</li>
<li>为我们更新输出提供一定的依据（反向传播）<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> L1Loss</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line">inputs=torch.tensor([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],dtype=torch.float32)</span><br><span class="line">targets=torch.tensor([<span class="number">1</span>,<span class="number">2</span>,<span class="number">5</span>],dtype=torch.float32)</span><br><span class="line"></span><br><span class="line">inputs=torch.reshape(inputs,(<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">3</span>))</span><br><span class="line">targets=torch.reshape(targets,(<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">loss=L1Loss()</span><br><span class="line">result=loss(inputs,targets)</span><br><span class="line"></span><br><span class="line">loss_mse=nn.MSELoss()</span><br><span class="line">result_mse=loss_mse(inputs,targets)</span><br><span class="line"></span><br><span class="line">print(result)</span><br><span class="line">print(result_mse)</span><br><span class="line"></span><br><span class="line">x=torch.tensor([<span class="number">0.1</span>,<span class="number">0.2</span>,<span class="number">0.3</span>])</span><br><span class="line">y=torch.tensor([<span class="number">1</span>])</span><br><span class="line">x=torch.reshape(x,(<span class="number">1</span>,<span class="number">3</span>))</span><br><span class="line">loss_cross=nn.CrossEntropyLoss()</span><br><span class="line">result_cross=loss_cross(x,y)</span><br><span class="line">print(result_cross)</span><br></pre></td></tr></table></div></figure>
<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> Sequential, Conv2d, MaxPool2d, Flatten, Linear</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"></span><br><span class="line">dataset=torchvision.datasets.CIFAR10(<span class="string">'../dataset'</span>,train=<span class="literal">False</span>,download=<span class="literal">True</span>,</span><br><span class="line">                                    transform=torchvision.transforms.ToTensor())</span><br><span class="line">dataloader=DataLoader(dataset,batch_size=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Tudui</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(Tudui, self).__init__()</span><br><span class="line">        self.model1=Sequential(</span><br><span class="line">            Conv2d(<span class="number">3</span>, <span class="number">32</span>, <span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            Conv2d(<span class="number">32</span>, <span class="number">32</span>, <span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            Conv2d(<span class="number">32</span>, <span class="number">64</span>, <span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            Flatten(),</span><br><span class="line">            Linear(<span class="number">1024</span>, <span class="number">64</span>),</span><br><span class="line">            Linear(<span class="number">64</span>, <span class="number">10</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self,x)</span>:</span></span><br><span class="line">        x=self.model1(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">loss=nn.CrossEntropyLoss()</span><br><span class="line">tudui=Tudui()</span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> dataloader:</span><br><span class="line">    imgs,targets=data</span><br><span class="line">    output=tudui(imgs)</span><br><span class="line">    <span class="comment"># print(output)</span></span><br><span class="line">    <span class="comment"># print(targets)</span></span><br><span class="line">    result_loss=loss(output,targets)</span><br><span class="line">    print(result_loss)<span class="comment">#得到神经网络的输出和真实值的误差</span></span><br><span class="line">    result_loss.backward()</span><br><span class="line">    print(<span class="string">'ok'</span>)</span><br></pre></td></tr></table></div></figure></li>
</ul>
</li>
<li>优化器  <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> Sequential, Conv2d, MaxPool2d, Flatten, Linear</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"></span><br><span class="line">dataset=torchvision.datasets.CIFAR10(<span class="string">'../dataset'</span>,train=<span class="literal">False</span>,download=<span class="literal">True</span>,</span><br><span class="line">                                    transform=torchvision.transforms.ToTensor())</span><br><span class="line">dataloader=DataLoader(dataset,batch_size=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Tudui</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(Tudui, self).__init__()</span><br><span class="line">        self.model1=Sequential(</span><br><span class="line">            Conv2d(<span class="number">3</span>, <span class="number">32</span>, <span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            Conv2d(<span class="number">32</span>, <span class="number">32</span>, <span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            Conv2d(<span class="number">32</span>, <span class="number">64</span>, <span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            Flatten(),</span><br><span class="line">            Linear(<span class="number">1024</span>, <span class="number">64</span>),</span><br><span class="line">            Linear(<span class="number">64</span>, <span class="number">10</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self,x)</span>:</span></span><br><span class="line">        x=self.model1(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">loss=nn.CrossEntropyLoss()</span><br><span class="line">tudui=Tudui()</span><br><span class="line"><span class="comment">#学习速率太小训练的慢，太大模型不稳定，一开始用比较大的，后来用比较小的</span></span><br><span class="line">optim=torch.optim.SGD(tudui.parameters(),lr=<span class="number">0.01</span>)</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">20</span>):<span class="comment">#epoch一轮一轮的意思</span></span><br><span class="line">    running_loss=<span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> dataloader:</span><br><span class="line">        imgs,targets=data</span><br><span class="line">        output=tudui(imgs)</span><br><span class="line">        <span class="comment"># print(output)</span></span><br><span class="line">        <span class="comment"># print(targets)</span></span><br><span class="line">        result_loss=loss(output,targets)</span><br><span class="line">        optim.zero_grad()<span class="comment">#每个参数梯度清零</span></span><br><span class="line">        result_loss.backward()</span><br><span class="line">        optim.step()<span class="comment">#对每个参数调优，会跳到34行</span></span><br><span class="line">        running_loss=result_loss+result_loss<span class="comment">#所有数据整体的loss</span></span><br><span class="line">    print(running_loss)</span><br></pre></td></tr></table></div></figure></li>
<li>现有网络模型的使用及修改<br><img src="/2022/08/24/pytorch%E5%AD%A6%E4%B9%A0/vgg16_pretrained%3Dtrue.png" alt>  <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#dataset:ImageNet</span></span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line"><span class="comment"># train_data=torchvision.datasets.ImageNet('../data_image_net',split='train',download=True,</span></span><br><span class="line"><span class="comment">#                                         transform=torchvision.transforms.ToTensor())</span></span><br><span class="line"></span><br><span class="line">vgg16_false=torchvision.models.vgg16(pretrainde=<span class="literal">False</span>)</span><br><span class="line">vgg16_true=torchvision.models.vgg16(pretrainde=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># print('ok')</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># vgg16_true.add_module('add_linear',nn.Linear(1000,10))</span></span><br><span class="line">vgg16_true.classifier.add_module(<span class="string">'add_linear'</span>,nn.Linear(<span class="number">1000</span>,<span class="number">10</span>))</span><br><span class="line">print(vgg16_true)</span><br><span class="line"></span><br><span class="line">print(vgg16_false)</span><br><span class="line">vgg16_false.classifier[<span class="number">6</span>]=nn.Linear(<span class="number">4096</span>,<span class="number">10</span>)<span class="comment">#修改</span></span><br><span class="line">print(vgg16_false)</span><br></pre></td></tr></table></div></figure>
vgg16_add_module<br><img src="/2022/08/24/pytorch%E5%AD%A6%E4%B9%A0/vgg16_add_module.png" alt></li>
<li>网络模型的保存与读取<ul>
<li>模型的保存  <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line">vgg16=torchvision.models.vgg16(pretrained=<span class="literal">False</span>)</span><br><span class="line"><span class="comment">#保存方式1模型结构+模型参数</span></span><br><span class="line">torch.save(vgg16,<span class="string">'vgg16_method1.pth'</span>)<span class="comment">#.pth常用的后缀模式</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#保存方式2模型参数（官方推荐的保存方式）</span></span><br><span class="line">torch.save(vgg16.state_dict(),<span class="string">'vgg16_method2.pth'</span>)<span class="comment">#vgg16状态保存成字典格式</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#陷阱</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Tudui</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(Tudui, self).__init__()</span><br><span class="line">        self.conv1=nn.Conv2d(<span class="number">3</span>,<span class="number">64</span>,kernel_size=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self,x)</span>:</span></span><br><span class="line">        x=self.conv1(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">tudui=Tudui()</span><br><span class="line">torch.save(tudui,<span class="string">'tudui_method1.pth'</span>)</span><br></pre></td></tr></table></div></figure></li>
<li>模型的加载  <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line"><span class="comment">#方式1 -&gt;保存方式1，加载模型</span></span><br><span class="line"><span class="comment"># model=torch.load('vgg16_method1.pth')</span></span><br><span class="line"><span class="comment"># print(model)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#方式2加载模型</span></span><br><span class="line">vgg16=torchvision.models.vgg16(pretrained=<span class="literal">False</span>)<span class="comment">#预训练设置为false</span></span><br><span class="line">vgg16.load_state_dict(torch.load(<span class="string">'vgg16_method2.pth'</span>))</span><br><span class="line"><span class="comment">#model=torch.load('vgg16_method2.pth')</span></span><br><span class="line">print(vgg16)</span><br><span class="line"></span><br><span class="line"><span class="comment">#陷阱1</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Tudui</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(Tudui, self).__init__()</span><br><span class="line">        self.conv1=nn.Conv2d(<span class="number">3</span>,<span class="number">64</span>,kernel_size=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self,x)</span>:</span></span><br><span class="line">        x=self.conv1(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">model=torch.load(<span class="string">'tudui_method1.pth'</span>)</span><br><span class="line">print(model)</span><br></pre></td></tr></table></div></figure>
  <br>

</li>
</ul>
</li>
</ul>

        <h3 id="6-完整的模型训练套路">
          <a href="#6-完整的模型训练套路" class="heading-link"><i class="fas fa-link"></i></a><a href="#6-完整的模型训练套路" class="headerlink" title="6.完整的模型训练套路"></a>6.完整的模型训练套路</h3>
      <ul>
<li>准备数据集dataset</li>
<li>加载数据集dataloader</li>
<li>创建网络模型、损失函数、优化器</li>
<li>设置训练中的参数</li>
<li>设置训练轮数epoch</li>
<li>开始训练tudui.train()(此行代码意义不大)</li>
<li>优化器优化</li>
<li>开始测试tudui.eval() with torch.no_grad()</li>
<li>保存模型<br>以cifar10数据集为例  <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"><span class="comment">#准备数据集</span></span><br><span class="line">train_data=torchvision.datasets.CIFAR10(root=<span class="string">'../dataset'</span>,train=<span class="literal">True</span>,transform=torchvision.transforms.ToTensor(),</span><br><span class="line">                                        download=<span class="literal">True</span>)</span><br><span class="line">test_data=torchvision.datasets.CIFAR10(root=<span class="string">'../dataset'</span>,train=<span class="literal">False</span>,transform=torchvision.transforms.ToTensor(),</span><br><span class="line">                                    download=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#length长度</span></span><br><span class="line">train_data_size=len(train_data)</span><br><span class="line">test_data_size=len(test_data)</span><br><span class="line"><span class="comment">#如果train_data_size=10，训练数据集的长度为：10</span></span><br><span class="line"><span class="comment">#ctrl+d可以复制当前行</span></span><br><span class="line">print(<span class="string">'训练数据集长度为：&#123;&#125;'</span>.format(train_data_size))</span><br><span class="line">print(<span class="string">'测试数据集长度为：&#123;&#125;'</span>.format(test_data_size))</span><br><span class="line"></span><br><span class="line"><span class="comment">#利用dataloader来加载数据集</span></span><br><span class="line">train_dataloader=DataLoader(dataset=train_data,batch_size=<span class="number">64</span>)</span><br><span class="line">test_dataloader=DataLoader(dataset=test_data,batch_size=<span class="number">64</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># #搭建神经网络，见model.py</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#创建网络模型</span></span><br><span class="line">tudui=Tudui()</span><br><span class="line"></span><br><span class="line"><span class="comment">#损失函数</span></span><br><span class="line">loss_fn=nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line"><span class="comment">#优化器</span></span><br><span class="line"><span class="comment">#learning_rate=0.01</span></span><br><span class="line"><span class="comment">#1e-2=1*10^(-2)=1/100=0.01</span></span><br><span class="line">learning_rate=<span class="number">1e-2</span></span><br><span class="line">optimizer=torch.optim.SGD(tudui.parameters(),lr=learning_rate)</span><br><span class="line"></span><br><span class="line"><span class="comment">#设置训练网络的一些参数</span></span><br><span class="line">total_train_step=<span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#记录测试的次数</span></span><br><span class="line">total_test_step=<span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#训练次数</span></span><br><span class="line">epoch=<span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#添加tensorboard</span></span><br><span class="line">writer=SummaryWriter(<span class="string">'../logs_train'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(epoch):</span><br><span class="line">    print(<span class="string">'------第&#123;&#125;轮训练开始------'</span>.format(i+<span class="number">1</span>))</span><br><span class="line">    <span class="comment">#训练开始</span></span><br><span class="line">    tudui.train()</span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> train_dataloader:</span><br><span class="line">        imgs,targets=data</span><br><span class="line">        outputs=tudui(imgs)</span><br><span class="line">        loss=loss_fn(outputs,targets)</span><br><span class="line">        <span class="comment">#优化器优化模型</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        total_train_step+=<span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> total_train_step%<span class="number">100</span>==<span class="number">0</span>:</span><br><span class="line">            print(<span class="string">'训练次数：&#123;&#125;,Loss:&#123;&#125;'</span>.format(total_train_step,loss.item()))</span><br><span class="line">            writer.add_scalar(<span class="string">'train_loss'</span>,loss.item(),total_train_step)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#判断模型是否训练好：每次训练完之后在测试数据集上跑一遍，以测试数据集的损失或正确率来评估模型是否训练好</span></span><br><span class="line">    <span class="comment">#测试步骤开始</span></span><br><span class="line">    tudui.eval()</span><br><span class="line">    total_test_loss=<span class="number">0</span></span><br><span class="line">    total_accuracy=<span class="number">0</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():<span class="comment">#没有梯度调优，便于测试</span></span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> test_dataloader:</span><br><span class="line">            imgs,targets=data</span><br><span class="line">            outputs=tudui(imgs)</span><br><span class="line">            loss=loss_fn(outputs,targets)</span><br><span class="line">            total_test_loss+=loss.item()</span><br><span class="line">            accuracy=(outputs.argmax(<span class="number">1</span>)==targets).sum()</span><br><span class="line">            total_accuracy+=accuracy</span><br><span class="line">    print(<span class="string">'整体测试集上的Loss:&#123;&#125;'</span>.format(total_test_loss))</span><br><span class="line">    print(<span class="string">'整体测试集上的正确率：&#123;&#125;'</span>.format(total_accuracy/test_data_size))</span><br><span class="line">    writer.add_scalar(<span class="string">'test_loss'</span>,total_test_loss,total_test_step)</span><br><span class="line">    writer.add_scalar(<span class="string">'test_accuracy'</span>,total_accuracy/test_data_size,total_test_step)</span><br><span class="line">    total_test_step+=<span class="number">1</span></span><br><span class="line"></span><br><span class="line">    torch.save(tudui,<span class="string">'tudui_&#123;&#125;.pth'</span>.format(i))</span><br><span class="line">    <span class="comment">#torch.save(tudui,'tudui_&#123;&#125;.pth'.format(i))#方式二</span></span><br><span class="line">    print(<span class="string">'模型已保存'</span>)</span><br><span class="line">writer.close()</span><br></pre></td></tr></table></div></figure>
  <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#test</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">a=torch.tensor(<span class="number">5</span>)</span><br><span class="line">print(a)</span><br><span class="line"><span class="comment">#item()会把tensor数据类型转换成真实的数字</span></span><br><span class="line">print(a.item())</span><br></pre></td></tr></table></div></figure>
  <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#test2</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">outputs=torch.tensor([[<span class="number">0.1</span>,<span class="number">0.2</span>],</span><br><span class="line">                    [<span class="number">0.05</span>,<span class="number">0.4</span>]])</span><br><span class="line">print(outputs.argmax(<span class="number">1</span>))<span class="comment">#为1的时候横向看 0.2和0.4最大，所以结果为1，1</span></span><br><span class="line">print(outputs.argmax(<span class="number">0</span>))<span class="comment">#为0的时候纵向看 0.1和0.4最大，所以结果为0，1</span></span><br><span class="line">preds=outputs.argmax(<span class="number">1</span>)</span><br><span class="line">targets=torch.tensor([<span class="number">0</span>,<span class="number">1</span>])</span><br><span class="line">print((preds==targets).sum())<span class="comment">#相等返回true，不相等返回false</span></span><br></pre></td></tr></table></div></figure>
  <br>

</li>
</ul>

        <h3 id="7-利用GPU训练">
          <a href="#7-利用GPU训练" class="heading-link"><i class="fas fa-link"></i></a><a href="#7-利用GPU训练" class="headerlink" title="7.利用GPU训练"></a>7.利用GPU训练</h3>
      <p>若没有GPU，可访问Google colab<br>方式一</p>
<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"></span><br><span class="line"><span class="comment">#准备数据集</span></span><br><span class="line">train_data=torchvision.datasets.CIFAR10(root=<span class="string">'../dataset'</span>,train=<span class="literal">True</span>,transform=torchvision.transforms.ToTensor(),</span><br><span class="line">                                        download=<span class="literal">True</span>)</span><br><span class="line">test_data=torchvision.datasets.CIFAR10(root=<span class="string">'../dataset'</span>,train=<span class="literal">False</span>,transform=torchvision.transforms.ToTensor(),</span><br><span class="line">                                       download=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#length长度</span></span><br><span class="line">train_data_size=len(train_data)</span><br><span class="line">test_data_size=len(test_data)</span><br><span class="line"><span class="comment">#如果train_data_size=10，训练数据集的长度为：10</span></span><br><span class="line"><span class="comment">#ctrl+d可以复制当前行</span></span><br><span class="line">print(<span class="string">'训练数据集长度为：&#123;&#125;'</span>.format(train_data_size))</span><br><span class="line">print(<span class="string">'测试数据集长度为：&#123;&#125;'</span>.format(test_data_size))</span><br><span class="line"></span><br><span class="line"><span class="comment">#利用dataloader来加载数据集</span></span><br><span class="line">train_dataloader=DataLoader(dataset=train_data,batch_size=<span class="number">64</span>)</span><br><span class="line">test_dataloader=DataLoader(dataset=test_data,batch_size=<span class="number">64</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#搭建神经网络</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Tudui</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(Tudui, self).__init__()</span><br><span class="line">        self.model=nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">3</span>,<span class="number">32</span>,<span class="number">5</span>,<span class="number">1</span>,<span class="number">2</span>),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">32</span>,<span class="number">32</span>,<span class="number">5</span>,<span class="number">1</span>,<span class="number">2</span>),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">32</span>,<span class="number">64</span>,<span class="number">5</span>,<span class="number">1</span>,<span class="number">2</span>),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            nn.Flatten(),</span><br><span class="line">            nn.Linear(<span class="number">64</span>*<span class="number">4</span>*<span class="number">4</span>,<span class="number">64</span>),</span><br><span class="line">            nn.Linear(<span class="number">64</span>,<span class="number">10</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self,x)</span>:</span></span><br><span class="line">        x=self.model(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"><span class="comment">#创建网络模型</span></span><br><span class="line">tudui=Tudui()</span><br><span class="line"><span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">    tudui=tudui.cuda()</span><br><span class="line"></span><br><span class="line"><span class="comment">#损失函数</span></span><br><span class="line">loss_fn=nn.CrossEntropyLoss()</span><br><span class="line"><span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">    loss_fn=loss_fn.cuda()</span><br><span class="line"></span><br><span class="line"><span class="comment">#优化器</span></span><br><span class="line"><span class="comment">#learning_rate=0.01</span></span><br><span class="line"><span class="comment">#1e-2=1*10^(-2)=1/100=0.01</span></span><br><span class="line">learning_rate=<span class="number">1e-2</span></span><br><span class="line">optimizer=torch.optim.SGD(tudui.parameters(),lr=learning_rate)</span><br><span class="line"></span><br><span class="line"><span class="comment">#设置训练网络的一些参数</span></span><br><span class="line">total_train_step=<span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#记录测试的次数</span></span><br><span class="line">total_test_step=<span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#训练次数</span></span><br><span class="line">epoch=<span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#添加tensorboard</span></span><br><span class="line">writer=SummaryWriter(<span class="string">'../logs_train'</span>)</span><br><span class="line">strat_time=time.time()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(epoch):</span><br><span class="line">    print(<span class="string">'------第&#123;&#125;轮训练开始------'</span>.format(i+<span class="number">1</span>))</span><br><span class="line">    <span class="comment">#训练步骤开始</span></span><br><span class="line">    tudui.train()</span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> train_dataloader:</span><br><span class="line">        imgs,targets=data</span><br><span class="line">        <span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">            imgs=imgs.cuda()</span><br><span class="line">            targets=targets.cuda()</span><br><span class="line">        outputs=tudui(imgs)</span><br><span class="line">        loss=loss_fn(outputs,targets)</span><br><span class="line">        <span class="comment">#优化器优化模型</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        total_train_step+=<span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> total_train_step%<span class="number">100</span>==<span class="number">0</span>:</span><br><span class="line">            end_time = time.time()</span><br><span class="line">            print(end_time-strat_time)</span><br><span class="line">            print(<span class="string">'训练次数：&#123;&#125;,Loss:&#123;&#125;'</span>.format(total_train_step,loss.item()))</span><br><span class="line">            writer.add_scalar(<span class="string">'train_loss'</span>,loss.item(),total_train_step)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#判断模型是否训练好：每次训练完之后在测试数据集上跑一遍，以测试数据集的损失或正确率来评估模型是否训练好</span></span><br><span class="line">    <span class="comment">#测试步骤开始</span></span><br><span class="line">    tudui.eval()</span><br><span class="line">    total_test_loss=<span class="number">0</span></span><br><span class="line">    total_accuracy=<span class="number">0</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():<span class="comment">#没有梯度调优，便于测试</span></span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> test_dataloader:</span><br><span class="line">            imgs,targets=data</span><br><span class="line">            <span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">                imgs = imgs.cuda()</span><br><span class="line">                targets = targets.cuda()</span><br><span class="line">            outputs=tudui(imgs)</span><br><span class="line">            loss=loss_fn(outputs,targets)</span><br><span class="line">            total_test_loss+=loss.item()</span><br><span class="line">            accuracy=(outputs.argmax(<span class="number">1</span>)==targets).sum()</span><br><span class="line">            total_accuracy+=accuracy</span><br><span class="line">    print(<span class="string">'整体测试集上的Loss:&#123;&#125;'</span>.format(total_test_loss))</span><br><span class="line">    print(<span class="string">'整体测试集上的正确率：&#123;&#125;'</span>.format(total_accuracy/test_data_size))</span><br><span class="line">    writer.add_scalar(<span class="string">'test_loss'</span>,total_test_loss,total_test_step)</span><br><span class="line">    writer.add_scalar(<span class="string">'test_accuracy'</span>,total_accuracy/test_data_size,total_test_step)</span><br><span class="line">    total_test_step+=<span class="number">1</span></span><br><span class="line"></span><br><span class="line">    torch.save(tudui,<span class="string">'tudui_&#123;&#125;.pth'</span>.format(i))</span><br><span class="line">    <span class="comment">#torch.save(tudui,'tudui_&#123;&#125;.pth'.format(i))#方式二</span></span><br><span class="line">    print(<span class="string">'模型已保存'</span>)</span><br><span class="line">writer.close()</span><br></pre></td></tr></table></div></figure>
<p>方式二</p>
<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#定义了训练的设备</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"></span><br><span class="line"><span class="comment">#定义训练的设备</span></span><br><span class="line">device=torch.device(<span class="string">'cuda'</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">'cpu'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#准备数据集</span></span><br><span class="line">train_data=torchvision.datasets.CIFAR10(root=<span class="string">'../dataset'</span>,train=<span class="literal">True</span>,transform=torchvision.transforms.ToTensor(),</span><br><span class="line">                                        download=<span class="literal">True</span>)</span><br><span class="line">test_data=torchvision.datasets.CIFAR10(root=<span class="string">'../dataset'</span>,train=<span class="literal">False</span>,transform=torchvision.transforms.ToTensor(),</span><br><span class="line">                                       download=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#length长度</span></span><br><span class="line">train_data_size=len(train_data)</span><br><span class="line">test_data_size=len(test_data)</span><br><span class="line"><span class="comment">#如果train_data_size=10，训练数据集的长度为：10</span></span><br><span class="line"><span class="comment">#ctrl+d可以复制当前行</span></span><br><span class="line">print(<span class="string">'训练数据集长度为：&#123;&#125;'</span>.format(train_data_size))</span><br><span class="line">print(<span class="string">'测试数据集长度为：&#123;&#125;'</span>.format(test_data_size))</span><br><span class="line"></span><br><span class="line"><span class="comment">#利用dataloader来加载数据集</span></span><br><span class="line">train_dataloader=DataLoader(dataset=train_data,batch_size=<span class="number">64</span>)</span><br><span class="line">test_dataloader=DataLoader(dataset=test_data,batch_size=<span class="number">64</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#搭建神经网络</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Tudui</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(Tudui, self).__init__()</span><br><span class="line">        self.model=nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">3</span>,<span class="number">32</span>,<span class="number">5</span>,<span class="number">1</span>,<span class="number">2</span>),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">32</span>,<span class="number">32</span>,<span class="number">5</span>,<span class="number">1</span>,<span class="number">2</span>),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">32</span>,<span class="number">64</span>,<span class="number">5</span>,<span class="number">1</span>,<span class="number">2</span>),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            nn.Flatten(),</span><br><span class="line">            nn.Linear(<span class="number">64</span>*<span class="number">4</span>*<span class="number">4</span>,<span class="number">64</span>),</span><br><span class="line">            nn.Linear(<span class="number">64</span>,<span class="number">10</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self,x)</span>:</span></span><br><span class="line">        x=self.model(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"><span class="comment">#创建网络模型</span></span><br><span class="line">tudui=Tudui()</span><br><span class="line">tudui=tudui.to(device)</span><br><span class="line"></span><br><span class="line"><span class="comment">#损失函数</span></span><br><span class="line">loss_fn=nn.CrossEntropyLoss()</span><br><span class="line">loss_fn=loss_fn.to(device)</span><br><span class="line"></span><br><span class="line"><span class="comment">#优化器</span></span><br><span class="line"><span class="comment">#learning_rate=0.01</span></span><br><span class="line"><span class="comment">#1e-2=1*10^(-2)=1/100=0.01</span></span><br><span class="line">learning_rate=<span class="number">1e-2</span></span><br><span class="line">optimizer=torch.optim.SGD(tudui.parameters(),lr=learning_rate)</span><br><span class="line"></span><br><span class="line"><span class="comment">#设置训练网络的一些参数</span></span><br><span class="line">total_train_step=<span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#记录测试的次数</span></span><br><span class="line">total_test_step=<span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#训练次数</span></span><br><span class="line">epoch=<span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#添加tensorboard</span></span><br><span class="line">writer=SummaryWriter(<span class="string">'../logs_train'</span>)</span><br><span class="line">strat_time=time.time()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(epoch):</span><br><span class="line">    print(<span class="string">'------第&#123;&#125;轮训练开始------'</span>.format(i+<span class="number">1</span>))</span><br><span class="line">    <span class="comment">#训练步骤开始</span></span><br><span class="line">    tudui.train()</span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> train_dataloader:</span><br><span class="line">        imgs,targets=data</span><br><span class="line">        imgs=imgs.to(device)</span><br><span class="line">        targets=targets.to(device)</span><br><span class="line">        outputs=tudui(imgs)</span><br><span class="line">        loss=loss_fn(outputs,targets)</span><br><span class="line">        <span class="comment">#优化器优化模型</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        total_train_step+=<span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> total_train_step%<span class="number">100</span>==<span class="number">0</span>:</span><br><span class="line">            end_time = time.time()</span><br><span class="line">            print(end_time-strat_time)</span><br><span class="line">            print(<span class="string">'训练次数：&#123;&#125;,Loss:&#123;&#125;'</span>.format(total_train_step,loss.item()))</span><br><span class="line">            writer.add_scalar(<span class="string">'train_loss'</span>,loss.item(),total_train_step)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#判断模型是否训练好：每次训练完之后在测试数据集上跑一遍，以测试数据集的损失或正确率来评估模型是否训练好</span></span><br><span class="line">    <span class="comment">#测试步骤开始</span></span><br><span class="line">    tudui.eval()</span><br><span class="line">    total_test_loss=<span class="number">0</span></span><br><span class="line">    total_accuracy=<span class="number">0</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():<span class="comment">#没有梯度调优，便于测试</span></span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> test_dataloader:</span><br><span class="line">            imgs,targets=data</span><br><span class="line">            imgs = imgs.to(device)</span><br><span class="line">            targets = targets.to(device)</span><br><span class="line">            outputs=tudui(imgs)</span><br><span class="line">            loss=loss_fn(outputs,targets)</span><br><span class="line">            total_test_loss+=loss.item()</span><br><span class="line">            accuracy=(outputs.argmax(<span class="number">1</span>)==targets).sum()</span><br><span class="line">            total_accuracy+=accuracy</span><br><span class="line">    print(<span class="string">'整体测试集上的Loss:&#123;&#125;'</span>.format(total_test_loss))</span><br><span class="line">    print(<span class="string">'整体测试集上的正确率：&#123;&#125;'</span>.format(total_accuracy/test_data_size))</span><br><span class="line">    writer.add_scalar(<span class="string">'test_loss'</span>,total_test_loss,total_test_step)</span><br><span class="line">    writer.add_scalar(<span class="string">'test_accuracy'</span>,total_accuracy/test_data_size,total_test_step)</span><br><span class="line">    total_test_step+=<span class="number">1</span></span><br><span class="line"></span><br><span class="line">    torch.save(tudui,<span class="string">'tudui_&#123;&#125;.pth'</span>.format(i))</span><br><span class="line">    <span class="comment">#torch.save(tudui,'tudui_&#123;&#125;.pth'.format(i))#方式二</span></span><br><span class="line">    print(<span class="string">'模型已保存'</span>)</span><br><span class="line">writer.close()</span><br></pre></td></tr></table></div></figure>

        <h3 id="8-完整的模型验证（测试，demo）套路">
          <a href="#8-完整的模型验证（测试，demo）套路" class="heading-link"><i class="fas fa-link"></i></a><a href="#8-完整的模型验证（测试，demo）套路" class="headerlink" title="8.完整的模型验证（测试，demo）套路"></a>8.完整的模型验证（测试，demo）套路</h3>
      <p>利用已经训练好的模型，然后给它提供输入</p>
<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line">image_path=<span class="string">'../images/QQ图片201802031008421.jpg'</span></span><br><span class="line">image=Image.open(image_path)<span class="comment">#PIL类型</span></span><br><span class="line">print(image)</span><br><span class="line"><span class="comment">#因为png格式是四个通道，除了RGB三通道外，还有一个透明度通道。所以，外面调用下述代码，保留其颜色通道</span></span><br><span class="line"><span class="comment">#当然，如果图片本来就是三个颜色通道，经过此操作，不变。加上这一步后，可以适应png jpg各种格式的图片</span></span><br><span class="line">image=image.convert(<span class="string">'RGB'</span>)</span><br><span class="line">transform=torchvision.transforms.Compose([torchvision.transforms.Resize((<span class="number">32</span>,<span class="number">32</span>)),</span><br><span class="line">                                          torchvision.transforms.ToTensor()])</span><br><span class="line">image=transform(image)</span><br><span class="line">print(image.shape)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Tudui</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(Tudui, self).__init__()</span><br><span class="line">        self.model=nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">3</span>,<span class="number">32</span>,<span class="number">5</span>,<span class="number">1</span>,<span class="number">2</span>),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">32</span>,<span class="number">32</span>,<span class="number">5</span>,<span class="number">1</span>,<span class="number">2</span>),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">32</span>,<span class="number">64</span>,<span class="number">5</span>,<span class="number">1</span>,<span class="number">2</span>),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            nn.Flatten(),</span><br><span class="line">            nn.Linear(<span class="number">64</span>*<span class="number">4</span>*<span class="number">4</span>,<span class="number">64</span>),</span><br><span class="line">            nn.Linear(<span class="number">64</span>,<span class="number">10</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self,x)</span>:</span></span><br><span class="line">        x=self.model(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">model=torch.load(<span class="string">'tudui_0.pth'</span>,map_location=torch.device(<span class="string">'cpu'</span>))</span><br><span class="line">print(model)</span><br><span class="line">image=torch.reshape(image,(<span class="number">1</span>,<span class="number">3</span>,<span class="number">32</span>,<span class="number">32</span>))</span><br><span class="line">model.eval()</span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    output=model(image)</span><br><span class="line">print(output)</span><br><span class="line"></span><br><span class="line">print(output.argmax(<span class="number">1</span>))</span><br></pre></td></tr></table></div></figure></div></div></article><article class="postlist-item post"><header class="post-header"><h1 class="post-title"><a class="post-title__link" href="/2022/07/07/pytorch%E7%8E%AF%E5%A2%83%E7%9A%84%E9%85%8D%E7%BD%AE%E4%B8%8E%E5%AE%89%E8%A3%85/">pytorch环境的配置与安装</a></h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">Created</span><span class="post-meta-item__value">2022-07-07</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">Updated</span><span class="post-meta-item__value">2022-07-07</span></span></div></header><div class="post-body"><div class="post-excerpt">
        <h2 id="1-默认已经安装了Anaconda">
          <a href="#1-默认已经安装了Anaconda" class="heading-link"><i class="fas fa-link"></i></a><a href="#1-默认已经安装了Anaconda" class="headerlink" title="1.默认已经安装了Anaconda"></a>1.默认已经安装了Anaconda</h2>
      
        <h2 id="2-Anaconda-Prompt">
          <a href="#2-Anaconda-Prompt" class="heading-link"><i class="fas fa-link"></i></a><a href="#2-Anaconda-Prompt" class="headerlink" title="2.Anaconda Prompt"></a>2.Anaconda Prompt</h2>
      <ul>
<li>根据自己的python版本创建pytorch环境  <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda create -n pytorch python=<span class="number">3.7</span></span><br></pre></td></tr></table></div></figure></li>
<li>激活环境  <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda activate pytorch</span><br></pre></td></tr></table></div></figure>
  左边括号里的环境由base变成了pytorch</li>
<li>安装pytorch<ul>
<li>看下环境中的工具包，并没有pytorch  <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip list</span><br></pre></td></tr></table></div></figure></li>
<li>查看电脑cuda版本<ul>
<li>桌面右键-NVIDIA控制面板-帮助-系统信息-组件-NVCUDA64.DLL,cuda版本向下兼容</li>
</ul>
</li>
<li><span class="exturl"><a class="exturl__link" href="https://pytorch.org/" target="_blank" rel="noopener">pytorch官网</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span><ul>
<li>找到适合自己的版本，复制命令  <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda install pytorch torchvision torchaudio cudatoolkit=<span class="number">11.3</span> -c pytorch</span><br></pre></td></tr></table></div></figure></li>
</ul>
</li>
</ul>
</li>
<li>直接用命令安装较慢，可用镜像安装或先下载对应版本的pytorch和torchvision安装包，然后本地安装，我选择了离线安装<ul>
<li><span class="exturl"><a class="exturl__link" href="https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/win-64/" target="_blank" rel="noopener">清华镜像</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span><figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#install后面为安装包的文件路径</span></span><br><span class="line">conda install D:\pytorch<span class="number">-1.6</span><span class="number">.0</span>-py3<span class="number">.8</span>_cpu_0.tar.bz2</span><br><span class="line">conda install D:\torchvision<span class="number">-0.7</span><span class="number">.0</span>-py38_cpu.tar.bz2</span><br></pre></td></tr></table></div></figure></li>
<li>验证是否安装成功<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">python</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="comment">#若没报错则安装成功</span></span><br></pre></td></tr></table></div></figure></li>
<li>报错<ul>
<li>winerror:126找不到指定模块<ul>
<li>升级numpy（命令中有提示，复制即可）  <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda update -n base -c defaults conda</span><br></pre></td></tr></table></div></figure></li>
<li>没有安装cudatoolkit<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#版本要对应</span></span><br><span class="line">conda install cudatoolkit=<span class="number">11.3</span></span><br></pre></td></tr></table></div></figure></li>
</ul>
</li>
<li>依旧报错，缺少依赖包，再次执行下载命令   <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda install pytorch torchvision torchaudio cudatoolkit=<span class="number">11.3</span> -c pytorch</span><br></pre></td></tr></table></div></figure></li>
<li>检验安装成功  <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">pip list</span><br><span class="line"><span class="comment">#发现有torch</span></span><br><span class="line">python</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="comment">#无报错信息</span></span><br><span class="line"> torch.cuda.is_available()</span><br><span class="line"> <span class="comment">#检验pytorch是否可以用GPU，返回True</span></span><br></pre></td></tr></table></div></figure></li>
</ul>
</li>
<li>附：镜像安装<ul>
<li>anaconda prompt      <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/</span><br><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/</span><br><span class="line">conda config --set show_channel_urls yes</span><br><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/</span><br><span class="line">conda install pytorch torchvision torchaudio cudatoolkit=<span class="number">11.3</span></span><br><span class="line"><span class="comment">#删去-c pytorch</span></span><br></pre></td></tr></table></div></figure></li>
<li>安装成功<br>              
        <h2 id="3-Jupyter-Notebook">
          <a href="#3-Jupyter-Notebook" class="heading-link"><i class="fas fa-link"></i></a><a href="#3-Jupyter-Notebook" class="headerlink" title="3.Jupyter Notebook"></a>3.Jupyter Notebook</h2>
      </li>
</ul>
</li>
</ul>
</li>
<li>Jupyter默认安装在base环境下，但是base环境中没有安装 Pytorch，所以需要在pytorch环境下安装Jupyter</li>
<li>Anaconda Prompt  <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#base环境可以看到有要用到的package-ipykernel</span></span><br><span class="line">conda list</span><br><span class="line"><span class="comment">#进入pytorch环境，发现没有</span></span><br><span class="line">conda activate pytorch</span><br><span class="line">conda list</span><br><span class="line"><span class="comment">#安装</span></span><br><span class="line">conda install nb_conda</span><br><span class="line">jupyter notebook</span><br><span class="line"><span class="comment">#新建</span></span><br><span class="line">New-Python[conda env:pytorch]*</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"> torch.cuda.is_available()</span><br><span class="line"> <span class="comment">#返回true</span></span><br></pre></td></tr></table></div></figure></li>
</ul>
</div></div></article><article class="postlist-item post"><header class="post-header"><h1 class="post-title"><a class="post-title__link" href="/2022/06/24/DRF/">DRF</a></h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">Created</span><span class="post-meta-item__value">2022-06-24</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">Updated</span><span class="post-meta-item__value">2022-05-16</span></span></div></header><div class="post-body"><div class="post-excerpt">
        <h2 id="1-增删改查接口">
          <a href="#1-增删改查接口" class="heading-link"><i class="fas fa-link"></i></a><a href="#1-增删改查接口" class="headerlink" title="1.增删改查接口"></a><strong>1.增删改查接口</strong></h2>
      <ul>
<li>views.py  <figure class="highlight py"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">GET /books/ 提供所有记录</span></span><br><span class="line"><span class="string">POST /books/ 新增一条记录</span></span><br><span class="line"><span class="string">GET /books/&lt;pk&gt;/ 提供指定id的记录</span></span><br><span class="line"><span class="string">PUT /books/&lt;pk&gt;/ 修改指定id的记录</span></span><br><span class="line"><span class="string">DELETE /books/&lt;pk&gt;/ 删除指定id的记录</span></span><br><span class="line"><span class="string">响应数据 JSON</span></span><br><span class="line"><span class="string">列表视图：路由后面没有pk/ID</span></span><br><span class="line"><span class="string">详情视图：路由后面pk/ID</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="comment">#192.168.103.210</span></span><br><span class="line"><span class="keyword">from</span> django.views <span class="keyword">import</span> View</span><br><span class="line"><span class="keyword">from</span> django.http <span class="keyword">import</span> HttpResponse,JsonResponse</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> .models <span class="keyword">import</span> BookInfo</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BookListView</span><span class="params">(View)</span>:</span></span><br><span class="line">    <span class="string">'''列表视图'''</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get</span><span class="params">(self,request)</span>:</span></span><br><span class="line">        <span class="string">'''查询所有图书接口'''</span></span><br><span class="line">        <span class="comment">#1.查询出所有图书模型</span></span><br><span class="line">        books=BookInfo.objects.all()</span><br><span class="line">        <span class="comment">#2.遍历查询集，取出里面的每个书籍模型对象，把模型对象转换成字典</span></span><br><span class="line">        <span class="comment">#定义一个列表变量用来保存多个字典</span></span><br><span class="line">        book_list=[]</span><br><span class="line">        <span class="keyword">for</span> book <span class="keyword">in</span> books:</span><br><span class="line">            book_dict=&#123;</span><br><span class="line">                <span class="string">'id'</span>:book.id,</span><br><span class="line">                <span class="string">'btitle'</span>:book.btitle,</span><br><span class="line">                <span class="string">'bpub_date'</span>:book.bpub_date,</span><br><span class="line">                <span class="string">'bread'</span>:book.bread,</span><br><span class="line">                <span class="string">'bcomment'</span>:book.bcomment,</span><br><span class="line">                <span class="string">'image'</span>:book.image.url <span class="keyword">if</span> book.image <span class="keyword">else</span> <span class="string">''</span><span class="comment">#if不成立为None.url，返回空字符串</span></span><br><span class="line">            &#125;</span><br><span class="line">            book_list.append(book_dict)<span class="comment">#将转换好的字典添加到列表中</span></span><br><span class="line">        <span class="comment">#3.响应</span></span><br><span class="line">        <span class="keyword">return</span> JsonResponse(book_list,safe=<span class="literal">False</span>)<span class="comment">#如果book_list不是一个字典的话就需要将safe设置成False</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">post</span><span class="params">(self,request)</span>:</span></span><br><span class="line">        <span class="string">'''新增图书接口'''</span></span><br><span class="line">        <span class="comment">#获取前端传入的请求体数据（json） request.body</span></span><br><span class="line">        json_str_bytes=request.body</span><br><span class="line">        <span class="comment">#把bytes类型的json字符串转换成json_str</span></span><br><span class="line">        json_str=json_str_bytes.decode()</span><br><span class="line">        <span class="comment">#利用json.loads将json字符串转换成json（字典、列表）</span></span><br><span class="line">        book_dict=json.loads(json_str)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#创建模型对象并保存（把字典转换成模型并存储）</span></span><br><span class="line">        book=BookInfo(</span><br><span class="line">            btitle=book_dict[<span class="string">'btitle'</span>],</span><br><span class="line">            bpub_date=book_dict[<span class="string">'bpub_date'</span>],</span><br><span class="line">        )</span><br><span class="line">        book.save()</span><br><span class="line">        <span class="comment">#把新增的模型转换成字典</span></span><br><span class="line">        json_dict = &#123;</span><br><span class="line">            <span class="string">'id'</span>: book.id,</span><br><span class="line">            <span class="string">'btitle'</span>: book.btitle,</span><br><span class="line">            <span class="string">'bpub_date'</span>: book.bpub_date,</span><br><span class="line">            <span class="string">'bread'</span>: book.bread,</span><br><span class="line">            <span class="string">'bcomment'</span>: book.bcomment,</span><br><span class="line">            <span class="string">'image'</span>: book.image.url <span class="keyword">if</span> book.image <span class="keyword">else</span> <span class="string">''</span>  <span class="comment"># if不成立为None.url，返回空字符串</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">#响应（把新增的数据再响应回去，201）</span></span><br><span class="line">        <span class="keyword">return</span> JsonResponse(json_dict,status=<span class="number">201</span>)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BookDetailView</span><span class="params">(View)</span>:</span></span><br><span class="line">    <span class="string">'''详情视图'''</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get</span><span class="params">(self,request,pk)</span>:</span></span><br><span class="line">        <span class="string">'''查询指定pk的图书接口'''</span></span><br><span class="line">        <span class="comment">#1.获取出指定pk的那个模型对象</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            book=BookInfo.objects.get(id=pk)</span><br><span class="line">        <span class="keyword">except</span> BookInfo.DoesNotExist:</span><br><span class="line">            <span class="keyword">return</span> HttpResponse(&#123;<span class="string">'message'</span>:<span class="string">'查询的数据不存在'</span>&#125;,status=<span class="number">404</span>)</span><br><span class="line">        <span class="comment">#2.模型对象转字典</span></span><br><span class="line">        book_dict = &#123;</span><br><span class="line">            <span class="string">'id'</span>: book.id,</span><br><span class="line">            <span class="string">'btitle'</span>: book.btitle,</span><br><span class="line">            <span class="string">'bpub_date'</span>: book.bpub_date,</span><br><span class="line">            <span class="string">'bread'</span>: book.bread,</span><br><span class="line">            <span class="string">'bcomment'</span>: book.bcomment,</span><br><span class="line">            <span class="string">'image'</span>: book.image.url <span class="keyword">if</span> book.image <span class="keyword">else</span> <span class="string">''</span>  <span class="comment"># if不成立为None.url，返回空字符串</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">#3.响应</span></span><br><span class="line">        <span class="keyword">return</span> JsonResponse(book_dict)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">post</span><span class="params">(self,request,pk)</span>:</span></span><br><span class="line">        <span class="string">'''修改指定图书接口'''</span></span><br><span class="line">        <span class="comment">#先查询要修改的模型对象</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            book=BookInfo.objects.get(pk=pk)</span><br><span class="line">        <span class="keyword">except</span> BookInfo.DoesNotExist:</span><br><span class="line">            <span class="keyword">return</span> HttpResponse(&#123;<span class="string">'message'</span>:<span class="string">'要修改的数据不存在'</span>&#125;,status=<span class="number">404</span>)</span><br><span class="line">        <span class="comment">#获取前端传入的新数据（把数据转换成字典）</span></span><br><span class="line">        json_str_bytes=request.body</span><br><span class="line">        json_str=json_str_bytes.decode()</span><br><span class="line">        book_dict=json.loads(json_str)</span><br><span class="line">        <span class="comment">#book_dict=json.loads(request.body.decode())</span></span><br><span class="line">        <span class="comment">#重新给模型指定的属性赋值</span></span><br><span class="line">        book.btitle=book_dict[<span class="string">'btitle'</span>]</span><br><span class="line">        book.bpub_date=book_dict[<span class="string">'bpub_date'</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment">#调用save方法进行修改操作</span></span><br><span class="line">        book.save()</span><br><span class="line">        <span class="comment">#把修改后的模型再转换成字典</span></span><br><span class="line">        json_dict = &#123;</span><br><span class="line">            <span class="string">'id'</span>: book.id,</span><br><span class="line">            <span class="string">'btitle'</span>: book.btitle,</span><br><span class="line">            <span class="string">'bpub_date'</span>: book.bpub_date,</span><br><span class="line">            <span class="string">'bread'</span>: book.bread,</span><br><span class="line">            <span class="string">'bcomment'</span>: book.bcomment,</span><br><span class="line">            <span class="string">'image'</span>: book.image.url <span class="keyword">if</span> book.image <span class="keyword">else</span> <span class="string">''</span>  <span class="comment"># if不成立为None.url，返回空字符串</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">#响应</span></span><br><span class="line">        <span class="keyword">return</span> JsonResponse(json_dict)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">delete</span><span class="params">(self,request,pk)</span>:</span></span><br><span class="line">        <span class="string">'''删除指定图书接口'''</span></span><br><span class="line">        <span class="comment">#获取要删除的模型对象</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            book=BookInfo.objects.get(id=pk)</span><br><span class="line">        <span class="keyword">except</span> BookInfo.DoesNotExist:</span><br><span class="line">            <span class="keyword">return</span> HttpResponse(&#123;<span class="string">'message'</span>:<span class="string">'要删除的数据不存在'</span>&#125;,status=<span class="number">404</span>)</span><br><span class="line">        <span class="comment">#删除模型对象</span></span><br><span class="line">        book.delete()<span class="comment">#物理删除（真正从数据库中删除）</span></span><br><span class="line">        <span class="comment">#逻辑删除</span></span><br><span class="line">        <span class="comment"># book.is_delete=True</span></span><br><span class="line">        <span class="comment"># book.save()</span></span><br><span class="line">        <span class="comment">#响应：删除时不需要有响应体，但要指定状态码为204</span></span><br><span class="line">        <span class="keyword">return</span> HttpResponse(status=<span class="number">204</span>)</span><br></pre></td></tr></table></div></figure>

        <h2 id="2-DRF框架简介">
          <a href="#2-DRF框架简介" class="heading-link"><i class="fas fa-link"></i></a><a href="#2-DRF框架简介" class="headerlink" title="2.DRF框架简介"></a><strong>2.DRF框架简介</strong></h2>
      </li>
<li>序列化和反序列化<ul>
<li>序列化：（输出）模型转字典，只有删除操作不需要</li>
<li>反序列化：（输入）字典转模型，只有增加和修改操作需要</li>
<li>在开发REST API的视图中，虽然每个视图具体操作的数据不同，但增、删、改、查的实现流程基本套路化，所以这部分代码也是可以复⽤简化编写的：<ul>
<li>增：校验请求数据 -&gt; 执⾏反序列化过程 -&gt; 保存数据库 -&gt; 将保存的对象序列化并返回</li>
<li>删：判断要删除的数据是否存在 -&gt; 执⾏数据库删除</li>
<li>改：判断要修改的数据是否存在 -&gt; 校验请求的数据 -&gt; 执⾏反序列化过程 -&gt; 保存数据库 -&gt; 将保存的对象序列化并返回</li>
<li>查：查询数据库 -&gt; 将数据序列化并返回</li>
</ul>
</li>
<li>DRF将序列化和反序列化的业务逻辑进行了封装，程序员只需要将序列化和反序列化的数据传给DRF即可
        <h2 id="3-DRF安装和配置">
          <a href="#3-DRF安装和配置" class="heading-link"><i class="fas fa-link"></i></a><a href="#3-DRF安装和配置" class="headerlink" title="3.DRF安装和配置"></a><strong>3.DRF安装和配置</strong></h2>
      </li>
</ul>
</li>
<li>DRF环境依赖<ul>
<li>python</li>
<li>django</li>
</ul>
</li>
<li>安装DRF  <figure class="highlight plain"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install djangorestframework</span><br></pre></td></tr></table></div></figure></li>
<li>添加rest_framework应用<ul>
<li>settings.py  <figure class="highlight py"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">INSTALLED_APPS = [</span><br><span class="line"><span class="string">'django.contrib.admin'</span>,</span><br><span class="line"><span class="string">'django.contrib.auth'</span>,</span><br><span class="line"><span class="string">'django.contrib.contenttypes'</span>,</span><br><span class="line"><span class="string">'django.contrib.sessions'</span>,</span><br><span class="line"><span class="string">'django.contrib.messages'</span>,</span><br><span class="line"><span class="string">'django.contrib.staticfiles'</span>,</span><br><span class="line"></span><br><span class="line"><span class="string">'rest_framework'</span>, <span class="comment"># DRF</span></span><br><span class="line"><span class="string">'users.apps.UsersConfig'</span>, <span class="comment"># 安装users应⽤,演示基本使⽤</span></span><br><span class="line"><span class="string">'request_response.apps.RequestResponseConfig'</span>, <span class="comment"># 演示请求和响应</span></span><br><span class="line"><span class="string">'booktest.apps.BooktestConfig'</span>, <span class="comment"># 图书英雄管理应用</span></span><br><span class="line">]</span><br></pre></td></tr></table></div></figure></li>
</ul>
  <strong>【十行代码】</strong><ul>
<li>urls.py  <figure class="highlight py"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> rest_framework.routers <span class="keyword">import</span> DefaultRouter</span><br><span class="line">router=DefaultRouter()<span class="comment">#创建路由器</span></span><br><span class="line">router.register(<span class="string">r'books'</span>,views.BookListView)<span class="comment">#注册路由</span></span><br><span class="line">urlpatterns+=router.urls<span class="comment">#把生成好的路由拼接到urlpatterns</span></span><br></pre></td></tr></table></div></figure></li>
<li>views.py  <figure class="highlight py"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> rest_framework.viewsets <span class="keyword">import</span> ModelViewSet</span><br><span class="line"><span class="keyword">from</span> .serializers <span class="keyword">import</span> BookInfoSerializer</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BookInfo</span><span class="params">(ModelViewSet)</span>:</span></span><br><span class="line">    <span class="string">'''定义类视图'''</span></span><br><span class="line">    <span class="comment">#指定查询集</span></span><br><span class="line">    queryset = BookInfo.objects.all()</span><br><span class="line"></span><br><span class="line">    <span class="comment">#指定序列化器</span></span><br><span class="line">    serializer_class = BookInfoSerializer</span><br></pre></td></tr></table></div></figure></li>
<li>app目录(booktest)下新建serializers.py  <figure class="highlight py"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> rest_framework <span class="keyword">import</span> serializers</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> .models <span class="keyword">import</span> BookInfo</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BookInfoSerializer</span><span class="params">(serializers.ModelSerializer)</span>:</span></span><br><span class="line">    <span class="string">'''定义序列化器'''</span></span><br><span class="line">    <span class="class"><span class="keyword">class</span> <span class="title">Meta</span>:</span><span class="comment">#元类</span></span><br><span class="line">        model=BookInfo<span class="comment">#指定序列化从哪个模型映射字段</span></span><br><span class="line">        fields=<span class="string">'__all__'</span><span class="comment">#映射哪些字段</span></span><br></pre></td></tr></table></div></figure></li>
</ul>
</li>
</ul>
</div></div></article><article class="postlist-item post"><header class="post-header"><h1 class="post-title"><a class="post-title__link" href="/2022/05/21/excel%E5%AE%9E%E7%94%A8%E6%8A%80%E5%B7%A7/">excel实用技巧</a></h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">Created</span><span class="post-meta-item__value">2022-05-21</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">Updated</span><span class="post-meta-item__value">2022-05-21</span></span></div></header><div class="post-body"><div class="post-excerpt">
        <h3 id="1-计算合计数据">
          <a href="#1-计算合计数据" class="heading-link"><i class="fas fa-link"></i></a><a href="#1-计算合计数据" class="headerlink" title="1.计算合计数据"></a><strong>1.计算合计数据</strong></h3>
      <p>方法：alt+=<br><img src="/2022/05/21/excel%E5%AE%9E%E7%94%A8%E6%8A%80%E5%B7%A7/alt%2B%3D.png" alt></p>

        <h3 id="2-填好空格信息">
          <a href="#2-填好空格信息" class="heading-link"><i class="fas fa-link"></i></a><a href="#2-填好空格信息" class="headerlink" title="2.填好空格信息"></a><strong>2.填好空格信息</strong></h3>
      <p>方法：ctrl+e<br>【如果找不到规律就多写几个】<br><img src="/2022/05/21/excel%E5%AE%9E%E7%94%A8%E6%8A%80%E5%B7%A7/ctrl%2Be.jpg" alt></p>

        <h3 id="3-函数">
          <a href="#3-函数" class="heading-link"><i class="fas fa-link"></i></a><a href="#3-函数" class="headerlink" title="3.函数"></a><strong>3.函数</strong></h3>
      
        <h4 id="3-1-sum实战">
          <a href="#3-1-sum实战" class="heading-link"><i class="fas fa-link"></i></a><a href="#3-1-sum实战" class="headerlink" title="3.1 sum实战"></a><strong>3.1 sum实战</strong></h4>
      <p><img src="/2022/05/21/excel%E5%AE%9E%E7%94%A8%E6%8A%80%E5%B7%A7/sum.jpg" alt></p>
<ul>
<li>sum函数<ul>
<li>选中单元格，=SUM()，选中要求和的列即可自动填充</li>
<li>手机总销售额=SUM(Q:Q)</li>
</ul>
</li>
<li>SUMIF函数<ul>
<li>满足一个条件的求和<br>SUMIF(Range,Criteria,[Sum_range])条件范围，条件，求和范围</li>
<li>=SUMIF(，按tab键，选择插入函数，选中上述三个参数对应的列<br>2019年手机总销售额<br><img src="/2022/05/21/excel%E5%AE%9E%E7%94%A8%E6%8A%80%E5%B7%A7/sumif.jpg" alt></li>
<li>=SUMIF(B:B,B4,Q:Q)</li>
</ul>
</li>
<li>SUMIFS函数<ul>
<li>满足多个条件的求和</li>
<li>SUMIFS(Sum_range,Criteria_Range1,Criteria1,…)求和范围,条件范围1，条件1,…<br>2019年小米手机总销售额<br><img src="/2022/05/21/excel%E5%AE%9E%E7%94%A8%E6%8A%80%E5%B7%A7/sumifs1.jpg" alt><br>2019年2月1日到2月15日小米红米8A总销售额<br><img src="/2022/05/21/excel%E5%AE%9E%E7%94%A8%E6%8A%80%E5%B7%A7/sumifs2.jpg" alt>  </li>
</ul>
</li>
</ul>

        <h4 id="3-2-VLOOKUP实战">
          <a href="#3-2-VLOOKUP实战" class="heading-link"><i class="fas fa-link"></i></a><a href="#3-2-VLOOKUP实战" class="headerlink" title="3.2 VLOOKUP实战"></a><strong>3.2 VLOOKUP实战</strong></h4>
      <p><img src="/2022/05/21/excel%E5%AE%9E%E7%94%A8%E6%8A%80%E5%B7%A7/vlookup.jpg" alt><br>做出其中一个，剩下的往下一拖即可</p>
<ul>
<li>VLOOKUP(lookup_value,table_array,col_index_num,[range_lookup])<ul>
<li>lookup_value：查找值（用谁找）</li>
<li>table_array：表格阵列（在哪找）</li>
<li>col_index_num：所在列数（在哪列）</li>
<li>range_lookup：查找方式<ul>
<li>精确（0）：一对一匹配<br><img src="/2022/05/21/excel%E5%AE%9E%E7%94%A8%E6%8A%80%E5%B7%A7/vlookup0.jpg" alt><br>其中4表示所选区域的第四列</li>
<li>模糊（1或不填）：没有一对一匹配<br><img src="/2022/05/21/excel%E5%AE%9E%E7%94%A8%E6%8A%80%E5%B7%A7/vlookup1.jpg" alt><br>col_index_num=3,range_lookup=1（因为是范围，无法精确查找）</li>
</ul>
</li>
<li>col_index_num必须为table_array中的第一列（若不在第一列，可将其复制到最前面）</li>
<li>正常是相对引用，若表格改变，则函数失效。选中参数按F4变成绝对引用，此时，参数前面会多一个$。</li>
<li>混合引用：列固定/行固定<br>固定单价的列，不固定行，所以F前加$，这样左右上下拖拽，结果仍然正确。<br><img src="/2022/05/21/excel%E5%AE%9E%E7%94%A8%E6%8A%80%E5%B7%A7/vlookup_%E7%BB%9D%E5%AF%B9.png" alt></li>
<li>跨表查询<br>选择参数时，先点击要查询的表，参数中会自动添加【表名】!，其他操作同上  </li>
</ul>
</li>
</ul>

        <h4 id="3-3数据透视表实战">
          <a href="#3-3数据透视表实战" class="heading-link"><i class="fas fa-link"></i></a><a href="#3-3数据透视表实战" class="headerlink" title="3.3数据透视表实战"></a><strong>3.3数据透视表实战</strong></h4>
      <ul>
<li>选中数据，插入数据透视表，并根据需求将字段拖拽到四个区域。</li>
<li>建议行可以多几个维度，列最好只有1-2个维度（多了不好看）</li>
<li>若原数据改变，则右键数据透视表刷新即可</li>
<li>汇总方式<br><img src="/2022/05/21/excel%E5%AE%9E%E7%94%A8%E6%8A%80%E5%B7%A7/%E6%B1%87%E6%80%BB%E6%96%B9%E5%BC%8F.png" alt><ul>
<li>父行汇总的百分比：黑龙江的iPhone销售额百分比相加为1</li>
</ul>
</li>
<li>切片器：筛选数据，与数据透视表联动</li>
<li>放入ppt选择嵌入粘贴方式</li>
</ul>
</div></div></article></section><nav class="paginator"><div class="paginator-inner"><span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/"><i class="fas fa-angle-right"></i></a></div></nav></div></div><div class="sidebar-wrap" id="sidebar-wrap"><aside class="sidebar" id="sidebar"><section class="sidebar-toc hide"></section><!-- ov = overview--><section class="sidebar-ov"><div class="sidebar-ov-author"><div class="sidebar-ov-author__avatar"><img class="sidebar-ov-author__avatar_img" src="/images/icons/stun-logo.svg" alt="avatar"></div><p class="sidebar-ov-author__text">hello world</p></div><div class="sidebar-ov-state"><a class="sidebar-ov-state-item sidebar-ov-state-item--posts" href="/archives/"><div class="sidebar-ov-state-item__count">15</div><div class="sidebar-ov-state-item__name">Archives</div></a></div><div class="sidebar-ov-cc"><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en" target="_blank" rel="noopener" data-popover="Creative Commons" data-popover-pos="up"><img src="/images/cc-by-nc-sa.svg"></a></div></section></aside></div><div class="clearfix"></div></div></main><footer class="footer" id="footer"><div class="footer-inner"><div><span>Copyright © 2023</span><span class="footer__icon"><i class="fas fa-heart"></i></span><span>Millionchan</span></div><div><span>Powered by <a href="http://hexo.io/" title="Hexo" target="_blank" rel="noopener">Hexo</a></span><span> v4.2.1</span><span class="footer__devider">|</span><span>Theme - <a href="https://github.com/liuyib/hexo-theme-stun/" title="Stun" target="_blank" rel="noopener">Stun</a></span><span> v2.6.2</span></div></div></footer><div class="loading-bar" id="loading-bar"><div class="loading-bar__progress"></div></div><div class="back2top" id="back2top"><span class="back2top__icon"><i class="fas fa-rocket"></i></span></div></div><script src="https://cdn.jsdelivr.net/npm/jquery@v3.4.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.2/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.2/velocity.ui.min.js"></script><script src="/js/utils.js?v=2.6.2"></script><script src="/js/stun-boot.js?v=2.6.2"></script><script src="/js/scroll.js?v=2.6.2"></script><script src="/js/header.js?v=2.6.2"></script><script src="/js/sidebar.js?v=2.6.2"></script></body></html>